#!/usr/bin/env python3
from __future__ import annotations

import argparse
import hashlib
import json
import os
import sys
from pathlib import Path
from typing import Any, Dict, List, Optional, Sequence, Tuple

sys.path.insert(0, os.path.dirname(os.path.dirname(__file__)))

from atos_core.act import canonical_json_dumps, sha256_hex
from atos_core.conversation_loop_v110 import run_conversation_v110
from atos_core.external_dialogue_world_v111 import load_world_v111
from atos_core.external_world_ledger_v111 import (
    EXTERNAL_WORLD_ACTION_SEARCH_V111,
    EXTERNAL_WORLD_REASON_CODES_V111,
    compute_external_world_chain_hash_v111,
    external_world_event_to_dict_v111,
    make_external_world_event_v111,
    verify_external_world_event_sig_chain_v111,
)
from atos_core.external_world_gating_v112 import external_world_access_v112
from atos_core.fluency_survival_v112 import fluency_contract_v112, fluency_survival_plan_v112, summarize_fluency_fail_code_v112


def _fail(msg: str, *, code: int = 2) -> None:
    print(msg, file=sys.stderr)
    raise SystemExit(code)


def _sha256_file(path: Path) -> str:
    h = hashlib.sha256()
    with open(path, "rb") as f:
        while True:
            b = f.read(1024 * 1024)
            if not b:
                break
            h.update(b)
    return h.hexdigest()


def _ensure_absent(path: Path) -> None:
    if path.exists():
        _fail(f"worm_exists:{path}")


ACK_TO_CHOICE_LABEL_V112 = {
    # Deterministic minimal acknowledgements that are safe to treat as "continue with default option A"
    # when the system is awaiting an explicit A/B/C choice.
    # This is a V112 survival shim to avoid deadlocks where the user only replies "ok" for long horizons.
    "ok",
    "okay",
    "certo",
    "beleza",
    "blz",
    "continua",
    "continue",
    "segue",
    "vai",
    "faz",
    "pode",
    "sim",
}


def _canon_ack_token_v112(s: str) -> str:
    t = str(s or "").strip().lower()
    t = " ".join([x for x in t.split() if x])
    return t


def _choiceify_minimal_ack_v112(user_turn_texts: Sequence[str]) -> List[str]:
    """
    Deterministic "agency survival" mapping:
      - If the user replies with a minimal acknowledgement (ok/continue/etc.),
        treat it as choosing the default option "A" when a choice is pending.

    This avoids the V110 deadlock where the agent repeatedly asks "Escolha: A/B/C" and the user keeps
    replying "ok", producing extremely repetitive assistant outputs that fail the fluency survival gate.
    """
    out: List[str] = []
    for s in user_turn_texts:
        cs = _canon_ack_token_v112(str(s))
        if cs in ACK_TO_CHOICE_LABEL_V112:
            out.append("A")
        else:
            out.append(str(s))
    return out


def _load_jsonl_payload_view(path: Path) -> List[Dict[str, Any]]:
    out: List[Dict[str, Any]] = []
    if not path.exists():
        return out
    with open(path, "r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            obj = json.loads(line)
            if not isinstance(obj, dict):
                continue
            payload = obj.get("payload")
            if not isinstance(payload, dict):
                continue
            out.append(dict(payload))
    return out


def _load_jsonl(path: Path) -> List[Dict[str, Any]]:
    out: List[Dict[str, Any]] = []
    if not path.exists():
        return out
    with open(path, "r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            out.append(json.loads(line))
    return out


def _write_once_json(path: Path, obj: Any) -> None:
    _ensure_absent(path)
    tmp = path.with_suffix(path.suffix + ".tmp")
    if tmp.exists():
        _fail(f"tmp_exists:{tmp}")
    tmp.write_text(json.dumps(obj, ensure_ascii=False, indent=2, sort_keys=True) + "\n", encoding="utf-8")
    os.replace(str(tmp), str(path))


def _compute_external_world_access_once(
    *,
    world_manifest: str,
    reason_code: str,
    query: str,
    seed: int,
) -> Tuple[List[Dict[str, Any]], Dict[str, Any]]:
    # Single event at event_index=0 (ledger in-run is per-task).
    try:
        evs, summary = external_world_access_v112(
            allowed=True,
            world_manifest=str(world_manifest),
            action=EXTERNAL_WORLD_ACTION_SEARCH_V111,
            reason_code=str(reason_code),
            args={"query": str(query), "limit": 3, "roles": ["user"]},
            seed=int(seed),
            turn_index=0,
            prev_event_sig="",
        )
        return list(evs), dict(summary)
    except ValueError as e:
        _fail(str(e))


def _count_unresolved_reference_events(binding_events: Sequence[Dict[str, Any]]) -> int:
    bad = 0
    for ev in binding_events:
        if not isinstance(ev, dict):
            continue
        t = str(ev.get("type") or "")
        if t in {"BIND_MISS", "BIND_AMBIGUOUS"}:
            bad += 1
    return int(bad)


def _unresolved_reference_final_from_flow(flow_events: Sequence[Dict[str, Any]]) -> int:
    """
    Minimal V112 interpretation: unresolved reference must not remain active at end of run.
    (We allow repairs mid-run, but require the final state to be clean.)
    """
    if not flow_events:
        return 0
    last = flow_events[-1] if isinstance(flow_events[-1], dict) else {}
    flags = last.get("flow_flags_v108")
    if not isinstance(flags, dict):
        return 0
    return 1 if bool(flags.get("UNRESOLVED_REFERENCE")) else 0


def _count_semantic_contradiction_flags(semantic_events: Sequence[Dict[str, Any]]) -> int:
    cnt = 0
    for ev in semantic_events:
        if not isinstance(ev, dict):
            continue
        flags = ev.get("flags_v109")
        if not isinstance(flags, dict):
            continue
        if bool(flags.get("CONTRADICTION_UNREPAIRED")):
            cnt += 1
    return int(cnt)


def _write_external_world_ledger(*, task_dir: Path, events: Sequence[Dict[str, Any]]) -> Dict[str, Any]:
    events_path = task_dir / "external_world_events.jsonl"
    _ensure_absent(events_path)
    # Write as JSONL (no outer chain here; inner sig-chain already binds prev_event_sig).
    if events:
        with open(events_path, "x", encoding="utf-8") as f:
            for e in events:
                f.write(canonical_json_dumps(e))
                f.write("\n")
    else:
        events_path.write_text("", encoding="utf-8")

    ok_sig, reason_sig, details_sig = verify_external_world_event_sig_chain_v111(list(events))
    if not ok_sig:
        _fail(f"external_world_sig_chain_fail:{reason_sig}")
    chain_hash = compute_external_world_chain_hash_v111(list(events))
    snap = {
        "schema_version": 111,
        "kind": "external_world_registry_snapshot_v111",
        "events_total": int(len(events)),
        "external_world_chain_hash_v111": str(chain_hash),
    }
    snap_path = task_dir / "external_world_registry_snapshot_v111.json"
    _write_once_json(snap_path, snap)
    return {
        "events_total": int(len(events)),
        "external_world_chain_hash_v111": str(chain_hash),
        "external_world_events_jsonl": str(events_path),
        "external_world_registry_snapshot_v111_json": str(snap_path),
    }


def _compute_freeze_manifest_v112(*, task_dir: Path, sha256_paths: Dict[str, str]) -> Dict[str, Any]:
    sha256: Dict[str, str] = {}
    rel_paths: Dict[str, str] = {}
    for k, p in sorted(sha256_paths.items(), key=lambda kv: str(kv[0])):
        fp = Path(p)
        try:
            rel_paths[str(k)] = str(fp.relative_to(task_dir))
        except Exception:
            rel_paths[str(k)] = str(fp.name)
        if fp.exists():
            sha256[str(k)] = _sha256_file(fp)
    return {"schema_version": 112, "kind": "freeze_manifest_v112", "sha256": sha256, "sha256_paths": dict(rel_paths)}


def main() -> None:
    ap = argparse.ArgumentParser()
    ap.add_argument("--tasks", required=True)
    ap.add_argument("--out", required=True)
    ap.add_argument("--seed", required=True, type=int)
    ap.add_argument("--max_tasks", type=int, default=9999)
    ap.add_argument("--max_rewrites", type=int, default=4)
    args = ap.parse_args()

    seed = int(args.seed)
    tasks_path = Path(str(args.tasks))
    out_dir = Path(str(args.out))
    _ensure_absent(out_dir)
    out_dir.mkdir(parents=True, exist_ok=False)

    tasks: List[Dict[str, Any]] = []
    with open(tasks_path, "r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            tasks.append(json.loads(line))
    if not tasks:
        _fail("empty_tasks")

    max_tasks = min(int(args.max_tasks), len(tasks))
    tasks = tasks[:max_tasks]

    results: List[Dict[str, Any]] = []
    failures: List[Dict[str, Any]] = []

    for i, task in enumerate(tasks):
        if not isinstance(task, dict):
            continue
        task_id = str(task.get("task_id") or f"task_{i}")
        user_turns = task.get("user_turns") if isinstance(task.get("user_turns"), list) else []
        user_turn_texts = [str(x) for x in user_turns if isinstance(x, str)]
        # V112: long-horizon survival shim: map minimal acks to a deterministic "A" choice label.
        user_turn_texts_engine = _choiceify_minimal_ack_v112(user_turn_texts)
        task_subdir = out_dir / f"task_{i:03d}"
        _ensure_absent(task_subdir)
        task_subdir.mkdir(parents=True, exist_ok=False)

        world_manifest = str(task.get("world_manifest") or "")
        allow_external = bool(task.get("allow_external_world_once"))
        reason_code = str(task.get("external_world_probe_reason_code") or "validator_failed_fluency_contract")
        if reason_code and reason_code not in EXTERNAL_WORLD_REASON_CODES_V111:
            _fail(f"invalid_reason_code_in_task:{reason_code}")

        attempt_seeds = fluency_survival_plan_v112(base_seed=int(seed), max_attempts=int(args.max_rewrites))
        attempts: List[Dict[str, Any]] = []
        chosen_attempt = -1
        ext_events_final: List[Dict[str, Any]] = []
        ext_used = False
        ext_used_reason = ""

        for a, seed_used in enumerate(attempt_seeds):
            attempt_dir = task_subdir / f"attempt_{a:03d}"
            _ensure_absent(attempt_dir)
            run_conversation_v110(user_turn_texts=user_turn_texts_engine, out_dir=str(attempt_dir), seed=int(seed_used))

            transcript_rows = _load_jsonl_payload_view(attempt_dir / "transcript.jsonl")
            # Restore original user text for fluency auditing (assistant output is the primary target, but keep the
            # transcript view aligned with the task input for reproducibility/debugging).
            user_i = 0
            transcript_view: List[Dict[str, Any]] = []
            for r in transcript_rows:
                role = str(r.get("role") or "")
                text = str(r.get("text") or "")
                if role == "user" and user_i < len(user_turn_texts):
                    text = str(user_turn_texts[user_i])
                    user_i += 1
                transcript_view.append({"role": role, "text": text})

            ok_fc, reason_fc, details_fc = fluency_contract_v112(transcript_view=transcript_view)
            # Deterministic probe: ensure exactly one in-cycle external world access is exercised.
            # This creates a blocked condition (fluency gate) on attempt 0, then recovery on a later attempt.
            if allow_external and (not ext_used) and a == 0:
                ok_fc = False
                reason_fc = "forced_external_world_probe"

            binding_events = _load_jsonl(attempt_dir / "binding_events.jsonl")
            unresolved_refs_total = _count_unresolved_reference_events(binding_events)
            flow_events = _load_jsonl(attempt_dir / "flow_events.jsonl")
            unresolved_refs_final = _unresolved_reference_final_from_flow(flow_events)
            semantic_events = _load_jsonl(attempt_dir / "semantic_events.jsonl")
            contradiction_flags = _count_semantic_contradiction_flags(semantic_events)

            attempts.append(
                {
                    "attempt_index": int(a),
                    "seed_used": int(seed_used),
                    "ok_fluency": bool(ok_fc),
                    "reason_fluency": str(reason_fc),
                    "unresolved_reference_events_total": int(unresolved_refs_total),
                    "unresolved_reference_final": int(unresolved_refs_final),
                    "semantic_contradiction_flags": int(contradiction_flags),
                    "fluency_details": dict(details_fc),
                }
            )

            # External world: allow exactly once, only after a failed attempt (progress blocked).
            if allow_external and (not ext_used) and (not ok_fc):
                # Deterministic single access; do not use results as "answer", only as auditably logged evidence.
                ext_events_final, _ = _compute_external_world_access_once(
                    world_manifest=world_manifest,
                    reason_code=str(reason_code),
                    query="nÃ£o invente",
                    seed=int(seed),
                )
                ext_used = True
                ext_used_reason = str(reason_code)

            if ok_fc and unresolved_refs_final == 0 and contradiction_flags == 0:
                chosen_attempt = int(a)
                break

        # Persist fluency survival trace (WORM).
        _write_once_json(
            task_subdir / "fluency_survival_v112.json",
            {
                "schema_version": 112,
                "task_id": str(task_id),
                "chosen_attempt_index": int(chosen_attempt),
                "attempts": list(attempts),
                "external_world_used": bool(ext_used),
                "external_world_reason_code": str(ext_used_reason),
            },
        )

        # Pick the attempt dir that will be considered "final" for this task (even if failing).
        final_attempt_dir = task_subdir / (f"attempt_{chosen_attempt:03d}" if chosen_attempt >= 0 else "attempt_000")

        # External world ledger (WORM) inside final attempt dir (empty by default).
        ext_info = _write_external_world_ledger(task_dir=final_attempt_dir, events=ext_events_final if ext_used else [])

        # Freeze manifest v112 (task-local, points to final attempt dir artifacts).
        freeze_path = final_attempt_dir / "freeze_manifest_v112.json"
        sha256_paths = {
            "v110_summary_json": str(final_attempt_dir / "summary.json"),
            "v110_freeze_manifest_v110_json": str(final_attempt_dir / "freeze_manifest_v110.json"),
            "task_eval_json": str(final_attempt_dir / "eval.json"),
            "fluency_survival_v112_json": str(task_subdir / "fluency_survival_v112.json"),
            "external_world_events_jsonl": str(ext_info["external_world_events_jsonl"]),
            "external_world_registry_snapshot_v111_json": str(ext_info["external_world_registry_snapshot_v111_json"]),
        }
        freeze = _compute_freeze_manifest_v112(task_dir=final_attempt_dir, sha256_paths=sha256_paths)
        _write_once_json(freeze_path, freeze)
        ledger_hash = _sha256_file(freeze_path)

        # Per-task eval v112.
        ok_task = bool(chosen_attempt >= 0)
        eval_obj = {
            "schema_version": 112,
            "task_id": str(task_id),
            "ok": bool(ok_task),
            "chosen_attempt_index": int(chosen_attempt),
            "external_world_events_total": int(ext_info["events_total"]),
            "external_world_chain_hash_v111": str(ext_info["external_world_chain_hash_v111"]),
            "external_world_used_reason_code": str(ext_used_reason),
            "ledger_hash": str(ledger_hash),
        }
        eval_path = final_attempt_dir / "eval_v112.json"
        _write_once_json(eval_path, eval_obj)

        results.append(
            {
                "task_index": int(i),
                "task_id": str(task_id),
                "run_dir": str(f"task_{i:03d}/" + final_attempt_dir.name),
                "ok": bool(ok_task),
                "chosen_attempt_index": int(chosen_attempt),
                "external_world_events_total": int(ext_info["events_total"]),
                "ledger_hash": str(ledger_hash),
            }
        )

        if not ok_task:
            fail_reason = summarize_fluency_fail_code_v112(str(attempts[-1].get("reason_fluency") or "")) if attempts else "unknown"
            failures.append(
                {
                    "task_index": int(i),
                    "task_id": str(task_id),
                    "fail_code": str(fail_reason),
                    "attempts_total": int(len(attempts)),
                    "final_attempt_seed": int(attempts[-1].get("seed_used") or seed) if attempts else int(seed),
                    "final_attempt_dir": str(final_attempt_dir),
                }
            )

    # Aggregate eval (deterministic; run_dir are relative).
    agg = {
        "schema_version": 112,
        "seed": int(seed),
        "tasks_total": int(len(results)),
        "tasks_ok": int(sum(1 for r in results if bool(r.get("ok")))),
        "results": list(results),
        "aggregate_sig": sha256_hex(canonical_json_dumps({"seed": int(seed), "results": results}).encode("utf-8")),
    }
    _write_once_json(out_dir / "eval.json", agg)

    summary = {
        "schema_version": 112,
        "seed": int(seed),
        "tasks_total": int(len(results)),
        "tasks_ok": int(sum(1 for r in results if bool(r.get("ok")))),
        "eval_sha256": _sha256_file(out_dir / "eval.json"),
    }
    _write_once_json(out_dir / "summary.json", summary)

    # Fail catalog (WORM) for triage.
    fc = {
        "schema_version": 112,
        "seed": int(seed),
        "tasks_total": int(len(results)),
        "tasks_ok": int(sum(1 for r in results if bool(r.get("ok")))),
        "failures_total": int(len(failures)),
        "failures": list(failures),
        "top_failures": {
            k: int(sum(1 for f in failures if str(f.get("fail_code") or "") == k))
            for k in sorted(set([str(f.get("fail_code") or "") for f in failures]), key=str)
        },
        "suggested_patch_scope": "atos_core/fluency_survival_v112.py",
    }
    _write_once_json(out_dir / "fail_catalog_v112.json", fc)

    print(json.dumps({"ok": True, "out_dir": str(out_dir), "summary": summary}, ensure_ascii=False, indent=2, sort_keys=True))


if __name__ == "__main__":
    main()
