--- patches/v120_base/atos_core/conversation_loop_v110.py	2026-01-16 10:06:48
+++ atos_core/conversation_loop_v110.py	2026-01-16 09:54:47
@@ -991,6 +991,7 @@
     out_dir: str,
     seed: int,
     discourse_variants_v119_enabled: bool = False,
+    goal_autopilot_total_steps: int = 60,
 ) -> Dict[str, Any]:
     ensure_absent(str(out_dir))
     os.makedirs(str(out_dir), exist_ok=False)
@@ -4839,7 +4840,7 @@
                         except Exception:
                             step_idx_after = 0
                         step_num = int(step_idx_after + 1)
-                        total_steps = 60
+                        total_steps = int(goal_autopilot_total_steps) if int(goal_autopilot_total_steps) > 0 else 60
                         # Deterministic micro-variation to avoid robotic repetition (no randomness).
                         prefixes = ["AVANÇO", "SEGUINDO", "CONTINUANDO", "PRÓXIMO"]
                         prefix = prefixes[int(step_idx_after) % len(prefixes)]
--- /dev/null	2026-01-16 10:10:11
+++ atos_core/conversation_loop_v120.py	2026-01-16 09:54:29
@@ -0,0 +1,637 @@
+from __future__ import annotations
+
+import json
+import os
+import shutil
+from dataclasses import dataclass
+from typing import Any, Dict, List, Optional, Sequence, Tuple
+
+from .act import canonical_json_dumps, deterministic_iso, sha256_hex
+from .ato_v71 import ATOv71, stable_hash_obj
+from .conversation_loop_v110 import run_conversation_v110
+from .conversation_loop_v116 import apply_dialogue_survival_as_law_v116
+from .conversation_v96 import verify_chained_jsonl_v96
+from .fluency_contract_v118 import FluencyContractResultV118, fluency_contract_v118
+from .goal_persistence_law_v120 import write_goal_persistence_summary_v120
+from .goal_persistence_v115 import render_fail_response_v115
+from .goal_plan_eval_gate_v115 import goal_id_v115, verify_goal_plan_eval_law_v115
+from .mind_graph_v71 import append_chained_jsonl, verify_chained_jsonl
+
+
+FAIL_REASON_PLAN_SEARCH_BUDGET_EXHAUSTED_V120 = "plan_search_budget_exhausted_v120"
+
+
+def _ensure_absent(path: str) -> None:
+    if os.path.exists(path):
+        raise ValueError(f"worm_exists:{path}")
+    tmp = path + ".tmp"
+    if os.path.exists(tmp):
+        raise ValueError(f"tmp_exists:{tmp}")
+
+
+def _write_once_json(path: str, obj: Any) -> None:
+    _ensure_absent(path)
+    tmp = path + ".tmp"
+    with open(tmp, "w", encoding="utf-8") as f:
+        f.write(json.dumps(obj, ensure_ascii=False, indent=2, sort_keys=True))
+        f.write("\n")
+    os.replace(tmp, path)
+
+
+def _read_json(path: str) -> Any:
+    with open(path, "r", encoding="utf-8") as f:
+        return json.load(f)
+
+
+def _read_jsonl(path: str) -> List[Dict[str, Any]]:
+    out: List[Dict[str, Any]] = []
+    if not os.path.exists(path):
+        return out
+    with open(path, "r", encoding="utf-8") as f:
+        for line in f:
+            line = line.strip()
+            if not line:
+                continue
+            out.append(json.loads(line))
+    return out
+
+
+def _last_entry_hash(path: str) -> str:
+    last = ""
+    if not os.path.exists(path):
+        return last
+    with open(path, "r", encoding="utf-8") as f:
+        for line in f:
+            line = line.strip()
+            if not line:
+                continue
+            obj = json.loads(line)
+            if isinstance(obj, dict):
+                last = str(obj.get("entry_hash") or last)
+    return str(last)
+
+
+def _sorted_dict_list(items: Sequence[Dict[str, Any]]) -> List[Dict[str, Any]]:
+    pairs: List[Tuple[str, Dict[str, Any]]] = []
+    for it in items:
+        if not isinstance(it, dict):
+            continue
+        try:
+            k = canonical_json_dumps(it)
+        except Exception:
+            k = str(it)
+        pairs.append((str(k), dict(it)))
+    pairs.sort(key=lambda kv: str(kv[0]))
+    return [v for _, v in pairs]
+
+
+def _copy_file_worm(src: str, dst: str) -> None:
+    _ensure_absent(dst)
+    with open(src, "rb") as f:
+        data = f.read()
+    tmp = dst + ".tmp"
+    if os.path.exists(tmp):
+        raise ValueError(f"tmp_exists:{tmp}")
+    with open(tmp, "wb") as f:
+        f.write(data)
+    os.replace(tmp, dst)
+
+
+def _copy_tree_worm(src_dir: str, dst_dir: str) -> None:
+    _ensure_absent(dst_dir)
+    shutil.copytree(src_dir, dst_dir, dirs_exist_ok=False)
+
+
+def _promote_attempt_to_root(*, attempt_dir: str, out_dir: str) -> None:
+    ad = str(attempt_dir)
+    od = str(out_dir)
+    for name in sorted(os.listdir(ad), key=str):
+        src = os.path.join(ad, name)
+        dst = os.path.join(od, name)
+        if os.path.isdir(src):
+            if name.startswith("attempt_") or name.startswith("replan_attempt_"):
+                continue
+            _copy_tree_worm(src, dst)
+        else:
+            _copy_file_worm(src, dst)
+
+
+def _extract_last_user_turn_payload(run_dir: str) -> Dict[str, Any]:
+    rows = _read_jsonl(os.path.join(str(run_dir), "conversation_turns.jsonl"))
+    users: List[Dict[str, Any]] = []
+    for row in rows:
+        payload = row.get("payload") if isinstance(row, dict) else None
+        if not isinstance(payload, dict):
+            continue
+        if str(payload.get("role") or "") == "user":
+            users.append(dict(payload))
+    if not users:
+        return {}
+    users.sort(key=lambda p: (int(p.get("turn_index", 0) or 0), int(p.get("created_step", 0) or 0), str(p.get("turn_id") or "")))
+    return dict(users[-1])
+
+
+def _plan_row_for_user_turn(run_dir: str, user_turn_id: str) -> Dict[str, Any]:
+    rows = _read_jsonl(os.path.join(str(run_dir), "action_plans.jsonl"))
+    for row in rows:
+        if not isinstance(row, dict):
+            continue
+        if str(row.get("user_turn_id") or "") == str(user_turn_id):
+            return dict(row)
+    return {}
+
+
+def _make_plan_ato_v120(*, action_plan: Dict[str, Any]) -> ATOv71:
+    plan_id = str(action_plan.get("plan_id") or action_plan.get("plan_sig") or "")
+    if not plan_id:
+        raise ValueError("missing_plan_id")
+    created_step = int(action_plan.get("created_step", 0) or 0)
+    user_turn_id = str(action_plan.get("user_turn_id") or "")
+    user_turn_index = int(action_plan.get("user_turn_index", -1) or -1)
+    ranked = action_plan.get("ranked_candidates") if isinstance(action_plan.get("ranked_candidates"), list) else []
+    attempted = action_plan.get("attempted_actions") if isinstance(action_plan.get("attempted_actions"), list) else []
+    subgraph = {
+        "schema_version": 120,
+        "plan_id": str(plan_id),
+        "user_turn_id": str(user_turn_id),
+        "user_turn_index": int(user_turn_index),
+        "chosen_action_id": str(action_plan.get("chosen_action_id") or ""),
+        "chosen_eval_id": str(action_plan.get("chosen_eval_id") or ""),
+        "chosen_ok": bool(action_plan.get("chosen_ok", False)),
+        "ranked_candidates": [
+            {
+                "act_id": str(r.get("act_id") or ""),
+                "expected_success": float(r.get("expected_success", 0.0) or 0.0),
+                "expected_cost": float(r.get("expected_cost", 0.0) or 0.0),
+            }
+            for r in ranked
+            if isinstance(r, dict)
+        ],
+        "attempted_actions": [
+            {"act_id": str(a.get("act_id") or ""), "eval_id": str(a.get("eval_id") or ""), "ok": bool(a.get("ok", False))}
+            for a in attempted
+            if isinstance(a, dict)
+        ],
+    }
+    subgraph["ranked_candidates"].sort(key=lambda d: str(d.get("act_id") or ""))
+    subgraph["attempted_actions"].sort(key=lambda d: (str(d.get("eval_id") or ""), str(d.get("act_id") or "")))
+    return ATOv71(
+        ato_id=str(plan_id),
+        ato_type="PLAN",
+        subgraph=dict(subgraph),
+        slots={},
+        bindings={},
+        cost=float(len(subgraph["ranked_candidates"])),
+        evidence_refs=[{"kind": "turn", "turn_id": str(user_turn_id)}] if user_turn_id else [],
+        invariants={"schema_version": 120, "plan_kind": "action_plan_v100"},
+        created_step=int(created_step),
+        last_step=int(created_step),
+    )
+
+
+def _make_fail_event_ato_v120(
+    *,
+    conversation_id: str,
+    user_turn_id: str,
+    goal_ato_id: str,
+    plan_ato_id: str,
+    reason_code: str,
+    step: int,
+    evidence: Dict[str, Any],
+) -> ATOv71:
+    body = {
+        "schema_version": 120,
+        "conversation_id": str(conversation_id),
+        "user_turn_id": str(user_turn_id),
+        "goal_ato_id": str(goal_ato_id),
+        "plan_ato_id": str(plan_ato_id),
+        "reason_code": str(reason_code),
+        "evidence": dict(evidence) if isinstance(evidence, dict) else {},
+    }
+    fail_id = "fail_event_v120_" + sha256_hex(canonical_json_dumps(body).encode("utf-8"))
+    return ATOv71(
+        ato_id=str(fail_id),
+        ato_type="EVAL",
+        subgraph=dict(body, satisfies=False),
+        slots={},
+        bindings={},
+        cost=0.0,
+        evidence_refs=[{"kind": "turn", "turn_id": str(user_turn_id)}] if user_turn_id else [],
+        invariants={"schema_version": 120, "eval_kind": "FAIL_EVENT_V120"},
+        created_step=int(step),
+        last_step=int(step),
+    )
+
+
+def _append_fail_event_to_mind_graph_v120(
+    *,
+    mind_graph_v120_dir: str,
+    fail_ato: ATOv71,
+    goal_ato_id: str,
+    plan_ato_id: str,
+    user_turn_id: str,
+    step: int,
+    evidence_refs: Sequence[Dict[str, Any]],
+) -> None:
+    mg_dir = str(mind_graph_v120_dir)
+    nodes_path = os.path.join(mg_dir, "mind_nodes.jsonl")
+    edges_path = os.path.join(mg_dir, "mind_edges.jsonl")
+    if not os.path.exists(nodes_path) or not os.path.exists(edges_path):
+        raise ValueError("missing_mind_graph_files_v120")
+
+    fail_ato_dict = fail_ato.to_dict(include_sig=True)
+    prev_nodes_hash = _last_entry_hash(nodes_path) or None
+    nodes_entry = {
+        "time": deterministic_iso(step=int(step)),
+        "step": int(step),
+        "event": "NODE",
+        "payload": {"reason": "fail_event_v120", "ato": dict(fail_ato_dict)},
+    }
+    append_chained_jsonl(nodes_path, dict(nodes_entry), prev_hash=prev_nodes_hash)
+
+    ev_refs = _sorted_dict_list([x for x in evidence_refs if isinstance(x, dict)])
+
+    def _mk_edge(dst: str) -> Dict[str, Any]:
+        edge_sem_sig = {"src": str(fail_ato.ato_id), "dst": str(dst), "edge_type": "DERIVED_FROM", "evidence_refs": list(ev_refs)}
+        edge_sig = stable_hash_obj(edge_sem_sig)
+        return dict(edge_sem_sig, edge_sig=str(edge_sig))
+
+    dsts = [str(goal_ato_id), str(plan_ato_id), str(user_turn_id)]
+    dsts = [d for d in dsts if d]
+    for dst in dsts:
+        prev_edges_hash = _last_entry_hash(edges_path) or None
+        edges_entry = {
+            "time": deterministic_iso(step=int(step)),
+            "step": int(step),
+            "event": "EDGE",
+            "payload": {"reason": "fail_event_v120", "edge": _mk_edge(dst)},
+        }
+        append_chained_jsonl(edges_path, dict(edges_entry), prev_hash=prev_edges_hash)
+
+
+def _transcript_view_from_run_dir(run_dir: str) -> List[Dict[str, Any]]:
+    rows = _read_jsonl(os.path.join(str(run_dir), "transcript.jsonl"))
+    out: List[Dict[str, Any]] = []
+    for row in rows:
+        payload = row.get("payload") if isinstance(row, dict) else None
+        if not isinstance(payload, dict):
+            continue
+        role = str(payload.get("role") or "")
+        text = str(payload.get("text") or "")
+        if role in {"user", "assistant"}:
+            out.append({"role": role, "text": text})
+    return out
+
+
+@dataclass(frozen=True)
+class AttemptRecordV120:
+    attempt_index: int
+    seed_used: int
+    attempt_dir: str
+    goal_id: str
+    user_turn_id: str
+    ok_final_v116: bool
+    reason_final_v116: str
+    ok_fluency: bool
+    reason_fluency: str
+    ok_goal_persistence: bool
+    reason_goal_persistence: str
+
+    def to_dict(self) -> Dict[str, Any]:
+        return {
+            "attempt_index": int(self.attempt_index),
+            "seed_used": int(self.seed_used),
+            "attempt_dir": str(self.attempt_dir),
+            "goal_id": str(self.goal_id),
+            "user_turn_id": str(self.user_turn_id),
+            "ok_final_v116": bool(self.ok_final_v116),
+            "reason_final_v116": str(self.reason_final_v116),
+            "ok_fluency": bool(self.ok_fluency),
+            "reason_fluency": str(self.reason_fluency),
+            "ok_goal_persistence": bool(self.ok_goal_persistence),
+            "reason_goal_persistence": str(self.reason_goal_persistence),
+        }
+
+
+def _replan_trace_obj_v120(
+    *,
+    conversation_id: str,
+    attempts: List[AttemptRecordV120],
+    chosen_attempt_index: int,
+    budget_total: int,
+    final_ok: bool,
+    final_reason: str,
+) -> Dict[str, Any]:
+    body = {
+        "schema_version": 120,
+        "kind": "replan_trace_v120",
+        "conversation_id": str(conversation_id),
+        "budget_total": int(budget_total),
+        "chosen_attempt_index": int(chosen_attempt_index),
+        "final_ok": bool(final_ok),
+        "final_reason": str(final_reason),
+        "attempts": [a.to_dict() for a in list(attempts)],
+    }
+    body["trace_sig"] = sha256_hex(canonical_json_dumps(body).encode("utf-8"))
+    return dict(body)
+
+
+def run_conversation_v120(
+    *,
+    user_turn_texts: Sequence[str],
+    out_dir: str,
+    seed: int,
+    max_plan_attempts: int = 8,
+    max_replans_per_turn: int = 3,
+    goal_autopilot_total_steps: int = 60,
+) -> Dict[str, Any]:
+    """
+    V120: add "goal persistence as law" as an additional hard gate inside the replanning loop.
+    """
+    od = str(out_dir)
+    _ensure_absent(od)
+    os.makedirs(od, exist_ok=False)
+
+    attempts: List[AttemptRecordV120] = []
+    chosen_attempt = -1
+    conversation_id_seen = ""
+
+    for a in range(int(max_plan_attempts)):
+        seed_used = int(seed) + int(a)
+        attempt_dir = os.path.join(od, f"attempt_{a:03d}")
+
+        # 1) Base pipeline (V110) with discourse variants enabled (V119) and optional autopilot horizon override.
+        run_conversation_v110(
+            user_turn_texts=list(user_turn_texts),
+            out_dir=str(attempt_dir),
+            seed=int(seed_used),
+            discourse_variants_v119_enabled=True,
+            goal_autopilot_total_steps=int(goal_autopilot_total_steps),
+        )
+
+        # 2) Apply V115 goal-plan-eval law.
+        gate = verify_goal_plan_eval_law_v115(
+            run_dir=str(attempt_dir),
+            max_replans_per_turn=int(max_replans_per_turn),
+            write_mind_graph=True,
+            write_snapshots=True,
+        )
+        fr115 = {
+            "schema_version": 115,
+            "kind": "final_response_v115",
+            "ok": bool(gate.ok),
+            "reason": str(gate.reason if not bool(gate.ok) else "ok"),
+            "fail_response_text": str(render_fail_response_v115(str(gate.reason))) if not bool(gate.ok) else "",
+        }
+        fr115["final_sig"] = sha256_hex(canonical_json_dumps(fr115).encode("utf-8"))
+        _write_once_json(os.path.join(str(attempt_dir), "final_response_v115.json"), dict(fr115))
+
+        # 3) Apply V116 dialogue survival law.
+        applied = apply_dialogue_survival_as_law_v116(run_dir=str(attempt_dir), write_mind_graph=True)
+        fr116_path = os.path.join(str(attempt_dir), "final_response_v116.json")
+        fr116 = _read_json(fr116_path) if os.path.exists(fr116_path) else {}
+        ok_final = bool(fr116.get("ok", False)) if isinstance(fr116, dict) else False
+        reason_final = str(fr116.get("reason") or "") if isinstance(fr116, dict) else "missing_final_response_v116"
+
+        # 4) Fluency contract (V118).
+        transcript_view = _transcript_view_from_run_dir(str(attempt_dir))
+        ok_flu, reason_flu, details_flu = fluency_contract_v118(transcript_view=list(transcript_view))
+        flu_obj = FluencyContractResultV118(ok=bool(ok_flu), reason=str(reason_flu), details=dict(details_flu)).to_dict()
+        _write_once_json(os.path.join(str(attempt_dir), "fluency_summary_v120.json"), dict(flu_obj))
+
+        # 5) Goal persistence law (V120).
+        gps = write_goal_persistence_summary_v120(run_dir=str(attempt_dir), expected_autopilot_total_steps=int(goal_autopilot_total_steps))
+        ok_gp = bool(gps.get("ok", False))
+        reason_gp = str(gps.get("reason") or "") if isinstance(gps, dict) else "missing_goal_persistence_summary"
+
+        last_user = _extract_last_user_turn_payload(str(attempt_dir))
+        user_turn_id = str(last_user.get("turn_id") or "")
+        conversation_id = str(last_user.get("conversation_id") or str(applied.details.get("conversation_id") or ""))
+        if conversation_id and not conversation_id_seen:
+            conversation_id_seen = str(conversation_id)
+        user_turn_index = int(last_user.get("turn_index", 0) or 0)
+        refs = last_user.get("refs") if isinstance(last_user.get("refs"), dict) else {}
+        parse_sig = str(refs.get("parse_sig") or "")
+        user_text = str(last_user.get("text") or "")
+        gid = goal_id_v115(
+            conversation_id=str(conversation_id),
+            user_turn_id=str(user_turn_id),
+            user_turn_index=int(user_turn_index),
+            parse_sig=str(parse_sig),
+            user_text=str(user_text),
+        )
+
+        attempts.append(
+            AttemptRecordV120(
+                attempt_index=int(a),
+                seed_used=int(seed_used),
+                attempt_dir=os.path.basename(str(attempt_dir)),
+                goal_id=str(gid),
+                user_turn_id=str(user_turn_id),
+                ok_final_v116=bool(ok_final),
+                reason_final_v116=str(reason_final),
+                ok_fluency=bool(ok_flu),
+                reason_fluency=str(reason_flu) if not bool(ok_flu) else "ok",
+                ok_goal_persistence=bool(ok_gp),
+                reason_goal_persistence=str(reason_gp) if not bool(ok_gp) else "ok",
+            )
+        )
+
+        if bool(ok_final) and bool(ok_flu) and bool(ok_gp):
+            chosen_attempt = int(a)
+            break
+
+    if not attempts:
+        raise ValueError("no_attempts_v120")
+
+    final_ok = chosen_attempt >= 0
+    final_reason = "ok" if final_ok else FAIL_REASON_PLAN_SEARCH_BUDGET_EXHAUSTED_V120
+    chosen_idx = int(chosen_attempt if chosen_attempt >= 0 else (len(attempts) - 1))
+    chosen_attempt_dir = os.path.join(od, f"attempt_{chosen_idx:03d}")
+
+    # Promote chosen attempt artifacts to root (WORM).
+    _promote_attempt_to_root(attempt_dir=str(chosen_attempt_dir), out_dir=str(od))
+
+    # Write replanning trace (WORM).
+    rep_obj = _replan_trace_obj_v120(
+        conversation_id=str(conversation_id_seen),
+        attempts=list(attempts),
+        chosen_attempt_index=int(chosen_attempt if chosen_attempt >= 0 else -1),
+        budget_total=int(max_plan_attempts),
+        final_ok=bool(final_ok),
+        final_reason=str(final_reason),
+    )
+    _write_once_json(os.path.join(od, "replan_trace_v120.json"), dict(rep_obj))
+
+    # Write final_response_v120.json (WORM).
+    fr116_root_path = os.path.join(od, "final_response_v116.json")
+    fr116_root = _read_json(fr116_root_path) if os.path.exists(fr116_root_path) else {}
+    final_obj = {
+        "schema_version": 120,
+        "kind": "final_response_v120",
+        "ok": bool(final_ok),
+        "reason": str(final_reason if not final_ok else "ok"),
+        "fail_response_text": str(render_fail_response_v115(str(final_reason))) if not bool(final_ok) else "",
+        "upstream": {"final_response_v116": dict(fr116_root) if isinstance(fr116_root, dict) else {}},
+    }
+    final_obj["final_sig"] = sha256_hex(canonical_json_dumps(final_obj).encode("utf-8"))
+    _write_once_json(os.path.join(od, "final_response_v120.json"), dict(final_obj))
+
+    # Create mind_graph_v120: copy mind_graph_v116 and append FAIL_EVENT_V120 nodes for rejected attempts.
+    mg116_dir = os.path.join(od, "mind_graph_v116")
+    mg120_dir = os.path.join(od, "mind_graph_v120")
+    if os.path.isdir(mg116_dir):
+        os.makedirs(mg120_dir, exist_ok=False)
+        _copy_file_worm(os.path.join(mg116_dir, "mind_nodes.jsonl"), os.path.join(mg120_dir, "mind_nodes.jsonl"))
+        _copy_file_worm(os.path.join(mg116_dir, "mind_edges.jsonl"), os.path.join(mg120_dir, "mind_edges.jsonl"))
+        nodes_path = os.path.join(mg120_dir, "mind_nodes.jsonl")
+        edges_path = os.path.join(mg120_dir, "mind_edges.jsonl")
+        if not verify_chained_jsonl(nodes_path) or not verify_chained_jsonl(edges_path):
+            raise ValueError("mind_graph_v120_chain_invalid_after_copy")
+
+        existing_nodes: Dict[str, Dict[str, Any]] = {}
+        for row in _read_jsonl(nodes_path):
+            payload = row.get("payload") if isinstance(row, dict) else None
+            ato = payload.get("ato") if isinstance(payload, dict) else None
+            if not isinstance(ato, dict):
+                continue
+            ato_id = str(ato.get("ato_id") or "")
+            if ato_id:
+                existing_nodes[ato_id] = dict(ato)
+
+        chosen_last_user = _extract_last_user_turn_payload(str(chosen_attempt_dir))
+        chosen_user_turn_id = str(chosen_last_user.get("turn_id") or "")
+        chosen_conversation_id = str(chosen_last_user.get("conversation_id") or "")
+        chosen_user_turn_index = int(chosen_last_user.get("turn_index", 0) or 0)
+        chosen_refs = chosen_last_user.get("refs") if isinstance(chosen_last_user.get("refs"), dict) else {}
+        chosen_parse_sig = str(chosen_refs.get("parse_sig") or "")
+        chosen_user_text = str(chosen_last_user.get("text") or "")
+        chosen_goal_id = goal_id_v115(
+            conversation_id=str(chosen_conversation_id),
+            user_turn_id=str(chosen_user_turn_id),
+            user_turn_index=int(chosen_user_turn_index),
+            parse_sig=str(chosen_parse_sig),
+            user_text=str(chosen_user_text),
+        )
+        chosen_plan_row = _plan_row_for_user_turn(str(chosen_attempt_dir), str(chosen_user_turn_id))
+        chosen_plan_id = str(chosen_plan_row.get("plan_id") or chosen_plan_row.get("plan_sig") or "")
+
+        step0 = int(chosen_last_user.get("created_step", 0) or 0)
+
+        for ar in sorted(list(attempts), key=lambda a: int(a.attempt_index)):
+            if int(ar.attempt_index) == int(chosen_attempt):
+                continue
+
+            attempt_subdir = os.path.join(od, f"attempt_{int(ar.attempt_index):03d}")
+            plan_row = _plan_row_for_user_turn(str(attempt_subdir), str(ar.user_turn_id))
+            plan_id = str(plan_row.get("plan_id") or plan_row.get("plan_sig") or "") if isinstance(plan_row, dict) else ""
+
+            if plan_id and plan_id not in existing_nodes and isinstance(plan_row, dict) and plan_row:
+                plan_ato = _make_plan_ato_v120(action_plan=dict(plan_row))
+                plan_ato_dict = plan_ato.to_dict(include_sig=True)
+                prev_nodes_hash = _last_entry_hash(nodes_path) or None
+                nodes_entry = {
+                    "time": deterministic_iso(step=int(plan_ato.created_step)),
+                    "step": int(plan_ato.created_step),
+                    "event": "NODE",
+                    "payload": {"reason": "plan_import_v120", "ato": dict(plan_ato_dict)},
+                }
+                append_chained_jsonl(nodes_path, dict(nodes_entry), prev_hash=prev_nodes_hash)
+                existing_nodes[str(plan_id)] = dict(plan_ato_dict)
+
+            fail_specs: List[Tuple[str, Dict[str, Any]]] = []
+            if not bool(ar.ok_final_v116):
+                fail_specs.append(
+                    (
+                        "final_v116_fail",
+                        {
+                            "attempt_index": int(ar.attempt_index),
+                            "seed_used": int(ar.seed_used),
+                            "attempt_dir": str(ar.attempt_dir),
+                            "reason_final_v116": str(ar.reason_final_v116),
+                        },
+                    )
+                )
+            if not bool(ar.ok_fluency):
+                fsum_path = os.path.join(str(attempt_subdir), "fluency_summary_v120.json")
+                fsum_sig = ""
+                if os.path.exists(fsum_path):
+                    fobj = _read_json(fsum_path)
+                    if isinstance(fobj, dict):
+                        fsum_sig = str(fobj.get("result_sig") or "")
+                fail_specs.append(
+                    (
+                        "fluency_" + str(ar.reason_fluency),
+                        {
+                            "attempt_index": int(ar.attempt_index),
+                            "seed_used": int(ar.seed_used),
+                            "attempt_dir": str(ar.attempt_dir),
+                            "reason_fluency": str(ar.reason_fluency),
+                            "fluency_summary_result_sig": str(fsum_sig),
+                            "fluency_summary_file": os.path.basename(str(fsum_path)),
+                        },
+                    )
+                )
+            if not bool(ar.ok_goal_persistence):
+                gsum_path = os.path.join(str(attempt_subdir), "goal_persistence_summary_v120.json")
+                gsum_sig = ""
+                if os.path.exists(gsum_path):
+                    gobj = _read_json(gsum_path)
+                    if isinstance(gobj, dict):
+                        gsum_sig = str(gobj.get("summary_sig") or "")
+                fail_specs.append(
+                    (
+                        "goal_persistence_" + str(ar.reason_goal_persistence),
+                        {
+                            "attempt_index": int(ar.attempt_index),
+                            "seed_used": int(ar.seed_used),
+                            "attempt_dir": str(ar.attempt_dir),
+                            "reason_goal_persistence": str(ar.reason_goal_persistence),
+                            "goal_persistence_summary_sig": str(gsum_sig),
+                            "goal_persistence_summary_file": os.path.basename(str(gsum_path)),
+                        },
+                    )
+                )
+
+            for reason_code, evidence in sorted(fail_specs, key=lambda kv: str(kv[0])):
+                fail_ato = _make_fail_event_ato_v120(
+                    conversation_id=str(chosen_conversation_id),
+                    user_turn_id=str(chosen_user_turn_id),
+                    goal_ato_id=str(chosen_goal_id),
+                    plan_ato_id=str(plan_id or chosen_plan_id),
+                    reason_code=str(reason_code),
+                    step=int(step0),
+                    evidence=dict(evidence, replan_trace_sig=str(rep_obj.get("trace_sig") or ""), replan_trace_file="replan_trace_v120.json"),
+                )
+                _append_fail_event_to_mind_graph_v120(
+                    mind_graph_v120_dir=str(mg120_dir),
+                    fail_ato=fail_ato,
+                    goal_ato_id=str(chosen_goal_id),
+                    plan_ato_id=str(plan_id or chosen_plan_id),
+                    user_turn_id=str(chosen_user_turn_id),
+                    step=int(step0),
+                    evidence_refs=[
+                        {"kind": "turn", "turn_id": str(chosen_user_turn_id)},
+                        {"kind": "replan_trace", "trace_sig": str(rep_obj.get("trace_sig") or "")},
+                        {"kind": "attempt", "attempt_index": int(ar.attempt_index), "seed_used": int(ar.seed_used)},
+                    ],
+                )
+
+        if not verify_chained_jsonl(nodes_path) or not verify_chained_jsonl(edges_path):
+            raise ValueError("mind_graph_v120_chain_invalid_after_append")
+
+    # Best-effort chain checks on promoted ledgers.
+    for p in [
+        os.path.join(od, "transcript.jsonl"),
+        os.path.join(od, "conversation_turns.jsonl"),
+        os.path.join(od, "intent_parses.jsonl"),
+        os.path.join(od, "objective_evals.jsonl"),
+        os.path.join(od, "dialogue_trials.jsonl"),
+        os.path.join(od, "action_plans.jsonl"),
+        os.path.join(od, "goal_events.jsonl"),
+    ]:
+        if os.path.exists(p) and not bool(verify_chained_jsonl_v96(p)):
+            raise ValueError(f"chain_invalid_promoted:{os.path.basename(p)}")
+
+    return {"final_response_v120": dict(final_obj), "replan_trace_v120_sig": str(rep_obj.get("trace_sig") or "")}
+
--- /dev/null	2026-01-16 10:10:11
+++ atos_core/goal_persistence_law_v120.py	2026-01-16 10:07:31
@@ -0,0 +1,213 @@
+from __future__ import annotations
+
+import json
+import os
+import re
+from dataclasses import dataclass
+from typing import Any, Dict, List, Optional, Tuple
+
+from .act import canonical_json_dumps, sha256_hex
+from .conversation_v96 import verify_chained_jsonl_v96
+from .goal_ledger_v99 import verify_goal_event_sig_v99
+
+
+FAIL_REASON_MISSING_GOAL_EVENTS_V120 = "missing_goal_events_v120"
+FAIL_REASON_GOAL_EVENTS_CHAIN_INVALID_V120 = "goal_events_chain_invalid_v120"
+FAIL_REASON_GOAL_EVENT_SIG_INVALID_V120 = "goal_event_sig_invalid_v120"
+FAIL_REASON_GOAL_DONE_MISSING_ASSISTANT_TURN_V120 = "goal_done_missing_assistant_turn_v120"
+FAIL_REASON_GOAL_DONE_MISSING_PROGRESS_PROOF_V120 = "goal_done_missing_progress_proof_v120"
+FAIL_REASON_GOAL_DONE_BEFORE_HORIZON_V120 = "goal_done_before_horizon_v120"
+
+
+@dataclass(frozen=True)
+class GoalPersistenceResultV120:
+    ok: bool
+    reason: str
+    details: Dict[str, Any]
+
+
+def _read_jsonl(path: str) -> List[Dict[str, Any]]:
+    out: List[Dict[str, Any]] = []
+    if not os.path.exists(path):
+        return out
+    with open(path, "r", encoding="utf-8") as f:
+        for line in f:
+            line = line.strip()
+            if not line:
+                continue
+            out.append(json.loads(line))
+    return out
+
+
+def _payload_view(rows: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
+    out: List[Dict[str, Any]] = []
+    for r in rows:
+        if not isinstance(r, dict):
+            continue
+        payload = r.get("payload")
+        if isinstance(payload, dict):
+            out.append(dict(payload))
+    return out
+
+
+def _assistant_by_user_turn_index(conversation_turn_payloads: List[Dict[str, Any]]) -> Dict[int, Dict[str, Any]]:
+    """
+    conversation_turns.jsonl turn_index is global across both roles.
+    For a user turn at index i (even), the assistant reply (if present) is typically at i+1.
+    """
+    by_idx: Dict[int, Dict[str, Any]] = {}
+    for p in conversation_turn_payloads:
+        if not isinstance(p, dict):
+            continue
+        if str(p.get("role") or "") != "assistant":
+            continue
+        try:
+            ti = int(p.get("turn_index", -1))
+        except Exception:
+            continue
+        if ti >= 0 and ti not in by_idx:
+            by_idx[int(ti)] = dict(p)
+    return dict(by_idx)
+
+
+_PROGRESS_RE = re.compile(r"(?P<step>\d+)\s*/\s*(?P<total>\d+)")
+
+
+def _progress_proof_from_text(text: str) -> Tuple[bool, str, Dict[str, Any]]:
+    """
+    Deterministic proof for a system-closed goal:
+    expects a visible "<step>/<total>" marker in the assistant text.
+    """
+    m = _PROGRESS_RE.search(str(text or ""))
+    if not m:
+        return False, "missing_progress_marker", {}
+    try:
+        step = int(m.group("step"))
+        total = int(m.group("total"))
+    except Exception:
+        return False, "bad_progress_marker", {}
+    if total <= 0:
+        return False, "bad_progress_total", {"step": int(step), "total": int(total)}
+    return True, "ok", {"step": int(step), "total": int(total)}
+
+
+def verify_goal_persistence_law_v120(*, run_dir: str, expected_autopilot_total_steps: Optional[int]) -> GoalPersistenceResultV120:
+    """
+    V120 goal persistence law (minimal, deterministic):
+      - goal_events.jsonl must exist + be chain-valid (v96 chain).
+      - every goal event must have a valid v99 event_sig/event_id.
+      - any GOAL_DONE with cause_type=="system" must have a deterministic progress proof in the assistant text:
+          * a "<step>/<total>" marker exists, and
+          * step >= total, and
+          * if expected_autopilot_total_steps is provided: total == expected.
+    """
+    rd = str(run_dir)
+    goal_events_path = os.path.join(rd, "goal_events.jsonl")
+    turns_path = os.path.join(rd, "conversation_turns.jsonl")
+
+    if not os.path.exists(goal_events_path):
+        return GoalPersistenceResultV120(ok=False, reason=FAIL_REASON_MISSING_GOAL_EVENTS_V120, details={"goal_events_path": str(goal_events_path)})
+    if not bool(verify_chained_jsonl_v96(str(goal_events_path))):
+        return GoalPersistenceResultV120(ok=False, reason=FAIL_REASON_GOAL_EVENTS_CHAIN_INVALID_V120, details={"goal_events_path": str(goal_events_path)})
+
+    rows = _read_jsonl(goal_events_path)
+    payloads = _payload_view(rows)
+    bad_sig: List[Dict[str, Any]] = []
+    for ev in payloads:
+        ok_sig, reason_sig, det_sig = verify_goal_event_sig_v99(dict(ev))
+        if not bool(ok_sig):
+            bad_sig.append({"reason": str(reason_sig), "details": dict(det_sig)})
+    if bad_sig:
+        return GoalPersistenceResultV120(ok=False, reason=FAIL_REASON_GOAL_EVENT_SIG_INVALID_V120, details={"bad_sig": list(bad_sig)})
+
+    # Build assistant turn lookup.
+    turn_rows = _read_jsonl(turns_path)
+    turn_payloads = _payload_view(turn_rows)
+    assistant_by_idx = _assistant_by_user_turn_index(turn_payloads)
+
+    violations: List[Dict[str, Any]] = []
+    done_checked: List[Dict[str, Any]] = []
+    expected_total = int(expected_autopilot_total_steps) if expected_autopilot_total_steps is not None else None
+
+    for ev in payloads:
+        if str(ev.get("op") or "") != "GOAL_DONE":
+            continue
+        cause = ev.get("cause") if isinstance(ev.get("cause"), dict) else {}
+        cause_type = str(cause.get("cause_type") or "")
+        if cause_type != "system":
+            continue
+        try:
+            ts_turn_index = int(ev.get("ts_turn_index", -1))
+        except Exception:
+            ts_turn_index = -1
+        assistant_turn = assistant_by_idx.get(int(ts_turn_index + 1)) if ts_turn_index >= 0 else None
+        if not isinstance(assistant_turn, dict):
+            violations.append({"reason": FAIL_REASON_GOAL_DONE_MISSING_ASSISTANT_TURN_V120, "ts_turn_index": int(ts_turn_index)})
+            continue
+        ok_pf, pf_reason, pf_details = _progress_proof_from_text(str(assistant_turn.get("text") or ""))
+        if not bool(ok_pf):
+            violations.append(
+                {
+                    "reason": FAIL_REASON_GOAL_DONE_MISSING_PROGRESS_PROOF_V120,
+                    "ts_turn_index": int(ts_turn_index),
+                    "proof_reason": str(pf_reason),
+                }
+            )
+            continue
+        step = int(pf_details.get("step", 0) or 0)
+        total = int(pf_details.get("total", 0) or 0)
+        if int(step) < int(total):
+            violations.append(
+                {
+                    "reason": FAIL_REASON_GOAL_DONE_BEFORE_HORIZON_V120,
+                    "ts_turn_index": int(ts_turn_index),
+                    "step": int(step),
+                    "total": int(total),
+                }
+            )
+            continue
+        if expected_total is not None and int(total) != int(expected_total):
+            violations.append(
+                {
+                    "reason": FAIL_REASON_GOAL_DONE_BEFORE_HORIZON_V120,
+                    "ts_turn_index": int(ts_turn_index),
+                    "step": int(step),
+                    "total": int(total),
+                    "expected_total": int(expected_total),
+                }
+            )
+            continue
+        done_checked.append({"ts_turn_index": int(ts_turn_index), "step": int(step), "total": int(total)})
+
+    ok = len(violations) == 0
+    reason = "ok" if ok else str(violations[0].get("reason") or "violations")
+    details = {
+        "schema_version": 120,
+        "kind": "goal_persistence_law_v120_result",
+        "ok": bool(ok),
+        "reason": str(reason),
+        "expected_autopilot_total_steps": int(expected_total) if expected_total is not None else None,
+        "system_goal_done_checked": list(done_checked),
+        "violations": list(violations),
+    }
+    return GoalPersistenceResultV120(ok=bool(ok), reason=str(reason), details=dict(details))
+
+
+def write_goal_persistence_summary_v120(*, run_dir: str, expected_autopilot_total_steps: Optional[int]) -> Dict[str, Any]:
+    """
+    Write-once summary artifact: goal_persistence_summary_v120.json (deterministic).
+    """
+    res = verify_goal_persistence_law_v120(run_dir=str(run_dir), expected_autopilot_total_steps=expected_autopilot_total_steps)
+    body = dict(res.details)
+    body["summary_sig"] = sha256_hex(canonical_json_dumps(body).encode("utf-8"))
+    path = os.path.join(str(run_dir), "goal_persistence_summary_v120.json")
+    if os.path.exists(path):
+        raise ValueError(f"worm_exists:{path}")
+    tmp = path + ".tmp"
+    if os.path.exists(tmp):
+        raise ValueError(f"tmp_exists:{tmp}")
+    with open(tmp, "w", encoding="utf-8") as f:
+        f.write(json.dumps(body, ensure_ascii=False, indent=2, sort_keys=True))
+        f.write("\n")
+    os.replace(tmp, path)
+    return dict(body)
--- /dev/null	2026-01-16 10:10:11
+++ scripts/smoke_v120_goal_survival_100_turns.py	2026-01-16 10:09:34
@@ -0,0 +1,249 @@
+#!/usr/bin/env python3
+from __future__ import annotations
+
+import argparse
+import hashlib
+import json
+import os
+import shutil
+import sys
+from pathlib import Path
+from typing import Any, Dict, List, Tuple
+
+sys.path.insert(0, os.path.dirname(os.path.dirname(__file__)))
+
+from atos_core.act import canonical_json_dumps, sha256_hex
+from atos_core.conversation_loop_v120 import run_conversation_v120
+from atos_core.goal_persistence_law_v120 import (
+    FAIL_REASON_GOAL_DONE_BEFORE_HORIZON_V120,
+    verify_goal_persistence_law_v120,
+)
+
+
+def _fail(msg: str, *, code: int = 2) -> None:
+    print(msg, file=sys.stderr)
+    raise SystemExit(code)
+
+
+def _ensure_absent(path: Path) -> None:
+    if path.exists():
+        _fail(f"worm_exists:{path}")
+
+
+def _sha256_file(path: Path) -> str:
+    h = hashlib.sha256()
+    with open(path, "rb") as f:
+        while True:
+            b = f.read(1024 * 1024)
+            if not b:
+                break
+            h.update(b)
+    return h.hexdigest()
+
+
+def _write_once_json(path: Path, obj: Any) -> None:
+    _ensure_absent(path)
+    tmp = path.with_suffix(path.suffix + ".tmp")
+    if tmp.exists():
+        _fail(f"tmp_exists:{tmp}")
+    tmp.write_text(json.dumps(obj, ensure_ascii=False, indent=2, sort_keys=True) + "\n", encoding="utf-8")
+    os.replace(str(tmp), str(path))
+
+
+def _read_json(path: Path) -> Any:
+    return json.loads(path.read_text(encoding="utf-8"))
+
+
+def _read_jsonl(path: Path) -> List[Dict[str, Any]]:
+    out: List[Dict[str, Any]] = []
+    if not path.exists():
+        return out
+    for line in path.read_text(encoding="utf-8").splitlines():
+        line = line.strip()
+        if not line:
+            continue
+        out.append(json.loads(line))
+    return out
+
+
+def _payload_view(rows: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
+    out: List[Dict[str, Any]] = []
+    for r in rows:
+        if not isinstance(r, dict):
+            continue
+        payload = r.get("payload")
+        if isinstance(payload, dict):
+            out.append(dict(payload))
+    return out
+
+
+def _find_goal_done_system(goal_events_payloads: List[Dict[str, Any]]) -> Tuple[str, int]:
+    for ev in goal_events_payloads:
+        if not isinstance(ev, dict):
+            continue
+        if str(ev.get("op") or "") != "GOAL_DONE":
+            continue
+        cause = ev.get("cause") if isinstance(ev.get("cause"), dict) else {}
+        if str(cause.get("cause_type") or "") != "system":
+            continue
+        gid = str(ev.get("goal_id") or "")
+        try:
+            ts = int(ev.get("ts_turn_index", -1))
+        except Exception:
+            ts = -1
+        if gid and ts >= 0:
+            return str(gid), int(ts)
+    return "", -1
+
+
+def _smoke_once(*, out_dir: Path, seed: int, total_steps: int) -> Dict[str, Any]:
+    _ensure_absent(out_dir)
+    # Pre-fill required goal slots deterministically so V110 autopilot can advance without over-clarifying.
+    user_turns = ["goal: preparar demo; outcome=ok; constraints=none; deadline=none"] + ["ok"] * int(total_steps) + ["end now"]
+    run_conversation_v120(
+        user_turn_texts=list(user_turns),
+        out_dir=str(out_dir),
+        seed=int(seed),
+        goal_autopilot_total_steps=int(total_steps),
+    )
+
+    gps_path = out_dir / "goal_persistence_summary_v120.json"
+    gps = _read_json(gps_path)
+    if not isinstance(gps, dict) or not bool(gps.get("ok", False)):
+        _fail(f"goal_persistence_fail:{(gps.get('reason') if isinstance(gps, dict) else 'missing')}")
+
+    goal_rows = _read_jsonl(out_dir / "goal_events.jsonl")
+    goal_payloads = _payload_view(goal_rows)
+    done_goal_id, done_ts = _find_goal_done_system(goal_payloads)
+    if not done_goal_id or done_ts < 0:
+        _fail("missing_system_goal_done_event")
+
+    checked = gps.get("system_goal_done_checked") if isinstance(gps.get("system_goal_done_checked"), list) else []
+    checked0 = checked[0] if checked and isinstance(checked[0], dict) else {}
+    step = int(checked0.get("step", 0) or 0)
+    total = int(checked0.get("total", 0) or 0)
+    if int(total) != int(total_steps) or int(step) != int(total_steps):
+        _fail("goal_done_proof_mismatch")
+
+    eval_obj = {
+        "schema_version": 120,
+        "kind": "smoke_v120_goal_survival_100_turns_eval",
+        "seed": int(seed),
+        "goal_autopilot_total_steps": int(total_steps),
+        "goal_done": {"goal_id": str(done_goal_id), "ts_turn_index": int(done_ts), "proof": {"step": int(step), "total": int(total)}},
+        "goal_persistence_ok": True,
+        "final_ok": bool((_read_json(out_dir / "final_response_v120.json") or {}).get("ok", False)),
+    }
+    eval_obj["eval_sig"] = sha256_hex(canonical_json_dumps(eval_obj).encode("utf-8"))
+    _write_once_json(out_dir / "eval.json", eval_obj)
+
+    core = {
+        "seed": int(seed),
+        "goal_autopilot_total_steps": int(total_steps),
+        "goal_done": {"goal_id": str(done_goal_id), "ts_turn_index": int(done_ts), "proof": {"step": int(step), "total": int(total)}},
+        "eval_sha256": _sha256_file(out_dir / "eval.json"),
+    }
+    summary_sha256 = sha256_hex(canonical_json_dumps(core).encode("utf-8"))
+    summary = {"schema_version": 120, "kind": "smoke_v120_goal_survival_100_turns_summary", "core": dict(core), "summary_sha256": str(summary_sha256)}
+    _write_once_json(out_dir / "smoke_summary.json", summary)
+
+    return {"core": dict(core), "summary_sha256": str(summary_sha256)}
+
+
+def _tamper_progress_proof(*, src_dir: Path, dst_dir: Path, total_steps: int) -> None:
+    _ensure_absent(dst_dir)
+    shutil.copytree(str(src_dir), str(dst_dir), dirs_exist_ok=False)
+    turns_path = dst_dir / "conversation_turns.jsonl"
+    rows = _read_jsonl(turns_path)
+    payloads = _payload_view(rows)
+
+    # Find the assistant turn that corresponds to the system GOAL_DONE event (ts_turn_index+1),
+    # and corrupt its "<step>/<total>" marker (without touching chains elsewhere).
+    goal_rows = _read_jsonl(dst_dir / "goal_events.jsonl")
+    goal_payloads = _payload_view(goal_rows)
+    _gid, done_ts = _find_goal_done_system(goal_payloads)
+    if int(done_ts) < 0:
+        _fail("tamper_missing_system_goal_done_event")
+    target_turn_index = int(done_ts) + 1
+    target_assistant = None
+    for p in payloads:
+        if not isinstance(p, dict) or str(p.get("role") or "") != "assistant":
+            continue
+        try:
+            ti = int(p.get("turn_index", -1))
+        except Exception:
+            ti = -1
+        if int(ti) == int(target_turn_index):
+            target_assistant = p
+            break
+    if not isinstance(target_assistant, dict):
+        _fail("tamper_missing_goal_done_assistant_turn")
+
+    txt = str(target_assistant.get("text") or "")
+    want = f"{int(total_steps)}/{int(total_steps)}"
+    got = f"{int(total_steps - 1)}/{int(total_steps)}"
+    if want not in txt:
+        _fail("tamper_missing_progress_marker")
+    target_assistant["text"] = txt.replace(want, got, 1)
+    # Rewrite conversation_turns.jsonl WITHOUT trying to preserve its chain; this is only for verifier negative coverage.
+    # We keep it simple: the goal persistence verifier uses this file only as a text source.
+    out_lines: List[str] = []
+    for r in rows:
+        if not isinstance(r, dict):
+            continue
+        payload = r.get("payload")
+        if isinstance(payload, dict) and str(payload.get("turn_id") or "") == str(target_assistant.get("turn_id") or ""):
+            r2 = dict(r)
+            r2["payload"] = dict(target_assistant)
+            out_lines.append(json.dumps(r2, ensure_ascii=False, sort_keys=True))
+        else:
+            out_lines.append(json.dumps(r, ensure_ascii=False, sort_keys=True))
+    turns_path.write_text("\n".join(out_lines) + "\n", encoding="utf-8")
+
+
+def main() -> None:
+    ap = argparse.ArgumentParser()
+    ap.add_argument("--out_base", required=True)
+    ap.add_argument("--seed", required=True, type=int)
+    ap.add_argument("--total_steps", type=int, default=100)
+    args = ap.parse_args()
+
+    out_base = str(args.out_base)
+    seed = int(args.seed)
+    total_steps = int(args.total_steps)
+
+    r1 = _smoke_once(out_dir=Path(out_base + "_try1"), seed=seed, total_steps=total_steps)
+    r2 = _smoke_once(out_dir=Path(out_base + "_try2"), seed=seed, total_steps=total_steps)
+
+    if canonical_json_dumps(r1["core"]) != canonical_json_dumps(r2["core"]):
+        _fail("determinism_core_mismatch")
+    if str(r1["summary_sha256"]) != str(r2["summary_sha256"]):
+        _fail("determinism_summary_sha256_mismatch")
+
+    # Negative tamper: corrupt progress proof and require the goal persistence verifier to fail with a stable reason.
+    tamper_dir = Path(out_base + "_try1_tamper")
+    _tamper_progress_proof(src_dir=Path(out_base + "_try1"), dst_dir=tamper_dir, total_steps=total_steps)
+    res = verify_goal_persistence_law_v120(run_dir=str(tamper_dir), expected_autopilot_total_steps=int(total_steps))
+    if bool(res.ok):
+        _fail("tamper_expected_fail_but_ok")
+    if str(res.reason) != str(FAIL_REASON_GOAL_DONE_BEFORE_HORIZON_V120):
+        _fail(f"tamper_reason_mismatch:{res.reason}")
+
+    print(
+        json.dumps(
+            {
+                "ok": True,
+                "determinism_ok": True,
+                "summary_sha256": str(r1["summary_sha256"]),
+                "out_try1": str(out_base + "_try1"),
+                "out_try2": str(out_base + "_try2"),
+                "tamper_reason": str(res.reason),
+            },
+            ensure_ascii=False,
+            sort_keys=True,
+        )
+    )
+
+
+if __name__ == "__main__":
+    main()
--- /dev/null	2026-01-16 10:10:11
+++ tests/test_goal_persistence_law_v120.py	2026-01-16 10:05:49
@@ -0,0 +1,124 @@
+import json
+import os
+import tempfile
+import unittest
+
+from atos_core.conversation_v96 import append_chained_jsonl_v96
+from atos_core.goal_ledger_v99 import GoalEventV99, goal_id_v99
+from atos_core.goal_persistence_law_v120 import (
+    FAIL_REASON_GOAL_DONE_BEFORE_HORIZON_V120,
+    FAIL_REASON_GOAL_DONE_MISSING_PROGRESS_PROOF_V120,
+    FAIL_REASON_MISSING_GOAL_EVENTS_V120,
+    verify_goal_persistence_law_v120,
+)
+
+
+def _write_jsonl(path: str, rows) -> None:
+    with open(path, "w", encoding="utf-8") as f:
+        for r in rows:
+            f.write(json.dumps(r, ensure_ascii=False, sort_keys=True))
+            f.write("\n")
+
+
+def _write_goal_events(*, run_dir: str, goal_id: str, done_ts_turn_index: int, created_step: int) -> None:
+    goal_path = os.path.join(str(run_dir), "goal_events.jsonl")
+    prev_hash = None
+    prev_sig = ""
+
+    ev_add = GoalEventV99(
+        conversation_id="conv_test",
+        ts_turn_index=0,
+        op="GOAL_ADD",
+        goal_id=str(goal_id),
+        parent_goal_id="",
+        priority=100,
+        status="active",
+        text="demo",
+        cause_type="user_intent",
+        cause_id="turn0",
+        created_step=int(created_step),
+        prev_event_sig=str(prev_sig),
+    ).to_dict()
+    prev_hash = append_chained_jsonl_v96(
+        goal_path,
+        {"time": ev_add.get("created_at"), "step": int(created_step), "event": "GOAL_EVENT", "payload": dict(ev_add)},
+        prev_hash=prev_hash,
+    )
+    prev_sig = str(ev_add.get("event_sig") or "")
+
+    ev_done = GoalEventV99(
+        conversation_id="conv_test",
+        ts_turn_index=int(done_ts_turn_index),
+        op="GOAL_DONE",
+        goal_id=str(goal_id),
+        parent_goal_id="",
+        priority=100,
+        status="done",
+        text="demo",
+        cause_type="system",
+        cause_id="turn_done",
+        created_step=int(created_step + 1),
+        prev_event_sig=str(prev_sig),
+    ).to_dict()
+    append_chained_jsonl_v96(
+        goal_path,
+        {"time": ev_done.get("created_at"), "step": int(created_step + 1), "event": "GOAL_EVENT", "payload": dict(ev_done)},
+        prev_hash=prev_hash,
+    )
+
+
+class TestGoalPersistenceLawV120(unittest.TestCase):
+    def test_missing_goal_events_fails(self) -> None:
+        with tempfile.TemporaryDirectory() as td:
+            res = verify_goal_persistence_law_v120(run_dir=str(td), expected_autopilot_total_steps=5)
+            self.assertFalse(res.ok)
+            self.assertEqual(res.reason, FAIL_REASON_MISSING_GOAL_EVENTS_V120)
+
+    def test_ok_with_valid_progress_marker(self) -> None:
+        with tempfile.TemporaryDirectory() as td:
+            goal_id = goal_id_v99(conversation_id="conv_test", ts_turn_index=0, text="demo", parent_goal_id="")
+            _write_goal_events(run_dir=str(td), goal_id=str(goal_id), done_ts_turn_index=0, created_step=0)
+            turns_path = os.path.join(str(td), "conversation_turns.jsonl")
+            _write_jsonl(
+                turns_path,
+                [
+                    {"payload": {"role": "user", "turn_index": 0, "text": "ok"}},
+                    {"payload": {"role": "assistant", "turn_index": 1, "text": "AVANÇO 5/5: demo"}},
+                ],
+            )
+            res = verify_goal_persistence_law_v120(run_dir=str(td), expected_autopilot_total_steps=5)
+            self.assertTrue(res.ok)
+            self.assertEqual(res.reason, "ok")
+
+    def test_fail_when_step_less_than_total(self) -> None:
+        with tempfile.TemporaryDirectory() as td:
+            goal_id = goal_id_v99(conversation_id="conv_test", ts_turn_index=0, text="demo", parent_goal_id="")
+            _write_goal_events(run_dir=str(td), goal_id=str(goal_id), done_ts_turn_index=0, created_step=0)
+            turns_path = os.path.join(str(td), "conversation_turns.jsonl")
+            _write_jsonl(
+                turns_path,
+                [
+                    {"payload": {"role": "user", "turn_index": 0, "text": "ok"}},
+                    {"payload": {"role": "assistant", "turn_index": 1, "text": "AVANÇO 4/5: demo"}},
+                ],
+            )
+            res = verify_goal_persistence_law_v120(run_dir=str(td), expected_autopilot_total_steps=5)
+            self.assertFalse(res.ok)
+            self.assertEqual(res.reason, FAIL_REASON_GOAL_DONE_BEFORE_HORIZON_V120)
+
+    def test_fail_when_missing_progress_marker(self) -> None:
+        with tempfile.TemporaryDirectory() as td:
+            goal_id = goal_id_v99(conversation_id="conv_test", ts_turn_index=0, text="demo", parent_goal_id="")
+            _write_goal_events(run_dir=str(td), goal_id=str(goal_id), done_ts_turn_index=0, created_step=0)
+            turns_path = os.path.join(str(td), "conversation_turns.jsonl")
+            _write_jsonl(
+                turns_path,
+                [
+                    {"payload": {"role": "user", "turn_index": 0, "text": "ok"}},
+                    {"payload": {"role": "assistant", "turn_index": 1, "text": "done"}},
+                ],
+            )
+            res = verify_goal_persistence_law_v120(run_dir=str(td), expected_autopilot_total_steps=5)
+            self.assertFalse(res.ok)
+            self.assertEqual(res.reason, FAIL_REASON_GOAL_DONE_MISSING_PROGRESS_PROOF_V120)
+
