--- patches/v53_active_gate_compare_base/engine.py	2026-01-11 10:24:02
+++ atos_core/engine.py	2026-01-11 10:27:09
@@ -37,6 +37,9 @@
     disable_macro_router: bool = False
     # Proof mode: compute baseline + gate per token, count mismatches, and fall back to baseline.
     router_live_debug_compare: bool = False
+    # Force-gate proof mode (default OFF): compare baseline (all predictors) vs forced-gate
+    # (force_predictor_ids / force_predictor_ids_by_ctx_sig) and fall back to baseline on mismatch.
+    force_gate_debug_compare: bool = False
     # Force evaluation of only these predictor act_ids (default OFF). Applies only to n-gram
     # predictors and only when `predictors` is not passed explicitly to `_emit_candidates`.
     force_predictor_ids: Optional[List[str]] = None
@@ -459,6 +462,19 @@
         trace_instruction_contract_used: List[int] = []
         trace_instruction_contract_kind: List[str] = []
         trace_instruction_contract_reason: List[str] = []
+        trace_force_gate_used: List[int] = []
+        trace_force_gate_fallback: List[int] = []
+        trace_force_gate_fallback_reason: List[str] = []
+        trace_force_gate_allowed_size: List[int] = []
+        trace_force_gate_predictors_iterated: List[int] = []
+        trace_force_gate_predictors_matched: List[int] = []
+        trace_force_gate_predictors_emitted: List[int] = []
+        trace_force_gate_baseline_predictors_iterated: List[int] = []
+        trace_force_gate_baseline_predictors_matched: List[int] = []
+        trace_force_gate_baseline_predictors_emitted: List[int] = []
+        trace_force_gate_mismatch: List[int] = []
+        trace_force_gate_debug_baseline_token: List[str] = []
+        trace_force_gate_debug_gate_token: List[str] = []
 
         mode_state = "default"
         mode_act_id: Optional[str] = None
@@ -1214,6 +1230,19 @@
                 trace_instruction_contract_used.append(1)
                 trace_instruction_contract_kind.append(str(contract_kind))
                 trace_instruction_contract_reason.append(str(contract_reason))
+                trace_force_gate_used.append(0)
+                trace_force_gate_fallback.append(0)
+                trace_force_gate_fallback_reason.append("")
+                trace_force_gate_allowed_size.append(0)
+                trace_force_gate_predictors_iterated.append(0)
+                trace_force_gate_predictors_matched.append(0)
+                trace_force_gate_predictors_emitted.append(0)
+                trace_force_gate_baseline_predictors_iterated.append(0)
+                trace_force_gate_baseline_predictors_matched.append(0)
+                trace_force_gate_baseline_predictors_emitted.append(0)
+                trace_force_gate_mismatch.append(0)
+                trace_force_gate_debug_baseline_token.append("")
+                trace_force_gate_debug_gate_token.append("")
 
                 trace_selected_act_ids.append(str(contract_act_id or "__contract__"))
                 trace_selected_tokens.append(str(nxt))
@@ -1235,6 +1264,165 @@
 
                 if contract_pos >= len(contract_tokens):
                     break
+                continue
+
+            force_gate_compare = bool(self.config.force_gate_debug_compare) and (
+                (isinstance(self.config.force_predictor_ids, list) and bool(self.config.force_predictor_ids))
+                or (
+                    isinstance(self.config.force_predictor_ids_by_ctx_sig, dict)
+                    and bool(self.config.force_predictor_ids_by_ctx_sig)
+                )
+            )
+            if force_gate_compare:
+                allowed_size = 0
+                try:
+                    forced = self.config.force_predictor_ids
+                    if isinstance(forced, list) and forced:
+                        allowed_size = len(
+                            {str(x) for x in forced if isinstance(x, str) and str(x)}
+                        )
+                    else:
+                        by_ctx = self.config.force_predictor_ids_by_ctx_sig
+                        if isinstance(by_ctx, dict) and by_ctx:
+                            sig = f"{mode_state}{SEP}{ck}"
+                            ids = by_ctx.get(sig)
+                            if isinstance(ids, list) and ids:
+                                allowed_size = len(
+                                    {str(x) for x in ids if isinstance(x, str) and str(x)}
+                                )
+                except Exception:
+                    allowed_size = 0
+
+                emit_base_cmp: Dict[str, Any] = {}
+                cand_base_cmp = self._emit_candidates(
+                    context=context,
+                    penalties=penalties,
+                    predictors=self._predictors,
+                    trace=emit_base_cmp,
+                )
+                emit_gate_cmp: Dict[str, Any] = {}
+                cand_gate_cmp = self._emit_candidates(
+                    context=context, penalties=penalties, trace=emit_gate_cmp
+                )
+
+                base_after, rr_hits_base = _apply_rewrite_rules(
+                    cand_base_cmp, context=context, penalties=penalties
+                )
+                gate_after, _rr_hits_gate = _apply_rewrite_rules(
+                    cand_gate_cmp, context=context, penalties=penalties
+                )
+
+                if i < self.config.min_new_tokens_before_eos:
+                    if "<EOS>" in base_after:
+                        base_after["<EOS>"].score -= 1e6
+                    if "<EOS>" in gate_after:
+                        gate_after["<EOS>"].score -= 1e6
+
+                rng_state0 = self.rng.getstate()
+                b_nxt = _select_next_fluency(base_after, context=context, penalties=penalties)
+                rng_state1 = self.rng.getstate()
+                try:
+                    self.rng.setstate(rng_state0)
+                    g_nxt = _select_next_fluency(gate_after, context=context, penalties=penalties)
+                finally:
+                    self.rng.setstate(rng_state1)
+
+                if b_nxt is None or b_nxt == "<EOS>":
+                    break
+
+                mismatch = bool(g_nxt != b_nxt)
+                covered = bool(allowed_size > 0)
+                fallback = bool(mismatch or (not covered))
+                if not covered:
+                    fallback_reason = "missing_ctx"
+                else:
+                    fallback_reason = "mismatch" if mismatch else ""
+
+                exec_pred = emit_base_cmp.get("executed_predictor_ids") or []
+                exec_pred_ids: List[str] = []
+                if isinstance(exec_pred, list):
+                    exec_pred_ids = [str(x) for x in exec_pred if isinstance(x, str)]
+
+                pred_iter = int(emit_base_cmp.get("predictor_iterated", 0) or 0)
+                pred_mat = int(emit_base_cmp.get("predictor_matched", 0) or 0)
+                pred_emit = int(emit_base_cmp.get("predictor_emitted", 0) or 0)
+                cand_pre = int(
+                    emit_base_cmp.get("candidates_pre_rewrite", len(cand_base_cmp)) or 0
+                )
+
+                gate_iter = int(emit_gate_cmp.get("predictor_iterated", 0) or 0)
+                gate_mat = int(emit_gate_cmp.get("predictor_matched", 0) or 0)
+                gate_emit = int(emit_gate_cmp.get("predictor_emitted", 0) or 0)
+
+                candidates = base_after
+                nxt = str(b_nxt)
+                src_act = candidates.get(nxt).source_act if nxt in candidates else "__unknown__"
+
+                trace_context_keys.append(ck)
+                trace_executed_predictor_ids.append(exec_pred_ids)
+                trace_rewrite_rule_hit_ids.append(rr_hits_base)
+                trace_rewrite_rules_changed_count.append(int(len(rr_hits_base)))
+
+                trace_predictor_iterated.append(pred_iter)
+                trace_predictor_matched.append(pred_mat)
+                trace_predictor_emitted.append(pred_emit)
+                trace_candidates_pre.append(cand_pre)
+                trace_candidates_post.append(int(len(candidates)))
+
+                trace_router_live_used.append(0)
+                trace_router_live_fallback.append(0)
+                trace_router_live_fallback_reason.append("")
+                trace_router_live_allowed_predictor_ids.append([])
+                trace_router_live_predictors_iterated.append(pred_iter)
+                trace_router_live_predictors_matched.append(pred_mat)
+                trace_router_live_predictors_emitted.append(pred_emit)
+                trace_baseline_predictors_iterated.append(0)
+                trace_baseline_predictors_matched.append(0)
+                trace_baseline_predictors_emitted.append(0)
+                trace_router_live_mismatch.append(0)
+                trace_router_live_debug_baseline_token.append("")
+                trace_router_live_debug_gate_token.append("")
+
+                trace_instruction_contract_used.append(0)
+                trace_instruction_contract_kind.append("")
+                trace_instruction_contract_reason.append("")
+
+                trace_force_gate_used.append(1 if covered else 0)
+                trace_force_gate_fallback.append(1 if fallback else 0)
+                trace_force_gate_fallback_reason.append(str(fallback_reason))
+                trace_force_gate_allowed_size.append(int(allowed_size))
+                trace_force_gate_predictors_iterated.append(int(gate_iter))
+                trace_force_gate_predictors_matched.append(int(gate_mat))
+                trace_force_gate_predictors_emitted.append(int(gate_emit))
+                trace_force_gate_baseline_predictors_iterated.append(int(pred_iter))
+                trace_force_gate_baseline_predictors_matched.append(int(pred_mat))
+                trace_force_gate_baseline_predictors_emitted.append(int(pred_emit))
+                trace_force_gate_mismatch.append(1 if mismatch else 0)
+                trace_force_gate_debug_baseline_token.append(str(b_nxt or ""))
+                trace_force_gate_debug_gate_token.append(str(g_nxt or ""))
+
+                trace_selected_act_ids.append(str(src_act))
+                trace_selected_tokens.append(str(nxt))
+
+                gen_tokens.append(nxt)
+                if nxt not in {"<EOS>", "<BOS>"} and (not is_space(nxt)):
+                    turn_non_ws.append(nxt)
+                    if NO_REPEAT_NGRAM >= 2 and len(turn_non_ws) >= NO_REPEAT_NGRAM:
+                        seen_turn_ngrams.add(tuple(turn_non_ws[-NO_REPEAT_NGRAM:]))
+
+                filtered = [x for x in (out_tokens + gen_tokens) if x not in {"<BOS>"}]
+                n = self.config.cycle_ngram
+                if len(filtered) >= n:
+                    ng = tuple(filtered[-n:])
+                    history_ngrams.append(ng)
+                    history_ngram_set.add(ng)
+                    if len(history_ngrams) > self.config.cycle_history:
+                        old = history_ngrams.pop(0)
+                        if old not in history_ngrams:
+                            history_ngram_set.discard(old)
+
+                context.append(nxt)
+                context = context[-(self.config.max_order - 1) :]
                 continue
 
             router_live_enabled = bool(self.config.router_live_enabled) and not bool(
@@ -1438,6 +1626,19 @@
             trace_instruction_contract_used.append(0)
             trace_instruction_contract_kind.append("")
             trace_instruction_contract_reason.append("")
+            trace_force_gate_used.append(0)
+            trace_force_gate_fallback.append(0)
+            trace_force_gate_fallback_reason.append("")
+            trace_force_gate_allowed_size.append(0)
+            trace_force_gate_predictors_iterated.append(0)
+            trace_force_gate_predictors_matched.append(0)
+            trace_force_gate_predictors_emitted.append(0)
+            trace_force_gate_baseline_predictors_iterated.append(0)
+            trace_force_gate_baseline_predictors_matched.append(0)
+            trace_force_gate_baseline_predictors_emitted.append(0)
+            trace_force_gate_mismatch.append(0)
+            trace_force_gate_debug_baseline_token.append("")
+            trace_force_gate_debug_gate_token.append("")
 
             trace_selected_act_ids.append(str(src_act))
             trace_selected_tokens.append(str(nxt))
@@ -1521,6 +1722,19 @@
                 "instruction_contract_used": trace_instruction_contract_used,
                 "instruction_contract_kind": trace_instruction_contract_kind,
                 "instruction_contract_reason": trace_instruction_contract_reason,
+                "force_gate_used": trace_force_gate_used,
+                "force_gate_fallback": trace_force_gate_fallback,
+                "force_gate_fallback_reason": trace_force_gate_fallback_reason,
+                "force_gate_allowed_size": trace_force_gate_allowed_size,
+                "force_gate_predictors_iterated": trace_force_gate_predictors_iterated,
+                "force_gate_predictors_matched": trace_force_gate_predictors_matched,
+                "force_gate_predictors_emitted": trace_force_gate_predictors_emitted,
+                "force_gate_baseline_predictors_iterated": trace_force_gate_baseline_predictors_iterated,
+                "force_gate_baseline_predictors_matched": trace_force_gate_baseline_predictors_matched,
+                "force_gate_baseline_predictors_emitted": trace_force_gate_baseline_predictors_emitted,
+                "force_gate_mismatch": trace_force_gate_mismatch,
+                "force_gate_debug_baseline_token": trace_force_gate_debug_baseline_token,
+                "force_gate_debug_gate_token": trace_force_gate_debug_gate_token,
                 "subgraph": {
                     "executed_predictor_act_ids": exec_pred_unique,
                     "rewrite_rule_hit_ids": rr_hit_unique,
--- patches/v53_active_gate_compare_base/csv_loop_active_gate_demo.py	2026-01-11 10:24:02
+++ scripts/csv_loop_active_gate_demo.py	2026-01-11 10:29:22
@@ -301,6 +301,8 @@
     ap.add_argument("--suite", choices=["chat", "skill"], default="chat")
     ap.add_argument("--enable_contracts", action="store_true")
     ap.add_argument("--no_router", action="store_true", help="Disable macro_router usage (baseline high mode)")
+    ap.add_argument("--active_gate_top_k", type=int, default=2)
+    ap.add_argument("--active_gate_mode", choices=["compare", "real"], default="compare")
     args = ap.parse_args()
 
     acts_path = os.path.join(str(args.run), "acts.jsonl")
@@ -374,17 +376,17 @@
     if not invariance_ok:
         raise SystemExit("OUTPUT_INVARIANCE_FAILED: sha256(baseline)!=sha256(shadow)")
 
-    # 3) Active: build a ctx_sig -> topK predictors gate table from the baseline trace and
-    # apply it as a per-token predictor allowlist. Divergence is allowed.
-    gate_top_k = 2
+    # 3) Build a ctx_sig -> topK predictors gate table from the baseline trace.
+    gate_top_k = max(1, int(args.active_gate_top_k))
     gate_table: Dict[str, List[str]] = {}
     gate_table_path = ""
     gate_stats_base = CtxGateStats()
-    gate_stats_active = CtxGateStats()
+    gate_stats_compare = CtxGateStats()
+    gate_stats_real = CtxGateStats()
     if str(args.suite) == "chat":
         gate_table = build_ctx_sig_gate_table_chat(transcripts=base_transcripts, top_k=int(gate_top_k))
         gate_stats_base = ctx_gate_stats_chat(transcripts=base_transcripts, table=gate_table)
-        gate_table_path = os.path.join(out_dir, "active_gate_table_ctxsig_top2.json")
+        gate_table_path = os.path.join(out_dir, f"active_gate_table_ctxsig_top{int(gate_top_k)}.json")
         with open(gate_table_path, "w", encoding="utf-8") as f:
             f.write(
                 json.dumps(
@@ -396,20 +398,22 @@
             )
             f.write("\n")
 
-    csv.config.mode = "active"
-    active_cfg = EngineConfig(
+    # 4) Active gate compare (invariant): compute baseline + forced gate per token and fall back
+    # to baseline on mismatch, while measuring would-save.
+    compare_cfg = EngineConfig(
         enable_contracts=bool(args.enable_contracts),
         disable_macro_router=bool(args.no_router),
         force_predictor_ids_by_ctx_sig=gate_table if gate_table else None,
+        force_gate_debug_compare=True,
     )
-    eng2 = Engine(store, seed=int(args.seed), config=active_cfg)
+    eng2 = Engine(store, seed=int(args.seed), config=compare_cfg)
 
     if str(args.suite) == "skill":
-        active_transcripts, active_metrics = run_skill_suite(
+        compare_transcripts, compare_metrics = run_skill_suite(
             eng2, tasks=SKILL_DIALOGUES_V0, max_new_tokens=int(args.max_new_tokens), csv=None
         )
     else:
-        active_transcripts, active_metrics = run_chat_suite(
+        compare_transcripts, compare_metrics = run_chat_suite(
             eng2,
             dialogues=CHAT_DIALOGUES_20X3,
             max_new_tokens=int(args.max_new_tokens),
@@ -418,15 +422,80 @@
             template_prefix_window=32,
             csv=None,
         )
-        gate_stats_active = ctx_gate_stats_chat(transcripts=active_transcripts, table=gate_table)
-    active_text = transcripts_text(active_transcripts)
-    active_hash = sha256_text(active_text)
+        gate_stats_compare = ctx_gate_stats_chat(transcripts=compare_transcripts, table=gate_table)
+    compare_text = transcripts_text(compare_transcripts)
+    compare_hash = sha256_text(compare_text)
+    invariance_ok_compare = bool(compare_hash == base_hash)
+    if not invariance_ok_compare:
+        raise SystemExit("ACTIVE_COMPARE_INVARIANCE_FAILED: sha256(baseline)!=sha256(active_compare)")
 
-    # Divergence report (active vs baseline).
-    mismatch_count, mismatch_total, mismatch_examples = compare_transcripts_by_full_text(
-        base_transcripts, active_transcripts
-    )
+    def force_gate_compare_stats_chat(transcripts: Sequence[Dict[str, Any]]) -> Dict[str, Any]:
+        tokens_total = 0
+        mismatch_tokens = 0
+        fallback_tokens = 0
+        used_tokens = 0
+        base_iter_sum = 0
+        gate_iter_sum = 0
+        overhead_sum = 0
+
+        for d in transcripts:
+            turns = d.get("turns") or []
+            if not isinstance(turns, list):
+                continue
+            for t in turns:
+                if not isinstance(t, dict):
+                    continue
+                tr = t.get("trace") or {}
+                if not isinstance(tr, dict):
+                    continue
+                m = tr.get("force_gate_mismatch") or []
+                fb = tr.get("force_gate_fallback") or []
+                used = tr.get("force_gate_used") or []
+                base_it = tr.get("force_gate_baseline_predictors_iterated") or []
+                gate_it = tr.get("force_gate_predictors_iterated") or []
+                if not all(isinstance(x, list) for x in [m, fb, used, base_it, gate_it]):
+                    continue
+                n = min(len(m), len(fb), len(used), len(base_it), len(gate_it))
+                if n <= 0:
+                    continue
 
+                rr_total = int(tr.get("rewrite_rules_total", 0) or 0)
+                sel_present = 1 if tr.get("selector_id") else 0
+                overhead = int(rr_total + sel_present)
+
+                tokens_total += n
+                mismatch_tokens += sum(int(bool(m[i])) for i in range(n))
+                fallback_tokens += sum(int(bool(fb[i])) for i in range(n))
+                used_tokens += sum(int(bool(used[i])) for i in range(n))
+                base_iter_sum += sum(int(base_it[i] or 0) for i in range(n))
+                gate_iter_sum += sum(int(gate_it[i] or 0) for i in range(n))
+                overhead_sum += overhead * n
+
+        base_cost_sum = float(base_iter_sum + overhead_sum)
+        gate_cost_sum = float(gate_iter_sum + overhead_sum)
+        base_cost_mean = float(base_cost_sum / max(1, tokens_total))
+        gate_cost_mean = float(gate_cost_sum / max(1, tokens_total))
+        saved = float(base_cost_mean - gate_cost_mean)
+        pct_saved = float(saved / base_cost_mean) if base_cost_mean > 0 else 0.0
+
+        return {
+            "tokens_total": int(tokens_total),
+            "mismatch_tokens": int(mismatch_tokens),
+            "mismatch_rate": float(mismatch_tokens / max(1, tokens_total)),
+            "fallback_tokens": int(fallback_tokens),
+            "fallback_rate": float(fallback_tokens / max(1, tokens_total)),
+            "used_tokens": int(used_tokens),
+            "used_rate": float(used_tokens / max(1, tokens_total)),
+            "avg_scan_cost_baseline_per_token_mean": float(base_cost_mean),
+            "avg_scan_cost_gate_per_token_mean": float(gate_cost_mean),
+            "avg_scan_cost_would_save": float(saved),
+            "pct_saved": float(pct_saved),
+        }
+
+    compare_force_gate = {}
+    if str(args.suite) == "chat":
+        compare_force_gate = force_gate_compare_stats_chat(compare_transcripts)
+
     def _scan_cost(m: Dict[str, Any]) -> float:
         v = m.get("scan_acts_considered_per_token_mean")
         if v is None:
@@ -434,36 +503,86 @@
         return float(v)
 
     baseline_scan = _scan_cost(base_metrics)
-    active_scan = _scan_cost(active_metrics)
-    saved = float(baseline_scan - active_scan)
-    pct_saved = float(saved / baseline_scan) if baseline_scan > 0 else 0.0
+    compare_scan = _scan_cost(compare_metrics)
 
+    # Optional: active-real run (economia real, divergÃªncia permitida).
+    real_transcripts: List[Dict[str, Any]] = []
+    real_metrics: Dict[str, Any] = {}
+    real_hash = ""
+    real_div = {}
+    real_cost = {}
+    if str(args.active_gate_mode) == "real":
+        real_cfg = EngineConfig(
+            enable_contracts=bool(args.enable_contracts),
+            disable_macro_router=bool(args.no_router),
+            force_predictor_ids_by_ctx_sig=gate_table if gate_table else None,
+        )
+        eng3 = Engine(store, seed=int(args.seed), config=real_cfg)
+        if str(args.suite) == "skill":
+            real_transcripts, real_metrics = run_skill_suite(
+                eng3, tasks=SKILL_DIALOGUES_V0, max_new_tokens=int(args.max_new_tokens), csv=None
+            )
+        else:
+            real_transcripts, real_metrics = run_chat_suite(
+                eng3,
+                dialogues=CHAT_DIALOGUES_20X3,
+                max_new_tokens=int(args.max_new_tokens),
+                prefix_k=8,
+                template_ngram_n=6,
+                template_prefix_window=32,
+                csv=None,
+            )
+            gate_stats_real = ctx_gate_stats_chat(transcripts=real_transcripts, table=gate_table)
+        real_text = transcripts_text(real_transcripts)
+        real_hash = sha256_text(real_text)
+
+        mismatch_count, mismatch_total, mismatch_examples = compare_transcripts_by_full_text(
+            base_transcripts, real_transcripts
+        )
+        real_div = {
+            "sha256_transcript_text_active_real": real_hash,
+            "mismatch_count_full_text": int(mismatch_count),
+            "mismatch_total_full_text": int(mismatch_total),
+            "mismatch_examples": mismatch_examples,
+        }
+        real_scan = _scan_cost(real_metrics)
+        saved_real = float(baseline_scan - real_scan)
+        pct_saved_real = float(saved_real / baseline_scan) if baseline_scan > 0 else 0.0
+        real_cost = {
+            "avg_scan_cost_baseline_per_token_mean": float(baseline_scan),
+            "avg_scan_cost_active_real_per_token_mean": float(real_scan),
+            "avg_scan_cost_saved": float(saved_real),
+            "pct_saved": float(pct_saved_real),
+        }
+
     summary: Dict[str, Any] = {
         "seed": int(args.seed),
         "suite": str(args.suite),
         "max_new_tokens": int(args.max_new_tokens),
         "acts_source_run": str(args.run),
         "out_dir": out_dir,
-        "flags": {"enable_contracts": bool(args.enable_contracts), "no_router": bool(args.no_router)},
+        "flags": {
+            "enable_contracts": bool(args.enable_contracts),
+            "no_router": bool(args.no_router),
+            "active_gate_top_k": int(gate_top_k),
+            "active_gate_mode": str(args.active_gate_mode),
+        },
         "output_invariance": {
             "sha256_transcript_text_baseline": base_hash,
             "sha256_transcript_text_shadow": shadow_hash,
+            "sha256_transcript_text_active_compare": compare_hash,
             "ok": bool(invariance_ok),
+            "active_compare_ok": bool(invariance_ok_compare),
         },
         "baseline_suite_metrics": dict(base_metrics),
         "shadow_suite_metrics": dict(shadow_metrics),
-        "active_suite_metrics": dict(active_metrics),
-        "active_divergence": {
-            "sha256_transcript_text_active": active_hash,
-            "mismatch_count_full_text": int(mismatch_count),
-            "mismatch_total_full_text": int(mismatch_total),
-            "mismatch_examples": mismatch_examples,
-        },
-        "active_cost": {
+        "active_compare_suite_metrics": dict(compare_metrics),
+        "active_compare_force_gate": dict(compare_force_gate),
+        "active_compare_cost": {
             "avg_scan_cost_baseline_per_token_mean": float(baseline_scan),
-            "avg_scan_cost_active_per_token_mean": float(active_scan),
-            "avg_scan_cost_saved": float(saved),
-            "pct_saved": float(pct_saved),
+            "avg_scan_cost_active_compare_per_token_mean": float(compare_scan),
+            "avg_scan_cost_saved": float(baseline_scan - compare_scan),
+            "pct_saved": float((baseline_scan - compare_scan) / baseline_scan) if baseline_scan > 0 else 0.0,
         },
         "active_gate": {
             "top_k": int(gate_top_k),
@@ -471,8 +590,12 @@
             "table_path": str(gate_table_path),
             "table_sha256": sha256_file(gate_table_path) if gate_table_path else "",
             "baseline_stats": gate_stats_base.to_dict(),
-            "active_stats": gate_stats_active.to_dict(),
+            "active_compare_stats": gate_stats_compare.to_dict(),
+            **({"active_real_stats": gate_stats_real.to_dict()} if real_transcripts else {}),
         },
+        **({"active_real_suite_metrics": dict(real_metrics)} if real_transcripts else {}),
+        **({"active_real_divergence": dict(real_div)} if real_div else {}),
+        **({"active_real_cost": dict(real_cost)} if real_cost else {}),
         "csv": summarize_csv_logs(run_dir=out_dir, registry=registry),
     }
 
