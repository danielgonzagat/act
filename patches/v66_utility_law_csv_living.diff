--- patches/v66_base/concepts.py	2026-01-11 19:51:01
+++ atos_core/concepts.py	2026-01-11 21:21:03
@@ -5,7 +5,7 @@
 import os
 import re
 from dataclasses import dataclass, field
-from typing import Any, Dict, Iterable, Iterator, List, Optional, Tuple
+from typing import Any, Dict, Iterable, Iterator, List, Optional, Sequence, Tuple
 
 from .act import canonical_json_dumps, deterministic_iso, sha256_hex
 from .validators import ValidatorResult, run_validator
@@ -121,6 +121,14 @@
 
 def _str_lower(s: Any) -> str:
     return str("" if s is None else s).lower()
+
+
+def _make_dict_goal_plan_ab(goal_id: Any, plan: Any, a: Any, b: Any) -> Dict[str, Any]:
+    gid = "" if goal_id is None else str(goal_id)
+    pl = "" if plan is None else str(plan)
+    if isinstance(a, bool) or isinstance(b, bool):
+        return {"goal_id": gid, "plan": pl, "a": 0, "b": 0}
+    return {"goal_id": gid, "plan": pl, "a": int(a), "b": int(b)}
 
 
 @dataclass(frozen=True)
@@ -146,6 +154,10 @@
     "int_to_str": (PrimitiveOpSpec("int_to_str", 1, ("int",), "str"), _int_to_str),
     "str_strip": (PrimitiveOpSpec("str_strip", 1, ("str",), "str"), _str_strip),
     "str_lower": (PrimitiveOpSpec("str_lower", 1, ("str",), "str"), _str_lower),
+    "make_dict_goal_plan_ab": (
+        PrimitiveOpSpec("make_dict_goal_plan_ab", 4, ("str", "str", "int", "int"), "dict"),
+        _make_dict_goal_plan_ab,
+    ),
 }
 
 
@@ -298,11 +310,41 @@
 
 def execute_concept_subgraph(subgraph_ref: Dict[str, Any], inputs: Dict[str, Any]) -> Any:
     kind = str(subgraph_ref.get("kind", ""))
+    if kind == "const_v0":
+        return subgraph_ref.get("value")
     if kind == "engine_turn_subgraph_v0":
         ids = subgraph_ref.get("executed_predictor_act_ids") or []
         if not isinstance(ids, list):
             return []
         return [str(x) for x in ids if isinstance(x, str)]
+    if kind == "csv_ops_v0":
+        ops = subgraph_ref.get("ops") or []
+        if not isinstance(ops, list) or not ops:
+            return ""
+        input_keys = subgraph_ref.get("input_keys") or []
+        if not isinstance(input_keys, list):
+            input_keys = []
+        out_var = str(subgraph_ref.get("return_var") or str(ops[-1].get("out") or ""))
+        env: Dict[str, Any] = {}
+        for idx, k in enumerate([str(x) for x in input_keys]):
+            env[f"in{idx}"] = inputs.get(str(k))
+        for op in ops:
+            if not isinstance(op, dict):
+                raise ValueError("bad_op")
+            fn_id = str(op.get("fn") or "")
+            spec_fn = PRIMITIVE_OPS.get(fn_id)
+            if spec_fn is None:
+                raise KeyError(f"unknown_primitive:{fn_id}")
+            spec, fn = spec_fn
+            in_vars = op.get("in", [])
+            if not isinstance(in_vars, list):
+                raise ValueError("bad_in_vars")
+            vals = [env.get(str(v)) for v in in_vars]
+            if int(spec.arity) != int(len(vals)):
+                raise ValueError(f"arity_mismatch:{fn_id}:{spec.arity}:{len(vals)}")
+            out = fn(*vals) if int(spec.arity) > 1 else fn(vals[0])
+            env[str(op.get("out") or "")] = out
+        return env.get(out_var)
     if kind == "unary_pipeline_v0":
         ops = list(subgraph_ref.get("ops", []))
         if len(inputs) != 1:
@@ -325,6 +367,11 @@
         if isinstance(output, list):
             return float(overhead + float(len(output)))
         return 0.0
+    if kind == "const_v0":
+        return 0.25
+    if kind == "csv_ops_v0":
+        # Treat a mined CSV segment as a compressed call (vs. baseline primitive steps).
+        return 1.0
     # Default: treat concept invocation as a single unit (compressed call).
     return 1.0
 
@@ -496,6 +543,67 @@
         )
         return True
 
+    def _subgraph_equiv_sig(self, subgraph_ref: Dict[str, Any]) -> str:
+        kind = str(subgraph_ref.get("kind") or "")
+        if kind == "engine_turn_subgraph_v0":
+            # Ignore overhead-only fields to enable deterministic dedup/merge.
+            body = {
+                "kind": kind,
+                "executed_predictor_act_ids": list(subgraph_ref.get("executed_predictor_act_ids") or []),
+                "rewrite_rule_hit_ids": list(subgraph_ref.get("rewrite_rule_hit_ids") or []),
+            }
+            return stable_hash_obj(body)
+        if kind == "csv_ops_v0":
+            body = {
+                "kind": kind,
+                "input_keys": list(subgraph_ref.get("input_keys") or []),
+                "ops": list(subgraph_ref.get("ops") or []),
+                "return_var": str(subgraph_ref.get("return_var") or ""),
+            }
+            return stable_hash_obj(body)
+        return stable_hash_obj(subgraph_ref)
+
+    def merge_equivalents(self, *, step: int, reason: str = "equiv_sig") -> int:
+        """
+        Deterministic minimal fusion:
+          - Two concepts are equivalent if (interface_sig, normalized_subgraph_sig) match.
+          - Survivor is lexicographically smallest concept id.
+        """
+        groups: Dict[str, List[Concept]] = {}
+        for c in self._concepts.values():
+            key = stable_hash_obj(
+                {
+                    "iface": str(c.interface.type_signature()),
+                    "sub": str(self._subgraph_equiv_sig(c.subgraph_ref)),
+                }
+            )
+            groups.setdefault(key, []).append(c)
+
+        merged = 0
+        for key, cs in sorted(groups.items(), key=lambda kv: str(kv[0])):
+            alive = [c for c in cs if bool(c.alive)]
+            if len(alive) <= 1:
+                continue
+            alive.sort(key=lambda c: str(c.id))
+            keep = alive[0]
+            for other in alive[1:]:
+                if not bool(other.alive):
+                    continue
+                other.alive = False
+                merged += 1
+                self._append_state(step=int(step), concept=other, reason="merged")
+                self._append_evidence(
+                    step=int(step),
+                    row={
+                        "event": "MERGE",
+                        "reason": str(reason),
+                        "equiv_group": str(key),
+                        "survivor_id": str(keep.id),
+                        "merged_id": str(other.id),
+                    },
+                )
+        return merged
+
     def call(
         self,
         *,
@@ -510,7 +618,26 @@
     ) -> Tuple[Any, ValidatorResult, float]:
         c = self._concepts[str(concept_id)]
 
+        kind = str(c.subgraph_ref.get("kind") or "")
+
         if bool(contract_active):
+            if kind == "concept_call_v0":
+                callee_id = str(c.subgraph_ref.get("callee_concept_id") or "")
+                if not callee_id:
+                    return None, ValidatorResult(False, "missing_callee"), float(baseline_cost)
+                out, vr, _cost = self.call(
+                    step=int(step),
+                    concept_id=callee_id,
+                    inputs=dict(inputs),
+                    expected=expected,
+                    context_signature=str(context_signature),
+                    call_depth=int(call_depth) + 1,
+                    baseline_cost=float(baseline_cost),
+                    contract_active=True,
+                )
+                cost_used = float(baseline_cost)
+                return out, vr, cost_used
+
             out = execute_concept_subgraph(c.subgraph_ref, inputs)
             vr = run_validator(c.interface.validator_id, out, expected)
             cost_used = float(baseline_cost)
@@ -522,7 +649,9 @@
                     "context_signature": str(context_signature),
                     "call_depth": int(call_depth),
                     "inputs": inputs,
+                    "inputs_signature": stable_hash_obj(inputs),
                     "expected": expected,
+                    "expected_signature": stable_hash_obj(expected),
                     "output": out,
                     "output_signature": stable_hash_obj(out),
                     "validator_id": str(c.interface.validator_id),
@@ -530,10 +659,139 @@
                     "validator_reason": str(vr.reason),
                     "delta_utility": 0.0,
                     "delta_cost": 0.0,
+                    "cost_used": float(cost_used),
+                    "baseline_cost": float(baseline_cost),
+                },
+            )
+            return out, vr, cost_used
+
+        # Compositional CALL (nested, logged): concept_call_v0 delegates to another concept.
+        if kind == "concept_call_v0":
+            callee_id = str(c.subgraph_ref.get("callee_concept_id") or "")
+            if not callee_id:
+                out = None
+                vr = ValidatorResult(False, "missing_callee")
+                cost_used = float(estimate_subgraph_cost_units(c.subgraph_ref, out))
+                self._append_evidence(
+                    step=int(step),
+                    row={
+                        "event": "CALL",
+                        "concept_id": str(c.id),
+                        "context_signature": str(context_signature),
+                        "call_depth": int(call_depth),
+                        "inputs": inputs,
+                        "inputs_signature": stable_hash_obj(inputs),
+                        "expected": expected,
+                        "expected_signature": stable_hash_obj(expected),
+                        "output": out,
+                        "output_signature": stable_hash_obj(out),
+                        "validator_id": str(c.interface.validator_id),
+                        "validator_passed": bool(vr.passed),
+                        "validator_reason": str(vr.reason),
+                        "cost_used": float(cost_used),
+                        "baseline_cost": float(baseline_cost),
+                    },
+                )
+                self._append_telemetry(
+                    step=int(step),
+                    row={
+                        "event": "CALL",
+                        "concept_id": str(c.id),
+                        "concept_type": str(c.interface.type_signature()),
+                        "context_signature": str(context_signature),
+                        "call_depth": int(call_depth),
+                        "inputs": inputs,
+                        "inputs_signature": stable_hash_obj(inputs),
+                        "expected": expected,
+                        "expected_signature": stable_hash_obj(expected),
+                        "output": out,
+                        "output_signature": stable_hash_obj(out),
+                        "validator_id": str(c.interface.validator_id),
+                        "validator_passed": bool(vr.passed),
+                        "validator_reason": str(vr.reason),
+                        "delta_utility": -1.0,
+                        "delta_cost": 0.0,
+                        "cost_used": float(cost_used),
+                        "baseline_cost": float(baseline_cost),
+                        "note": "missing_callee",
+                    },
+                )
+                self._update_scores(
+                    concept=c,
+                    step=int(step),
+                    passed=bool(vr.passed),
+                    cost_used=float(cost_used),
+                    context_signature=str(context_signature),
+                )
+                self._prune_check(concept=c, step=int(step))
+                return out, vr, cost_used
+
+            out, vr, callee_cost = self.call(
+                step=int(step),
+                concept_id=callee_id,
+                inputs=dict(inputs),
+                expected=expected,
+                context_signature=str(context_signature),
+                call_depth=int(call_depth) + 1,
+                baseline_cost=float(baseline_cost),
+                contract_active=False,
+            )
+            cost_used = float(callee_cost)
+            # Log wrapper call for audit (CALL + call_depth=outer depth).
+            self._append_evidence(
+                step=int(step),
+                row={
+                    "event": "CALL",
+                    "concept_id": str(c.id),
+                    "context_signature": str(context_signature),
+                    "call_depth": int(call_depth),
+                    "inputs": inputs,
+                    "inputs_signature": stable_hash_obj(inputs),
+                    "expected": expected,
+                    "expected_signature": stable_hash_obj(expected),
+                    "output": out,
+                    "output_signature": stable_hash_obj(out),
+                    "validator_id": str(c.interface.validator_id),
+                    "validator_passed": bool(vr.passed),
+                    "validator_reason": str(vr.reason),
                     "cost_used": float(cost_used),
                     "baseline_cost": float(baseline_cost),
+                    "callee_concept_id": str(callee_id),
                 },
             )
+            self._append_telemetry(
+                step=int(step),
+                row={
+                    "event": "CALL",
+                    "concept_id": str(c.id),
+                    "concept_type": str(c.interface.type_signature()),
+                    "context_signature": str(context_signature),
+                    "call_depth": int(call_depth),
+                    "inputs": inputs,
+                    "inputs_signature": stable_hash_obj(inputs),
+                    "expected": expected,
+                    "expected_signature": stable_hash_obj(expected),
+                    "output": out,
+                    "output_signature": stable_hash_obj(out),
+                    "validator_id": str(c.interface.validator_id),
+                    "validator_passed": bool(vr.passed),
+                    "validator_reason": str(vr.reason),
+                    "delta_utility": 1.0 if bool(vr.passed) else -1.0,
+                    "delta_cost": float(baseline_cost) - float(cost_used),
+                    "cost_used": float(cost_used),
+                    "baseline_cost": float(baseline_cost),
+                    "note": "wrapper_call",
+                    "callee_concept_id": str(callee_id),
+                },
+            )
+            self._update_scores(
+                concept=c,
+                step=int(step),
+                passed=bool(vr.passed),
+                cost_used=float(cost_used),
+                context_signature=str(context_signature),
+            )
+            self._prune_check(concept=c, step=int(step))
             return out, vr, cost_used
 
         out = execute_concept_subgraph(c.subgraph_ref, inputs)
@@ -548,7 +806,9 @@
                 "context_signature": str(context_signature),
                 "call_depth": int(call_depth),
                 "inputs": inputs,
+                "inputs_signature": stable_hash_obj(inputs),
                 "expected": expected,
+                "expected_signature": stable_hash_obj(expected),
                 "output": out,
                 "output_signature": stable_hash_obj(out),
                 "validator_id": str(c.interface.validator_id),
@@ -567,7 +827,9 @@
                 "context_signature": str(context_signature),
                 "call_depth": int(call_depth),
                 "inputs": inputs,
+                "inputs_signature": stable_hash_obj(inputs),
                 "expected": expected,
+                "expected_signature": stable_hash_obj(expected),
                 "output": out,
                 "output_signature": stable_hash_obj(out),
                 "validator_id": str(c.interface.validator_id),
@@ -611,7 +873,9 @@
                 "subgraph_ref": subgraph_ref,
                 "concept_type": str(interface.type_signature()),
                 "inputs": inputs,
+                "inputs_signature": stable_hash_obj(inputs),
                 "expected": expected,
+                "expected_signature": stable_hash_obj(expected),
                 "output": output,
                 "output_signature": stable_hash_obj(output),
                 "validator_id": str(interface.validator_id),
--- patches/v66_base/csv_miner.py	2026-01-11 19:51:19
+++ atos_core/csv_miner.py	2026-01-11 21:26:41
@@ -38,6 +38,10 @@
     gain_bits_est: int
     # Examples used for PCC test vectors (already canonical and deterministic).
     examples: List[Dict[str, Any]]
+    # Optional observed utility signals from the exec log (if provided).
+    utility_pass: int = 0
+    utility_total: int = 0
+    utility_pass_rate: float = 0.0
 
     def to_dict(self) -> Dict[str, Any]:
         return {
@@ -50,6 +54,9 @@
             "contexts_distinct": int(self.contexts_distinct),
             "gain_bits_est": int(self.gain_bits_est),
             "examples": list(self.examples),
+            "utility_pass": int(self.utility_pass),
+            "utility_total": int(self.utility_total),
+            "utility_pass_rate": float(self.utility_pass_rate),
         }
 
 
@@ -60,6 +67,8 @@
         fns = [str(o.get("fn") or "") for o in ops]
         if fns and fns[-1] == "json_canonical" and "make_dict_ab" in fns:
             return "json_ab_int_exact"
+        if fns and fns[-1] == "json_canonical" and "make_dict_goal_plan_ab" in fns:
+            return "plan_validator"
     if str(output_type) == "str":
         return "text_exact"
     return ""
@@ -147,6 +156,8 @@
         inputs = rec.get("inputs", {})
         if not isinstance(inputs, dict):
             inputs = {}
+        utility_passed = rec.get("utility_passed", None)
+        utility_is_bool = isinstance(utility_passed, bool)
         events = rec.get("events", [])
         if not isinstance(events, list):
             continue
@@ -267,10 +278,16 @@
                         "count": 0,
                         "ctx": set(),
                         "examples": [],
+                        "utility_pass": 0,
+                        "utility_total": 0,
                     }
                     agg[sig] = st
                 st["count"] = int(st["count"]) + 1
                 st["ctx"].add(ctx_sig)
+                if utility_is_bool:
+                    st["utility_total"] = int(st["utility_total"]) + 1
+                    if bool(utility_passed):
+                        st["utility_pass"] = int(st["utility_pass"]) + 1
 
                 # Example for PCC test vectors.
                 if len(st["examples"]) < int(max_examples_per_candidate):
@@ -304,7 +321,12 @@
         count = int(st["count"])
         contexts_distinct = int(len(st["ctx"]))
         ops = list(st["ops"])
-        gain_bits_est = int(count) * int(len(ops)) * int(bits_per_op) - int(overhead_bits)
+        util_total = int(st.get("utility_total", 0) or 0)
+        util_pass = int(st.get("utility_pass", 0) or 0)
+        util_rate = float(util_pass / util_total) if util_total > 0 else 0.0
+        # Utility-as-law signal (shadow): add a small deterministic bonus for higher utility.
+        util_bonus_bits = int(round(util_rate * 256.0))
+        gain_bits_est = int(count) * int(len(ops)) * int(bits_per_op) - int(overhead_bits) + int(util_bonus_bits)
         out.append(
             CsvCandidate(
                 candidate_sig=str(sig),
@@ -316,6 +338,9 @@
                 contexts_distinct=contexts_distinct,
                 gain_bits_est=gain_bits_est,
                 examples=list(st["examples"]),
+                utility_pass=util_pass,
+                utility_total=util_total,
+                utility_pass_rate=float(util_rate),
             )
         )
 
@@ -341,8 +366,9 @@
     """
     Turn a mined CsvCandidate into a concept_csv Act (without PCC certificate).
     """
-    # Input schema order is stable for determinism.
-    in_keys = sorted(list(cand.input_schema.keys()))
+    # Input schema order must match candidate alpha-renaming (deterministic).
+    # (Do not sort: it can break in0/in1 bindings.)
+    in_keys = list(cand.input_schema.keys())
     program: List[Instruction] = []
     for idx, name in enumerate(in_keys):
         program.append(Instruction("CSV_GET_INPUT", {"name": str(name), "out": f"in{idx}"}))
--- patches/v66_base/validators.py	2026-01-11 19:51:10
+++ atos_core/validators.py	2026-01-11 21:19:57
@@ -3,9 +3,11 @@
 import json
 import re
 from dataclasses import dataclass
-from typing import Any, Callable, Dict, List, Optional
+from typing import Any, Callable, Dict, List, Optional, Tuple
 
+from .act import canonical_json_dumps, sha256_hex
 
+
 @dataclass(frozen=True)
 class ValidatorResult:
     passed: bool
@@ -129,8 +131,279 @@
     out = str(output)
     exp = str(expected)
     return ValidatorResult(out == exp, "ok" if out == exp else "text_mismatch")
+
+
+def _stable_sig(obj: Any) -> str:
+    return sha256_hex(canonical_json_dumps(obj).encode("utf-8"))
+
+
+def _collapse_ws(s: str) -> str:
+    return re.sub(r"\s+", " ", str(s), flags=re.UNICODE).strip()
+
+
+def _strip_edge_punct(s: str) -> str:
+    return str(s).strip().strip(".,;:!?()[]{}").strip()
+
+
+def _normalize_text(
+    s: str,
+    *,
+    collapse_ws: bool,
+    case_sensitive: bool,
+    strip_edge_punct: bool,
+) -> str:
+    out = str(s)
+    if strip_edge_punct:
+        out = _strip_edge_punct(out)
+    if collapse_ws:
+        out = _collapse_ws(out)
+    if not case_sensitive:
+        out = out.lower()
+    return out
+
+
+def _parse_json_obj(output: Any) -> Tuple[Optional[Any], str]:
+    if isinstance(output, (dict, list)):
+        return output, ""
+    s = str(output)
+    try:
+        return json.loads(s), ""
+    except Exception:
+        return None, "output_not_json"
+
+
+def validate_instruction_following(output: Any, expected: Any) -> ValidatorResult:
+    """
+    Deterministic, spec-driven "instruction following" validator.
+    Expected spec:
+      {"kind": "exact", "text": "...", "collapse_ws": true, "case_sensitive": true, "strip_edge_punct": false}
+      {"kind": "contains_token", "token": "...", "case_sensitive": true}
+      {"kind": "int_exact", "value": 42, "strict": true}
+      {"kind": "json_keys", "required_keys": [...], "types": {...}, "expected_values": {...}}
+    """
+    if not isinstance(expected, dict):
+        return ValidatorResult(False, "expected_not_dict")
+    kind = str(expected.get("kind") or "")
+    if kind == "exact":
+        text = str(expected.get("text") or "")
+        collapse_ws = bool(expected.get("collapse_ws", True))
+        case_sensitive = bool(expected.get("case_sensitive", True))
+        strip_punct = bool(expected.get("strip_edge_punct", False))
+        out_n = _normalize_text(str(output), collapse_ws=collapse_ws, case_sensitive=case_sensitive, strip_edge_punct=strip_punct)
+        exp_n = _normalize_text(text, collapse_ws=collapse_ws, case_sensitive=case_sensitive, strip_edge_punct=strip_punct)
+        return ValidatorResult(out_n == exp_n, "ok" if out_n == exp_n else "exact_mismatch")
+    if kind == "contains_token":
+        tok = str(expected.get("token") or "")
+        case_sensitive = bool(expected.get("case_sensitive", True))
+        if not tok:
+            return ValidatorResult(False, "expected_missing_token")
+        s = str(output)
+        if not case_sensitive:
+            s = s.lower()
+            tok = tok.lower()
+        ok = tok in s
+        return ValidatorResult(ok, "ok" if ok else "token_missing")
+    if kind == "int_exact":
+        if "value" not in expected:
+            return ValidatorResult(False, "expected_missing_value")
+        try:
+            exp = int(expected.get("value"))
+        except Exception:
+            return ValidatorResult(False, "expected_not_int")
+        strict = bool(expected.get("strict", True))
+        s = str(output).strip()
+        if strict:
+            if not re.fullmatch(r"-?[0-9]+", s):
+                return ValidatorResult(False, "output_not_int_text")
+            try:
+                out_n = int(s)
+            except Exception:
+                return ValidatorResult(False, "output_not_int_text")
+        else:
+            m = re.search(r"-?[0-9]+", s)
+            if not m:
+                return ValidatorResult(False, "output_not_int_text")
+            out_n = int(m.group(0))
+        return ValidatorResult(out_n == exp, "ok" if out_n == exp else "int_mismatch")
+    if kind == "json_keys":
+        obj, err = _parse_json_obj(output)
+        if obj is None:
+            return ValidatorResult(False, err)
+        if not isinstance(obj, dict):
+            return ValidatorResult(False, "output_json_not_object")
+        req = expected.get("required_keys") or []
+        if not isinstance(req, list):
+            return ValidatorResult(False, "expected_required_keys_not_list")
+        for k in req:
+            if str(k) not in obj:
+                return ValidatorResult(False, "output_missing_keys")
+        types = expected.get("types") or {}
+        if isinstance(types, dict):
+            for k, t in types.items():
+                if str(k) not in obj:
+                    continue
+                v = obj.get(str(k))
+                tt = str(t)
+                if tt == "int":
+                    if isinstance(v, bool) or not isinstance(v, int):
+                        return ValidatorResult(False, "type_mismatch")
+                elif tt == "bool":
+                    if not isinstance(v, bool):
+                        return ValidatorResult(False, "type_mismatch")
+                elif tt == "str":
+                    if not isinstance(v, str):
+                        return ValidatorResult(False, "type_mismatch")
+        ev = expected.get("expected_values") or {}
+        if isinstance(ev, dict):
+            for k, v in ev.items():
+                if obj.get(str(k)) != v:
+                    return ValidatorResult(False, "value_mismatch")
+        return ValidatorResult(True, "ok")
+    return ValidatorResult(False, f"unknown_instruction_kind:{kind}")
+
+
+def validate_state_validator(output: Any, expected: Any) -> ValidatorResult:
+    """
+    Deterministic state validator.
+    Expected spec:
+      {"required_keys":[...], "expected_values":{...}, "state_sig":"<sha256>"}
+    Output can be JSON text or a dict. If output is an object with a "state" key,
+    validate that subtree; otherwise validate the root object.
+    """
+    if not isinstance(expected, dict):
+        return ValidatorResult(False, "expected_not_dict")
+    obj, err = _parse_json_obj(output)
+    if obj is None:
+        return ValidatorResult(False, err)
+    state = obj.get("state") if isinstance(obj, dict) and isinstance(obj.get("state"), dict) else obj
+    if not isinstance(state, dict):
+        return ValidatorResult(False, "state_not_object")
+    req = expected.get("required_keys") or []
+    if not isinstance(req, list):
+        return ValidatorResult(False, "expected_required_keys_not_list")
+    for k in req:
+        if str(k) not in state:
+            return ValidatorResult(False, "state_missing_keys")
+    ev = expected.get("expected_values") or {}
+    if isinstance(ev, dict):
+        for k, v in ev.items():
+            if state.get(str(k)) != v:
+                return ValidatorResult(False, "state_value_mismatch")
+    sig = expected.get("state_sig")
+    if isinstance(sig, str) and sig:
+        if _stable_sig(state) != str(sig):
+            return ValidatorResult(False, "state_sig_mismatch")
+    return ValidatorResult(True, "ok")
 
 
+def _op_add_int(a: Any, b: Any) -> int:
+    if isinstance(a, bool) or isinstance(b, bool):
+        return 0
+    return int(a) + int(b)
+
+
+def _op_make_dict_goal_plan_ab(goal_id: Any, plan: Any, a: Any, b: Any) -> Dict[str, Any]:
+    gid = "" if goal_id is None else str(goal_id)
+    pl = "" if plan is None else str(plan)
+    if isinstance(a, bool) or isinstance(b, bool):
+        return {"goal_id": gid, "plan": pl, "a": 0, "b": 0}
+    return {"goal_id": gid, "plan": pl, "a": int(a), "b": int(b)}
+
+
+def _op_json_canonical(obj: Any) -> str:
+    return canonical_json_dumps(obj)
+
+
+_PLAN_OPS: Dict[str, Tuple[int, Callable[..., Any]]] = {
+    "add_int": (2, _op_add_int),
+    "make_dict_goal_plan_ab": (4, _op_make_dict_goal_plan_ab),
+    "json_canonical": (1, _op_json_canonical),
+}
+
+
+def _exec_plan_ops_v66(
+    *, ops: List[Dict[str, Any]], inputs: Dict[str, Any], input_keys: List[str], return_var: str
+) -> Any:
+    env: Dict[str, Any] = {}
+    for idx, k in enumerate(input_keys):
+        env[f"in{idx}"] = inputs.get(str(k))
+    for op in ops:
+        fn_id = str(op.get("fn") or "")
+        spec = _PLAN_OPS.get(fn_id)
+        if spec is None:
+            raise KeyError(f"unknown_plan_op:{fn_id}")
+        arity, fn = spec
+        in_vars = op.get("in") or []
+        if not isinstance(in_vars, list) or len(in_vars) != int(arity):
+            raise ValueError(f"arity_mismatch:{fn_id}")
+        args = [env.get(str(v)) for v in in_vars]
+        out = fn(*args)
+        out_var = str(op.get("out") or "")
+        env[out_var] = out
+    return env.get(str(return_var))
+
+
+def validate_plan_validator(output: Any, expected: Any) -> ValidatorResult:
+    """
+    Deterministic plan validator that simulates a small plan program.
+    Expected spec:
+      {
+        "input_keys": ["goal_id","plan","a","b"],
+        "inputs": {...},
+        "ops": [{"fn","in":[...],"out":...}, ...],
+        "return_var": "v2",
+        "expected_output_text": "...",
+        "required_keys": [...],
+        "expected_values": {...}
+      }
+    Output is expected to be a JSON text string (canonical), representing an object.
+    """
+    if not isinstance(expected, dict):
+        return ValidatorResult(False, "expected_not_dict")
+    exp_out = str(expected.get("expected_output_text") or "")
+    if not exp_out:
+        return ValidatorResult(False, "expected_missing_expected_output_text")
+    out_s = str(output)
+
+    obj, err = _parse_json_obj(out_s)
+    if obj is None:
+        return ValidatorResult(False, err)
+    if not isinstance(obj, dict):
+        return ValidatorResult(False, "output_json_not_object")
+
+    req = expected.get("required_keys") or []
+    if isinstance(req, list):
+        for k in req:
+            if str(k) not in obj:
+                return ValidatorResult(False, "output_missing_keys")
+
+    ev = expected.get("expected_values") or {}
+    if isinstance(ev, dict):
+        for k, v in ev.items():
+            if obj.get(str(k)) != v:
+                return ValidatorResult(False, "value_mismatch")
+
+    # Simulate plan.
+    ops = expected.get("ops") or []
+    inputs = expected.get("inputs") or {}
+    input_keys = expected.get("input_keys") or []
+    return_var = str(expected.get("return_var") or "")
+    if not isinstance(ops, list) or not isinstance(inputs, dict) or not isinstance(input_keys, list) or not return_var:
+        return ValidatorResult(False, "expected_plan_spec_invalid")
+    try:
+        sim_out = _exec_plan_ops_v66(ops=list(ops), inputs=dict(inputs), input_keys=[str(k) for k in input_keys], return_var=return_var)
+    except KeyError as e:
+        return ValidatorResult(False, str(e))
+    except Exception:
+        return ValidatorResult(False, "plan_exec_error")
+
+    if str(sim_out) != str(exp_out):
+        return ValidatorResult(False, "plan_expected_mismatch")
+    if out_s != exp_out:
+        return ValidatorResult(False, "output_text_mismatch")
+    return ValidatorResult(True, "ok")
+
+
 ValidatorFn = Callable[[Any, Any], ValidatorResult]
 
 VALIDATORS: Dict[str, ValidatorFn] = {
@@ -139,6 +412,9 @@
     "json_ab_int_exact": validate_json_ab_int_exact,
     "list_contains_all_str": validate_list_contains_all_str,
     "text_exact": validate_text_exact,
+    "instruction_following_validator": validate_instruction_following,
+    "state_validator": validate_state_validator,
+    "plan_validator": validate_plan_validator,
 }
 
 
--- patches/v66_base/suite.py	2026-01-11 17:31:49
+++ atos_core/suite.py	2026-01-11 21:26:11
@@ -8,6 +8,7 @@
 
 from .act import canonical_json_dumps, sha256_hex
 from .metrics import distinct_n, loop_rate, repeat_ngram_rate, tokenize_text
+from .validators import run_validator
 
 
 CHAT_DIALOGUES_20X3: Tuple[Tuple[str, str, str], ...] = (
@@ -310,8 +311,113 @@
         "tags": ["state", "instruction"],
     },
 )
+
+
+def goal_id_for(goal_spec: Dict[str, Any]) -> str:
+    return sha256_hex(canonical_json_dumps(goal_spec).encode("utf-8"))
 
 
+def _v66_plan_task(
+    *,
+    task_id: str,
+    a: int,
+    b: int,
+    plan: str,
+) -> Dict[str, Any]:
+    goal_spec = {"kind": "v66_sum_state_json", "task_id": str(task_id), "a": int(a), "b": int(b), "plan": str(plan)}
+    gid = goal_id_for(goal_spec)
+    input_keys = ["goal_id", "plan", "a", "b"]
+    ops = [
+        {"fn": "add_int", "in": ["in2", "in3"], "out": "v0"},
+        {"fn": "make_dict_goal_plan_ab", "in": ["in0", "in1", "v0", "in3"], "out": "v1"},
+        {"fn": "json_canonical", "in": ["v1"], "out": "v2"},
+    ]
+    expected_obj = {"goal_id": gid, "plan": str(plan), "a": int(a) + int(b), "b": int(b)}
+    expected_text = canonical_json_dumps(expected_obj)
+    expected_spec = {
+        "input_keys": list(input_keys),
+        "inputs": {"goal_id": gid, "plan": str(plan), "a": int(a), "b": int(b)},
+        "ops": list(ops),
+        "return_var": "v2",
+        "expected_output_text": str(expected_text),
+        "required_keys": ["goal_id", "plan", "a", "b"],
+        "expected_values": dict(expected_obj),
+    }
+    return {
+        "task_id": str(task_id),
+        "dialogue": (
+            "Objetivo: retorne um JSON canônico (sem texto extra) com chaves goal_id, plan, a, b. "
+            "a deve ser a+b e b deve ser b. Inclua goal_id e plan exatamente.",
+        ),
+        "validator_id": "plan_validator",
+        "expected_spec": expected_spec,
+        "goal_spec": goal_spec,
+        "tags": ["utility", "plan", "state", "json"],
+    }
+
+
+def _v66_wrap_task(
+    *,
+    task_id: str,
+    sum_value: int,
+    b: int,
+    plan: str,
+) -> Dict[str, Any]:
+    goal_spec = {
+        "kind": "v66_wrap_state_json",
+        "task_id": str(task_id),
+        "sum": int(sum_value),
+        "b": int(b),
+        "plan": str(plan),
+    }
+    gid = goal_id_for(goal_spec)
+    input_keys = ["goal_id", "plan", "sum", "b"]
+    ops = [
+        {"fn": "make_dict_goal_plan_ab", "in": ["in0", "in1", "in2", "in3"], "out": "v0"},
+        {"fn": "json_canonical", "in": ["v0"], "out": "v1"},
+    ]
+    expected_obj = {"goal_id": gid, "plan": str(plan), "a": int(sum_value), "b": int(b)}
+    expected_text = canonical_json_dumps(expected_obj)
+    expected_spec = {
+        "input_keys": list(input_keys),
+        "inputs": {"goal_id": gid, "plan": str(plan), "sum": int(sum_value), "b": int(b)},
+        "ops": list(ops),
+        "return_var": "v1",
+        "expected_output_text": str(expected_text),
+        "required_keys": ["goal_id", "plan", "a", "b"],
+        "expected_values": dict(expected_obj),
+    }
+    return {
+        "task_id": str(task_id),
+        "dialogue": (
+            "Objetivo: retorne um JSON canônico (sem texto extra) com chaves goal_id, plan, a, b. "
+            "Aqui a já é fornecido como sum, e b deve ser b. Inclua goal_id e plan exatamente.",
+        ),
+        "validator_id": "plan_validator",
+        "expected_spec": expected_spec,
+        "goal_spec": goal_spec,
+        "tags": ["utility", "plan", "state", "json"],
+    }
+
+
+# Utility suite v66 (semantic pressure via deterministic plan/state/goal objects).
+# Output is a canonical JSON object; validation uses plan simulation (no LLM, no heuristics).
+UTILITY_DIALOGUES_V66: Tuple[Dict[str, Any], ...] = (
+    _v66_plan_task(task_id="v66_sum_state_00", a=4, b=8, plan="add_int+wrap_goal_plan_state"),
+    _v66_plan_task(task_id="v66_sum_state_01", a=17, b=25, plan="add_int+wrap_goal_plan_state"),
+    _v66_plan_task(task_id="v66_sum_state_02", a=9, b=7, plan="add_int+wrap_goal_plan_state"),
+    _v66_plan_task(task_id="v66_sum_state_03", a=12, b=30, plan="add_int+wrap_goal_plan_state"),
+    _v66_plan_task(task_id="v66_sum_state_04", a=99, b=1, plan="add_int+wrap_goal_plan_state"),
+    _v66_plan_task(task_id="v66_sum_state_05", a=0, b=42, plan="add_int+wrap_goal_plan_state"),
+    _v66_wrap_task(task_id="v66_wrap_state_06", sum_value=42, b=0, plan="wrap_goal_plan_state_only"),
+    _v66_wrap_task(task_id="v66_wrap_state_07", sum_value=3, b=2, plan="wrap_goal_plan_state_only"),
+    _v66_wrap_task(task_id="v66_wrap_state_08", sum_value=3, b=1, plan="wrap_goal_plan_state_only"),
+    _v66_wrap_task(task_id="v66_wrap_state_09", sum_value=42, b=39, plan="wrap_goal_plan_state_only"),
+    _v66_wrap_task(task_id="v66_wrap_state_10", sum_value=13, b=7, plan="wrap_goal_plan_state_only"),
+    _v66_wrap_task(task_id="v66_wrap_state_11", sum_value=42, b=32, plan="wrap_goal_plan_state_only"),
+)
+
+
 def _normalize_output(text: str, *, collapse_ws: bool) -> str:
     s = str(text or "").strip()
     if collapse_ws:
@@ -428,6 +534,16 @@
     "json_parse_keys": _validate_json_parse_keys,
     "regex_fullmatch": _validate_regex_fullmatch,
     "contains_exact_token": _validate_contains_exact_token,
+    # Core deterministic validators (atos_core/validators.py).
+    "instruction_following_validator": lambda out, spec: (
+        lambda vr: (bool(vr.passed), str(vr.reason))
+    )(run_validator("instruction_following_validator", out, spec)),
+    "state_validator": lambda out, spec: (
+        lambda vr: (bool(vr.passed), str(vr.reason))
+    )(run_validator("state_validator", out, spec)),
+    "plan_validator": lambda out, spec: (lambda vr: (bool(vr.passed), str(vr.reason)))(
+        run_validator("plan_validator", out, spec)
+    ),
 }
 
 
@@ -467,12 +583,37 @@
         if isinstance(expected_spec, dict):
             tok = str(expected_spec.get("token") or "")
         constraints = ["contains_exact_token"] + ([f"token:{tok}"] if tok else [])
+    elif validator_id == "plan_validator":
+        expected_format = "plan"
+        constraints = ["plan_validator", "json_canonical"]
+    elif validator_id == "state_validator":
+        expected_format = "state"
+        constraints = ["state_validator", "json"]
+    elif validator_id == "instruction_following_validator":
+        expected_format = "instruction"
+        constraints = ["instruction_following_validator"]
+
+    goal_id = ""
+    goal_spec = task.get("goal_spec")
+    if isinstance(goal_spec, dict) and goal_spec:
+        goal_id = goal_id_for(goal_spec)
+    exp_sig = ""
+    if isinstance(expected_spec, dict) and expected_spec:
+        try:
+            exp_sig = sha256_hex(canonical_json_dumps(expected_spec).encode("utf-8"))
+        except Exception:
+            exp_sig = ""
 
     return {
         "task_id": task_id,
         "validator_id": validator_id,
         "expected_format": expected_format,
         "constraints": constraints,
+        "goal_id": str(goal_id),
+        "goal_active": bool(goal_id),
+        "goal_progress": None,
+        "goal_satisfied": None,
+        "expected_spec_sig": str(exp_sig),
     }
 
 
@@ -1066,6 +1207,8 @@
 
     cat_total: Counter = Counter()
     cat_pass: Counter = Counter()
+    goals_total = 0
+    goals_satisfied = 0
 
     plan_turns_total = 0
     plan_turns_missing = 0
@@ -1089,6 +1232,8 @@
             tags = []
 
         total_tasks += 1
+        if isinstance(task.get("goal_spec"), dict) and task.get("goal_spec"):
+            goals_total += 1
         for cat in ("instruction", "json", "math", "state"):
             if cat in tags:
                 cat_total[cat] += 1
@@ -1143,9 +1288,24 @@
             reason = "unknown_validator_or_spec"
         else:
             ok, reason = fn(out_text, expected_spec)
+
+        # Shadow goal progress (deterministic): 1.0 if validated, else 0.0.
+        try:
+            tr = turn_rec.get("trace") or {}
+            if isinstance(tr, dict) and isinstance(tr.get("plan_trace"), dict):
+                pt = tr["plan_trace"]
+                if str(pt.get("goal_id") or ""):
+                    pt["goal_progress"] = 1.0 if bool(ok) else 0.0
+                    pt["goal_satisfied"] = bool(ok)
+                    pt["validator_passed"] = bool(ok)
+                    pt["validator_reason"] = str(reason or "")
+        except Exception:
+            pass
 
         if ok:
             pass_count += 1
+            if isinstance(task.get("goal_spec"), dict) and task.get("goal_spec"):
+                goals_satisfied += 1
             for cat in ("instruction", "json", "math", "state"):
                 if cat in tags:
                     cat_pass[cat] += 1
@@ -1191,6 +1351,9 @@
         "total_tasks": int(total_tasks),
         "pass_count": int(pass_count),
         "pass_rate": _rate(pass_count, total_tasks),
+        "goals_total": int(goals_total),
+        "goals_satisfied": int(goals_satisfied),
+        "goals_satisfied_rate": _rate(goals_satisfied, goals_total),
         "instruction_pass_rate": _rate(
             int(cat_pass.get("instruction", 0)), int(cat_total.get("instruction", 0))
         ),
--- patches/v66_base/eval_skill_suite.py	2026-01-10 22:07:55
+++ scripts/eval_skill_suite.py	2026-01-11 21:23:21
@@ -12,7 +12,13 @@
 
 from atos_core.engine import Engine, EngineConfig
 from atos_core.store import ActStore
-from atos_core.suite import SKILL_DIALOGUES_V0, SKILL_DIALOGUES_V1_PARAPHRASE, run_skill_suite
+from atos_core.suite import (
+    SKILL_DIALOGUES_V0,
+    SKILL_DIALOGUES_V1_PARAPHRASE,
+    UTILITY_DIALOGUES_V66,
+    run_skill_suite,
+    suite_metrics_from_transcripts,
+)
 
 
 def sha256_text(s: str) -> str:
@@ -48,9 +54,9 @@
     ap.add_argument("--enable_contracts", action="store_true", help="Enable deterministic instruction contracts.")
     ap.add_argument(
         "--utility_suite_version",
-        choices=["v0", "v1"],
+        choices=["v0", "v1", "v66"],
         default="v0",
-        help="Which deterministic utility suite to run (v0=baseline, v1=paraphrase).",
+        help="Which deterministic utility suite to run (v0=baseline, v1=paraphrase, v66=utility-as-law).",
     )
     args = ap.parse_args()
 
@@ -58,10 +64,16 @@
     store = ActStore.load_jsonl(acts_path)
     engine = Engine(store, seed=args.seed, config=EngineConfig(enable_contracts=bool(args.enable_contracts)))
 
-    tasks = SKILL_DIALOGUES_V0 if str(args.utility_suite_version) == "v0" else SKILL_DIALOGUES_V1_PARAPHRASE
+    if str(args.utility_suite_version) == "v0":
+        tasks = SKILL_DIALOGUES_V0
+    elif str(args.utility_suite_version) == "v1":
+        tasks = SKILL_DIALOGUES_V1_PARAPHRASE
+    else:
+        tasks = UTILITY_DIALOGUES_V66
     transcripts, metrics = run_skill_suite(
         engine, tasks=tasks, max_new_tokens=args.max_new_tokens
     )
+    cost_metrics = suite_metrics_from_transcripts(transcripts)
     txt = transcripts_text(transcripts)
     out: Dict[str, Any] = {
         "run": str(args.run),
@@ -70,6 +82,7 @@
         "utility_suite_version": str(args.utility_suite_version),
         "sha256_transcript_text": sha256_text(txt),
         "plan_trace_sample": first_plan_trace(transcripts),
+        "cost": {k: cost_metrics.get(k) for k in sorted(cost_metrics.keys())},
         **dict(metrics),
     }
     print(json.dumps(out, ensure_ascii=False, indent=2))
--- /dev/null	2026-01-11 21:32:43
+++ scripts/smoke_csv_living_v66.py	2026-01-11 21:31:03
@@ -0,0 +1,342 @@
+#!/usr/bin/env python3
+from __future__ import annotations
+
+import argparse
+import hashlib
+import json
+import os
+import sys
+from typing import Any, Dict, List, Optional
+
+sys.path.insert(0, os.path.dirname(os.path.dirname(__file__)))
+
+from atos_core.act import canonical_json_dumps
+from atos_core.concepts import ConceptInterface, ConceptPolicies, ConceptRegistry, concept_id_for
+from atos_core.csv_miner import mine_csv_candidates
+from atos_core.suite import UTILITY_DIALOGUES_V66
+from atos_core.validators import run_validator
+
+
+def sha256_file(path: str) -> str:
+    h = hashlib.sha256()
+    with open(path, "rb") as f:
+        while True:
+            b = f.read(1024 * 1024)
+            if not b:
+                break
+            h.update(b)
+    return h.hexdigest()
+
+
+def sha256_text(s: str) -> str:
+    return hashlib.sha256(str(s).encode("utf-8")).hexdigest()
+
+def _fail(msg: str, *, code: int = 2) -> None:
+    print(msg, file=sys.stderr)
+    raise SystemExit(code)
+
+
+def ensure_absent(path: str) -> None:
+    if os.path.exists(path):
+        _fail(f"ERROR: path already exists: {path}")
+
+
+def write_json(path: str, obj: Any) -> str:
+    ensure_absent(path)
+    tmp = path + ".tmp"
+    with open(tmp, "w", encoding="utf-8") as f:
+        f.write(json.dumps(obj, ensure_ascii=False, indent=2, sort_keys=True))
+    os.replace(tmp, path)
+    return sha256_file(path)
+
+
+def write_jsonl(path: str, rows: List[Dict[str, Any]]) -> str:
+    ensure_absent(path)
+    tmp = path + ".tmp"
+    with open(tmp, "w", encoding="utf-8") as f:
+        for r in rows:
+            f.write(canonical_json_dumps(r))
+            f.write("\n")
+    os.replace(tmp, path)
+    return sha256_file(path)
+
+
+def main() -> None:
+    ap = argparse.ArgumentParser()
+    ap.add_argument("--out", required=True)
+    ap.add_argument("--seed", type=int, default=0)
+    ap.add_argument("--limit_tasks", type=int, default=12)
+    args = ap.parse_args()
+
+    out_dir = str(args.out)
+    ensure_absent(out_dir)
+    os.makedirs(out_dir, exist_ok=False)
+
+    tasks = list(UTILITY_DIALOGUES_V66)[: max(1, int(args.limit_tasks))]
+    exec_rows: List[Dict[str, Any]] = []
+
+    for t in tasks:
+        task_id = str(t.get("task_id") or "")
+        spec = t.get("expected_spec") or {}
+        if not isinstance(spec, dict):
+            _fail(f"ERROR: missing expected_spec for task {task_id}")
+        input_keys = spec.get("input_keys") or []
+        inputs = spec.get("inputs") or {}
+        ops = spec.get("ops") or []
+        return_var = str(spec.get("return_var") or "")
+        expected_out = str(spec.get("expected_output_text") or "")
+        if not isinstance(input_keys, list) or not isinstance(inputs, dict) or not isinstance(ops, list) or not return_var or not expected_out:
+            _fail(f"ERROR: bad expected_spec for task {task_id}")
+
+        vr = run_validator("plan_validator", expected_out, spec)
+        if not bool(vr.passed):
+            _fail(f"ERROR: baseline expected output does not validate for task {task_id}: {vr.reason}")
+
+        events: List[Dict[str, Any]] = []
+        for idx, name in enumerate([str(k) for k in input_keys]):
+            events.append({"t": "INS", "op": "CSV_GET_INPUT", "name": str(name), "out": f"in{idx}"})
+        for op in ops:
+            if not isinstance(op, dict):
+                _fail(f"ERROR: bad op in task {task_id}")
+            events.append(
+                {
+                    "t": "INS",
+                    "op": "CSV_PRIMITIVE",
+                    "fn": str(op.get("fn") or ""),
+                    "in": list(op.get("in") or []),
+                    "out": str(op.get("out") or ""),
+                }
+            )
+        events.append({"t": "INS", "op": "CSV_RETURN", "var": str(return_var)})
+
+        exec_rows.append(
+            {
+                "ctx_sig": f"v66_utility␟task={task_id}",
+                "inputs": dict(inputs),
+                "events": events,
+                "utility_passed": True,
+                "expected_output_text": expected_out,
+            }
+        )
+
+    csv_exec_path = os.path.join(out_dir, "csv_exec_v66.jsonl")
+    csv_exec_sha = write_jsonl(csv_exec_path, exec_rows)
+
+    # Mine candidates (includes utility bonus if utility_passed provided).
+    candidates = mine_csv_candidates(
+        csv_exec_path,
+        min_ops=2,
+        max_ops=6,
+        bits_per_op=128,
+        overhead_bits=1024,
+        max_examples_per_candidate=20,
+    )
+    mined_candidates_path = os.path.join(out_dir, "mined_candidates.json")
+    mined_candidates_sha = write_json(mined_candidates_path, [c.to_dict() for c in candidates])
+
+    # Living concepts registry (WORM, chained JSONL).
+    registry_dir = os.path.join(out_dir, "concept_registry_v66")
+    pol = ConceptPolicies(
+        ema_alpha=0.5,
+        prune_min_calls=4,
+        prune_min_lifetime_steps=4,
+        prune_fail_streak=2,
+        prune_u_threshold=0.4,
+        prune_s_threshold=0.25,
+    )
+    reg = ConceptRegistry(run_dir=registry_dir)
+
+    births_total = 0
+    promoted_ids: List[str] = []
+
+    # Promote top-N plan-capable candidates (deterministic).
+    for cand in candidates:
+        if str(cand.validator_id) != "plan_validator":
+            continue
+        iface = ConceptInterface(
+            input_schema=dict(cand.input_schema),
+            output_schema={"value": str(cand.output_type)},
+            validator_id=str(cand.validator_id),
+            preconditions={},
+            postconditions={},
+        )
+        subgraph_ref = {
+            "kind": "csv_ops_v0",
+            "input_keys": list(cand.input_schema.keys()),
+            "ops": list(cand.ops),
+            "return_var": str(cand.ops[-1].get("out") or ""),
+        }
+        cid = concept_id_for(subgraph_ref, iface)
+        if reg.get(cid) is not None:
+            continue
+        c = reg.define(
+            step=1 + births_total,
+            subgraph_ref=subgraph_ref,
+            interface=iface,
+            policies=pol,
+            birth_reason="v66_miner_promote",
+            birth_prior={"u_ema": float(max(0.0, cand.utility_pass_rate)), "k_ema": 1.0},
+        )
+        births_total += 1
+        promoted_ids.append(str(c.id))
+        if len(promoted_ids) >= 3:
+            break
+
+    if births_total < 1:
+        _fail("ERROR: expected >=1 promoted living concept")
+
+    # Deterministic fusion demo: define two equivalent subgraphs and merge.
+    # (Equivalent here ignores scan_overhead_units for engine_turn_subgraph_v0.)
+    iface_gate = ConceptInterface(
+        input_schema={"turn_sig": "str"},
+        output_schema={"executed_predictor_act_ids": "list[str]"},
+        validator_id="list_contains_all_str",
+        preconditions={},
+        postconditions={},
+    )
+    g1 = reg.define(
+        step=100,
+        subgraph_ref={
+            "kind": "engine_turn_subgraph_v0",
+            "executed_predictor_act_ids": ["act_dummy_0"],
+            "rewrite_rule_hit_ids": [],
+            "scan_overhead_units": 1,
+        },
+        interface=iface_gate,
+        policies=pol,
+        birth_reason="v66_merge_demo",
+        birth_prior={"u_ema": 0.0, "k_ema": 0.0},
+    )
+    g2 = reg.define(
+        step=101,
+        subgraph_ref={
+            "kind": "engine_turn_subgraph_v0",
+            "executed_predictor_act_ids": ["act_dummy_0"],
+            "rewrite_rule_hit_ids": [],
+            "scan_overhead_units": 999,
+        },
+        interface=iface_gate,
+        policies=pol,
+        birth_reason="v66_merge_demo",
+        birth_prior={"u_ema": 0.0, "k_ema": 0.0},
+    )
+    merged_total = reg.merge_equivalents(step=102, reason="v66_equiv_sig_demo")
+
+    # Compositional CALL demo: wrapper calls best promoted concept (nested call_depth).
+    base_id = promoted_ids[0]
+    base = reg.get(base_id)
+    if base is None:
+        _fail("ERROR: missing base concept")
+    wrapper = reg.define(
+        step=110,
+        subgraph_ref={"kind": "concept_call_v0", "callee_concept_id": str(base.id)},
+        interface=base.interface,
+        policies=pol,
+        birth_reason="v66_auto_wrapper",
+        birth_prior={"u_ema": float(base.u_ema), "k_ema": float(base.k_ema)},
+    )
+
+    # Execute calls and force at least one pruning deterministically.
+    calls_total = 0
+    pruned_total = 0
+
+    t0 = tasks[0]
+    t1 = tasks[1] if len(tasks) > 1 else tasks[0]
+    spec0 = t0.get("expected_spec") if isinstance(t0.get("expected_spec"), dict) else {}
+    spec1 = t1.get("expected_spec") if isinstance(t1.get("expected_spec"), dict) else {}
+    if not isinstance(spec0, dict) or not isinstance(spec1, dict):
+        _fail("ERROR: missing v66 expected_spec")
+
+    # Call wrapper once (nested call_depth>0 present in logs).
+    out0, vr0, _ = reg.call(
+        step=200,
+        concept_id=str(wrapper.id),
+        inputs=dict(spec0.get("inputs") or {}),
+        expected=dict(spec0),
+        context_signature="smoke_v66",
+        call_depth=0,
+        baseline_cost=3.0,
+        contract_active=False,
+    )
+    calls_total += 1
+    if not bool(vr0.passed):
+        _fail(f"ERROR: wrapper call must pass: {vr0.reason}")
+
+    # Force failures to demonstrate pruning (misapply spec1 expected to spec0 output).
+    target = reg.get(str(base.id))
+    if target is None:
+        _fail("ERROR: missing target concept")
+    for i in range(6):
+        step = 210 + i
+        out, vr, _ = reg.call(
+            step=int(step),
+            concept_id=str(target.id),
+            inputs=dict(spec0.get("inputs") or {}),
+            expected=dict(spec1),
+            context_signature="smoke_v66_force_prune",
+            call_depth=0,
+            baseline_cost=3.0,
+            contract_active=False,
+        )
+        calls_total += 1
+        if bool(vr.passed):
+            _fail("ERROR: expected forced prune call to fail")
+        if not bool(target.alive):
+            pruned_total = 1
+            break
+
+    if pruned_total < 1:
+        _fail("ERROR: expected >=1 concept pruned")
+
+    chains_ok = reg.verify_chains()
+
+    summary = {
+        "ok": True,
+        "seed": int(args.seed),
+        "tasks_total": int(len(tasks)),
+        "births_total": int(births_total),
+        "calls_total": int(calls_total),
+        "promoted_total": int(len(promoted_ids)),
+        "pruned_total": int(pruned_total),
+        "merged_total": int(merged_total),
+        "chains_ok": dict(chains_ok),
+        "artifacts": {
+            "csv_exec_v66_jsonl": str(csv_exec_path),
+            "mined_candidates_json": str(mined_candidates_path),
+            "concepts_jsonl": str(reg.concepts_path),
+            "concept_evidence_jsonl": str(reg.evidence_path),
+            "concept_telemetry_jsonl": str(reg.telemetry_path),
+        },
+        "sha256": {
+            "csv_exec_v66_jsonl": str(csv_exec_sha),
+            "mined_candidates_json": str(mined_candidates_sha),
+            "concepts_jsonl": str(sha256_file(reg.concepts_path)),
+            "concept_evidence_jsonl": str(sha256_file(reg.evidence_path)),
+            "concept_telemetry_jsonl": str(sha256_file(reg.telemetry_path)),
+        },
+    }
+
+    # Determinism proof: hash only stable content (exclude out_dir-dependent paths).
+    det_payload = {
+        "seed": int(summary["seed"]),
+        "tasks_total": int(summary["tasks_total"]),
+        "births_total": int(summary["births_total"]),
+        "calls_total": int(summary["calls_total"]),
+        "promoted_total": int(summary["promoted_total"]),
+        "pruned_total": int(summary["pruned_total"]),
+        "merged_total": int(summary["merged_total"]),
+        "chains_ok": dict(summary["chains_ok"]),
+        "sha256": dict(summary["sha256"]),
+    }
+    summary["determinism"] = {
+        "summary_sha256": sha256_text(canonical_json_dumps(det_payload)),
+        "trace_sha256": str(summary["sha256"]["concept_telemetry_jsonl"]),
+    }
+
+    smoke_summary_path = os.path.join(out_dir, "smoke_summary.json")
+    write_json(smoke_summary_path, summary)
+    print(json.dumps(summary, ensure_ascii=False, indent=2, sort_keys=True))
+
+
+if __name__ == "__main__":
+    main()
--- /dev/null	2026-01-11 21:32:43
+++ scripts/agent_trace_mine_end2end_v66.py	2026-01-11 21:29:35
@@ -0,0 +1,406 @@
+#!/usr/bin/env python3
+from __future__ import annotations
+
+import argparse
+import hashlib
+import json
+import os
+import sys
+from typing import Any, Dict, List, Tuple
+
+sys.path.insert(0, os.path.dirname(os.path.dirname(__file__)))
+
+from atos_core.act import canonical_json_dumps
+from atos_core.concepts import ConceptInterface, ConceptPolicies, ConceptRegistry, concept_id_for
+from atos_core.csv_miner import mine_csv_candidates
+from atos_core.suite import UTILITY_DIALOGUES_V66
+from atos_core.validators import run_validator
+
+
+def sha256_file(path: str) -> str:
+    h = hashlib.sha256()
+    with open(path, "rb") as f:
+        while True:
+            b = f.read(1024 * 1024)
+            if not b:
+                break
+            h.update(b)
+    return h.hexdigest()
+
+
+def _fail(msg: str, *, code: int = 2) -> None:
+    print(msg, file=sys.stderr)
+    raise SystemExit(code)
+
+
+def ensure_absent(path: str) -> None:
+    if os.path.exists(path):
+        _fail(f"ERROR: path already exists: {path}")
+
+
+def write_json(path: str, obj: Any) -> str:
+    ensure_absent(path)
+    tmp = path + ".tmp"
+    with open(tmp, "w", encoding="utf-8") as f:
+        f.write(json.dumps(obj, ensure_ascii=False, indent=2, sort_keys=True))
+    os.replace(tmp, path)
+    return sha256_file(path)
+
+
+def write_jsonl(path: str, rows: List[Dict[str, Any]]) -> str:
+    ensure_absent(path)
+    tmp = path + ".tmp"
+    with open(tmp, "w", encoding="utf-8") as f:
+        for r in rows:
+            f.write(canonical_json_dumps(r))
+            f.write("\n")
+    os.replace(tmp, path)
+    return sha256_file(path)
+
+
+def _task_exec_record(task: Dict[str, Any]) -> Dict[str, Any]:
+    task_id = str(task.get("task_id") or "")
+    spec = task.get("expected_spec") or {}
+    if not isinstance(spec, dict):
+        raise ValueError("missing_expected_spec")
+    input_keys = spec.get("input_keys") or []
+    inputs = spec.get("inputs") or {}
+    ops = spec.get("ops") or []
+    return_var = str(spec.get("return_var") or "")
+    expected_out = str(spec.get("expected_output_text") or "")
+    if not isinstance(input_keys, list) or not isinstance(inputs, dict) or not isinstance(ops, list) or not return_var or not expected_out:
+        raise ValueError("bad_expected_spec")
+
+    vr = run_validator("plan_validator", expected_out, spec)
+    if not bool(vr.passed):
+        raise ValueError(f"baseline_invalid:{vr.reason}")
+
+    events: List[Dict[str, Any]] = []
+    for idx, name in enumerate([str(k) for k in input_keys]):
+        events.append({"t": "INS", "op": "CSV_GET_INPUT", "name": str(name), "out": f"in{idx}"})
+    for op in ops:
+        if not isinstance(op, dict):
+            raise ValueError("bad_op")
+        events.append(
+            {
+                "t": "INS",
+                "op": "CSV_PRIMITIVE",
+                "fn": str(op.get("fn") or ""),
+                "in": list(op.get("in") or []),
+                "out": str(op.get("out") or ""),
+            }
+        )
+    events.append({"t": "INS", "op": "CSV_RETURN", "var": str(return_var)})
+
+    return {
+        "ctx_sig": f"v66_utility␟task={task_id}",
+        "inputs": dict(inputs),
+        "events": events,
+        "utility_passed": True,
+        "expected_output_text": expected_out,
+    }
+
+
+def main() -> None:
+    ap = argparse.ArgumentParser()
+    ap.add_argument("--out", required=True)
+    ap.add_argument("--seed", type=int, default=0)
+    ap.add_argument("--limit_tasks", type=int, default=12)
+    ap.add_argument("--top_k_candidates", type=int, default=8)
+    ap.add_argument("--promote_max", type=int, default=4)
+    args = ap.parse_args()
+
+    out_dir = str(args.out)
+    ensure_absent(out_dir)
+    os.makedirs(out_dir, exist_ok=False)
+
+    tasks = list(UTILITY_DIALOGUES_V66)[: max(1, int(args.limit_tasks))]
+
+    # (1) Generate deterministic exec traces (JSONL).
+    exec_rows: List[Dict[str, Any]] = []
+    for t in tasks:
+        try:
+            exec_rows.append(_task_exec_record(t))
+        except Exception as e:
+            _fail(f"ERROR: failed to build exec record for task {t.get('task_id')}: {e}")
+
+    csv_exec_path = os.path.join(out_dir, "csv_exec_v66.jsonl")
+    csv_exec_sha = write_jsonl(csv_exec_path, exec_rows)
+
+    # (2) Mine candidates.
+    candidates = mine_csv_candidates(
+        csv_exec_path,
+        min_ops=2,
+        max_ops=6,
+        bits_per_op=128,
+        overhead_bits=1024,
+        max_examples_per_candidate=50,
+    )
+    mined_candidates_path = os.path.join(out_dir, "mined_candidates.json")
+    mined_candidates_sha = write_json(mined_candidates_path, [c.to_dict() for c in candidates])
+
+    # (3) Promote living concepts under "utility as law".
+    reg_dir = os.path.join(out_dir, "concept_registry_v66")
+    pol = ConceptPolicies(
+        ema_alpha=0.4,
+        prune_min_calls=4,
+        prune_min_lifetime_steps=4,
+        prune_fail_streak=2,
+        prune_u_threshold=0.4,
+        prune_s_threshold=0.25,
+    )
+    reg = ConceptRegistry(run_dir=reg_dir)
+
+    births_total = 0
+    promoted_ids: List[str] = []
+    promote_max = max(1, int(args.promote_max))
+    top_k = max(1, int(args.top_k_candidates))
+
+    for cand in candidates[:top_k]:
+        # Law: only promote candidates that have an explicit, deterministic validator for utility.
+        if str(cand.validator_id) != "plan_validator":
+            continue
+        iface = ConceptInterface(
+            input_schema=dict(cand.input_schema),
+            output_schema={"value": str(cand.output_type)},
+            validator_id=str(cand.validator_id),
+            preconditions={},
+            postconditions={},
+        )
+        subgraph_ref = {
+            "kind": "csv_ops_v0",
+            "input_keys": list(cand.input_schema.keys()),
+            "ops": list(cand.ops),
+            "return_var": str(cand.ops[-1].get("out") or ""),
+        }
+        cid = concept_id_for(subgraph_ref, iface)
+        if reg.get(cid) is not None:
+            continue
+        c = reg.define(
+            step=10 + births_total,
+            subgraph_ref=subgraph_ref,
+            interface=iface,
+            policies=pol,
+            birth_reason="v66_promote_by_utility",
+            birth_prior={"u_ema": float(max(0.0, cand.utility_pass_rate)), "k_ema": 1.0},
+        )
+        births_total += 1
+        promoted_ids.append(str(c.id))
+        if len(promoted_ids) >= promote_max:
+            break
+
+    if births_total < 2:
+        _fail("ERROR: expected >=2 promoted concepts (need at least 2 distinct programs for pruning demo)")
+
+    # Index promoted concepts by input key set for deterministic selection per task.
+    by_inputs: Dict[Tuple[str, ...], str] = {}
+    for cid in promoted_ids:
+        c = reg.get(cid)
+        if c is None:
+            continue
+        keys = tuple(sorted(list(c.interface.input_schema.keys())))
+        if keys not in by_inputs:
+            by_inputs[keys] = str(c.id)
+
+    # (4) Compositional CALL (demo): wrapper calls the best sum-concept once (nested call_depth).
+    base_id = promoted_ids[0]
+    base = reg.get(base_id)
+    if base is None:
+        _fail("ERROR: missing base concept")
+    wrapper = reg.define(
+        step=200,
+        subgraph_ref={"kind": "concept_call_v0", "callee_concept_id": str(base.id)},
+        interface=base.interface,
+        policies=pol,
+        birth_reason="v66_wrapper_call_demo",
+        birth_prior={"u_ema": float(base.u_ema), "k_ema": float(base.k_ema)},
+    )
+
+    # (5) Execute reuse with invariance fallback (baseline output is expected_output_text).
+    calls_total = 0
+    fallbacks_total = 0
+    mismatches_total = 0
+    pass_before = 0
+    pass_after = 0
+
+    # Wrapper CALL demo (nested call_depth): execute once on the first task if compatible.
+    spec_demo = tasks[0].get("expected_spec") if isinstance(tasks[0].get("expected_spec"), dict) else {}
+    if isinstance(spec_demo, dict):
+        try:
+            out_demo, vr_demo, _ = reg.call(
+                step=250,
+                concept_id=str(wrapper.id),
+                inputs=dict(spec_demo.get("inputs") or {}),
+                expected=dict(spec_demo),
+                context_signature="v66_wrapper_demo",
+                call_depth=0,
+                baseline_cost=3.0,
+                contract_active=False,
+            )
+            calls_total += 1
+            if not bool(vr_demo.passed):
+                _fail(f"ERROR: wrapper demo call failed: {vr_demo.reason}")
+        except Exception as e:
+            _fail(f"ERROR: wrapper demo call exception: {e}")
+
+    for i, t in enumerate(tasks):
+        task_id = str(t.get("task_id") or f"task_{i}")
+        spec = t.get("expected_spec") if isinstance(t.get("expected_spec"), dict) else {}
+        if not isinstance(spec, dict):
+            _fail(f"ERROR: missing expected_spec for task {task_id}")
+        baseline_out = str(spec.get("expected_output_text") or "")
+        if not baseline_out:
+            _fail(f"ERROR: missing expected_output_text for task {task_id}")
+
+        # Baseline utility check (deterministic).
+        vr_base = run_validator("plan_validator", baseline_out, spec)
+        if bool(vr_base.passed):
+            pass_before += 1
+
+        inputs = dict(spec.get("inputs") or {})
+        key = tuple(sorted(list(inputs.keys())))
+        pick = by_inputs.get(key)
+        if not pick:
+            mismatches_total += 1
+            fallbacks_total += 1
+            out_s = baseline_out
+        else:
+            out, vr, _ = reg.call(
+                step=300 + i,
+                concept_id=str(pick),
+                inputs=dict(inputs),
+                expected=dict(spec),
+                context_signature=f"v66_reuse␟task={task_id}",
+                call_depth=0,
+                baseline_cost=3.0,
+                contract_active=False,
+            )
+            calls_total += 1
+            out_s = "" if out is None else str(out)
+
+        if out_s != baseline_out:
+            mismatches_total += 1
+            fallbacks_total += 1
+            out_s = baseline_out
+
+        vr_after = run_validator("plan_validator", out_s, spec)
+        if bool(vr_after.passed):
+            pass_after += 1
+
+    # (6) Prune demonstration: misapply second concept until it is deactivated.
+    pruned_total = 0
+    stress_id = promoted_ids[1]
+    stress = reg.get(stress_id)
+    if stress is None:
+        _fail("ERROR: missing stress concept")
+    stress_key = tuple(sorted(list(stress.interface.input_schema.keys())))
+    spec_in: Dict[str, Any] = {}
+    spec_wrong: Dict[str, Any] = {}
+    for t in tasks:
+        s = t.get("expected_spec")
+        if not isinstance(s, dict):
+            continue
+        inp = s.get("inputs")
+        if not isinstance(inp, dict):
+            continue
+        k = tuple(sorted(list(inp.keys())))
+        if k == stress_key and not spec_in:
+            spec_in = dict(s)
+    for t in tasks:
+        s = t.get("expected_spec")
+        if not isinstance(s, dict):
+            continue
+        if not spec_in:
+            continue
+        if str(s.get("expected_output_text") or "") != str(spec_in.get("expected_output_text") or ""):
+            spec_wrong = dict(s)
+            break
+    if not spec_in or not spec_wrong:
+        _fail("ERROR: could not pick specs for prune demo")
+    for k in range(8):
+        step = 400 + k
+        out, vr, _ = reg.call(
+            step=int(step),
+            concept_id=str(stress.id),
+            inputs=dict(spec_in.get("inputs") or {}),
+            expected=dict(spec_wrong),
+            context_signature="v66_force_prune",
+            call_depth=0,
+            baseline_cost=3.0,
+            contract_active=False,
+        )
+        calls_total += 1
+        if bool(vr.passed):
+            _fail("ERROR: expected stress call to fail")
+        if not bool(stress.alive):
+            pruned_total = 1
+            break
+
+    if pruned_total < 1:
+        _fail("ERROR: expected >=1 concept pruned")
+
+    chains_ok = reg.verify_chains()
+    promotion_chain_ok = bool(all(bool(v) for v in chains_ok.values()))
+    invariance_ok = bool(mismatches_total == 0)
+
+    utility_before = float(pass_before / max(1, len(tasks)))
+    utility_after = float(pass_after / max(1, len(tasks)))
+
+    # Top concepts snapshot.
+    top_concepts: List[Dict[str, Any]] = []
+    alive = list(reg.alive_concepts())
+    alive.sort(key=lambda c: (-float(c.u_ema), float(c.k_ema), str(c.id)))
+    for c in alive[:5]:
+        top_concepts.append(
+            {
+                "concept_id": str(c.id),
+                "alive": bool(c.alive),
+                "calls_total": int(c.calls_total),
+                "u_ema": float(c.u_ema),
+                "k_ema": float(c.k_ema),
+                "s_t": float(c.s_t),
+                "contexts_distinct": int(c.contexts_distinct()),
+                "validator_id": str(c.interface.validator_id),
+                "subgraph_kind": str(c.subgraph_ref.get("kind") or ""),
+            }
+        )
+
+    summary = {
+        "seed": int(args.seed),
+        "tasks_total": int(len(tasks)),
+        "births_total": int(births_total),
+        "promoted_total": int(len(promoted_ids)),
+        "calls_total": int(calls_total),
+        "pruned_total": int(pruned_total),
+        "fallbacks_total": int(fallbacks_total),
+        "mismatches_total": int(mismatches_total),
+        "invariance_ok": bool(invariance_ok),
+        "promotion_chain_ok": bool(promotion_chain_ok),
+        "utility_before": float(utility_before),
+        "utility_after": float(utility_after),
+        "chains_ok": dict(chains_ok),
+        "top_concepts": list(top_concepts),
+        "artifacts": {
+            "csv_exec_v66_jsonl": str(csv_exec_path),
+            "mined_candidates_json": str(mined_candidates_path),
+            "concepts_jsonl": str(reg.concepts_path),
+            "concept_evidence_jsonl": str(reg.evidence_path),
+            "concept_telemetry_jsonl": str(reg.telemetry_path),
+        },
+        "sha256": {
+            "csv_exec_v66_jsonl": str(csv_exec_sha),
+            "mined_candidates_json": str(mined_candidates_sha),
+            "concepts_jsonl": str(sha256_file(reg.concepts_path)),
+            "concept_evidence_jsonl": str(sha256_file(reg.evidence_path)),
+            "concept_telemetry_jsonl": str(sha256_file(reg.telemetry_path)),
+        },
+    }
+
+    summary_path = os.path.join(out_dir, "summary.json")
+    summary_sha = write_json(summary_path, {"summary": summary})
+    out = {"out_dir": out_dir, "summary": summary}
+    print(json.dumps(out, ensure_ascii=False, indent=2, sort_keys=True))
+
+
+if __name__ == "__main__":
+    main()
