--- /dev/null	2026-01-15 15:17:55
+++ atos_core/conversation_loop_v117.py	2026-01-15 15:04:20
@@ -0,0 +1,580 @@
+from __future__ import annotations
+
+import hashlib
+import json
+import os
+import shutil
+from dataclasses import dataclass
+from typing import Any, Dict, List, Optional, Sequence, Tuple
+
+from .act import canonical_json_dumps, deterministic_iso, sha256_hex
+from .ato_v71 import ATOv71, stable_hash_obj
+from .conversation_loop_v116 import run_conversation_v116
+from .goal_persistence_v115 import goal_id_v115, render_fail_response_v115
+from .mind_graph_v71 import append_chained_jsonl, verify_chained_jsonl
+
+FAIL_REASON_EXHAUSTED_PLANS_V117 = "exhausted_plans"
+FAIL_REASON_PLAN_SEARCH_BUDGET_EXHAUSTED_V117 = "plan_search_budget_exhausted"
+FAIL_REASON_DUPLICATE_PLAN_CANDIDATE_V117 = "duplicate_plan_candidate"
+
+
+def _ensure_absent(path: str) -> None:
+    if os.path.exists(path):
+        raise ValueError(f"worm_exists:{path}")
+
+
+def _sha256_file(path: str) -> str:
+    h = hashlib.sha256()
+    with open(path, "rb") as f:
+        while True:
+            b = f.read(1024 * 1024)
+            if not b:
+                break
+            h.update(b)
+    return h.hexdigest()
+
+
+def _write_once_json(path: str, obj: Any) -> None:
+    _ensure_absent(path)
+    tmp = path + ".tmp"
+    if os.path.exists(tmp):
+        raise ValueError(f"tmp_exists:{tmp}")
+    with open(tmp, "w", encoding="utf-8") as f:
+        f.write(json.dumps(obj, ensure_ascii=False, indent=2, sort_keys=True))
+        f.write("\n")
+    os.replace(tmp, path)
+
+
+def _read_json(path: str) -> Any:
+    with open(path, "r", encoding="utf-8") as f:
+        return json.loads(f.read())
+
+
+def _read_jsonl(path: str) -> List[Dict[str, Any]]:
+    out: List[Dict[str, Any]] = []
+    if not os.path.exists(path):
+        return out
+    with open(path, "r", encoding="utf-8") as f:
+        for line in f:
+            line = line.strip()
+            if not line:
+                continue
+            out.append(json.loads(line))
+    return out
+
+
+def _copy_file_worm(src: str, dst: str) -> None:
+    _ensure_absent(dst)
+    with open(src, "rb") as f:
+        data = f.read()
+    tmp = dst + ".tmp"
+    if os.path.exists(tmp):
+        raise ValueError(f"tmp_exists:{tmp}")
+    with open(tmp, "wb") as f:
+        f.write(data)
+    os.replace(tmp, dst)
+
+
+def _copy_tree_worm(src_dir: str, dst_dir: str) -> None:
+    _ensure_absent(dst_dir)
+    shutil.copytree(src_dir, dst_dir, dirs_exist_ok=False)
+
+
+def _promote_attempt_to_root(*, attempt_dir: str, out_dir: str) -> None:
+    """
+    Copy a chosen attempt run_dir into the V117 out_dir root (WORM).
+    This keeps V110/V115/V116 file layouts available at the top-level for downstream tooling.
+    """
+    ad = str(attempt_dir)
+    od = str(out_dir)
+    for name in sorted(os.listdir(ad), key=str):
+        src = os.path.join(ad, name)
+        dst = os.path.join(od, name)
+        if os.path.isdir(src):
+            # Do not copy nested attempt dirs (none expected), only regular directories (e.g., mind_graph_v116).
+            if name.startswith("attempt_") or name.startswith("replan_attempt_"):
+                continue
+            _copy_tree_worm(src, dst)
+        else:
+            _copy_file_worm(src, dst)
+
+
+def _extract_last_user_turn_payload(run_dir: str) -> Dict[str, Any]:
+    rows = _read_jsonl(os.path.join(str(run_dir), "conversation_turns.jsonl"))
+    users: List[Dict[str, Any]] = []
+    for row in rows:
+        if not isinstance(row, dict):
+            continue
+        payload = row.get("payload")
+        if not isinstance(payload, dict):
+            continue
+        if str(payload.get("role") or "") == "user":
+            users.append(dict(payload))
+    if not users:
+        return {}
+    users.sort(key=lambda p: (int(p.get("turn_index", 0) or 0), int(p.get("created_step", 0) or 0), str(p.get("turn_id") or "")))
+    return dict(users[-1])
+
+
+def _plan_row_for_user_turn(run_dir: str, user_turn_id: str) -> Dict[str, Any]:
+    rows = _read_jsonl(os.path.join(str(run_dir), "action_plans.jsonl"))
+    for row in rows:
+        if not isinstance(row, dict):
+            continue
+        if str(row.get("user_turn_id") or "") == str(user_turn_id):
+            return dict(row)
+    return {}
+
+
+def _expected_cost_for_act(plan_row: Dict[str, Any], act_id: str) -> float:
+    ranked = plan_row.get("ranked_candidates") if isinstance(plan_row.get("ranked_candidates"), list) else []
+    for r in ranked:
+        if not isinstance(r, dict):
+            continue
+        if str(r.get("act_id") or "") == str(act_id):
+            try:
+                return float(r.get("expected_cost") or 0.0)
+            except Exception:
+                return 0.0
+    return 0.0
+
+
+def _plan_hash_from_row(plan_row: Dict[str, Any]) -> str:
+    pid = str(plan_row.get("plan_id") or "")
+    psig = str(plan_row.get("plan_sig") or "")
+    if psig:
+        return str(psig)
+    if pid.startswith("action_plan_v96_"):
+        return pid[len("action_plan_v96_") :]
+    return sha256_hex(canonical_json_dumps(plan_row).encode("utf-8"))
+
+
+def _make_fail_event_ato_v117(
+    *,
+    conversation_id: str,
+    user_turn_id: str,
+    goal_ato_id: str,
+    plan_ato_id: str,
+    reason_code: str,
+    step: int,
+    evidence: Dict[str, Any],
+) -> ATOv71:
+    body = {
+        "schema_version": 117,
+        "conversation_id": str(conversation_id),
+        "user_turn_id": str(user_turn_id),
+        "goal_ato_id": str(goal_ato_id),
+        "plan_ato_id": str(plan_ato_id),
+        "reason_code": str(reason_code),
+        "evidence": dict(evidence) if isinstance(evidence, dict) else {},
+    }
+    fail_id = "fail_event_v117_" + sha256_hex(canonical_json_dumps(body).encode("utf-8"))
+    return ATOv71(
+        ato_id=str(fail_id),
+        ato_type="EVAL",
+        subgraph=dict(body, satisfies=False),
+        slots={},
+        bindings={},
+        cost=0.0,
+        evidence_refs=[{"kind": "turn", "turn_id": str(user_turn_id)}] if user_turn_id else [],
+        invariants={"schema_version": 117, "eval_kind": "FAIL_EVENT_V117"},
+        created_step=int(step),
+        last_step=int(step),
+    )
+
+
+def _make_plan_ato_v117(*, plan_row: Dict[str, Any]) -> ATOv71:
+    plan_id = str(plan_row.get("plan_id") or plan_row.get("plan_sig") or "")
+    if not plan_id:
+        raise ValueError("missing_plan_id")
+    created_step = int(plan_row.get("created_step", 0) or 0)
+    user_turn_id = str(plan_row.get("user_turn_id") or "")
+    ranked = plan_row.get("ranked_candidates") if isinstance(plan_row.get("ranked_candidates"), list) else []
+    attempted = plan_row.get("attempted_actions") if isinstance(plan_row.get("attempted_actions"), list) else []
+    subgraph = {
+        "schema_version": 117,
+        "plan_id": str(plan_id),
+        "user_turn_id": str(user_turn_id),
+        "user_turn_index": int(plan_row.get("user_turn_index", -1) or -1),
+        "chosen_action_id": str(plan_row.get("chosen_action_id") or ""),
+        "chosen_eval_id": str(plan_row.get("chosen_eval_id") or ""),
+        "chosen_ok": bool(plan_row.get("chosen_ok", False)),
+        "ranked_candidates": [
+            {
+                "act_id": str(r.get("act_id") or ""),
+                "expected_success": float(r.get("expected_success", 0.0) or 0.0),
+                "expected_cost": float(r.get("expected_cost", 0.0) or 0.0),
+            }
+            for r in ranked
+            if isinstance(r, dict) and str(r.get("act_id") or "")
+        ],
+        "attempted_actions": [
+            {"act_id": str(a.get("act_id") or ""), "eval_id": str(a.get("eval_id") or ""), "ok": bool(a.get("ok", False))}
+            for a in attempted
+            if isinstance(a, dict) and str(a.get("act_id") or "")
+        ],
+    }
+    # Deterministic ordering inside subgraph.
+    subgraph["ranked_candidates"].sort(key=lambda d: (str(d.get("act_id") or "")))
+    subgraph["attempted_actions"].sort(key=lambda d: (str(d.get("eval_id") or ""), str(d.get("act_id") or "")))
+    return ATOv71(
+        ato_id=str(plan_id),
+        ato_type="PLAN",
+        subgraph=dict(subgraph),
+        slots={},
+        bindings={},
+        cost=float(len(subgraph.get("ranked_candidates") or [])),
+        evidence_refs=[{"kind": "turn", "turn_id": str(user_turn_id)}] if user_turn_id else [],
+        invariants={"schema_version": 117, "plan_kind": "action_plan_v100"},
+        created_step=int(created_step),
+        last_step=int(created_step),
+    )
+
+
+def _last_entry_hash(path: str) -> str:
+    last = ""
+    if not os.path.exists(path):
+        return last
+    with open(path, "r", encoding="utf-8") as f:
+        for line in f:
+            line = line.strip()
+            if not line:
+                continue
+            obj = json.loads(line)
+            if isinstance(obj, dict):
+                last = str(obj.get("entry_hash") or last)
+    return str(last)
+
+
+def _append_fail_event_to_mind_graph_v117(
+    *,
+    mind_graph_v117_dir: str,
+    fail_ato: ATOv71,
+    goal_ato_id: str,
+    plan_ato_id: str,
+    user_turn_id: str,
+    step: int,
+    evidence_refs: List[Dict[str, Any]],
+) -> Dict[str, Any]:
+    mg_dir = str(mind_graph_v117_dir)
+    nodes_path = os.path.join(mg_dir, "mind_nodes.jsonl")
+    edges_path = os.path.join(mg_dir, "mind_edges.jsonl")
+    if not os.path.exists(nodes_path) or not os.path.exists(edges_path):
+        raise ValueError("missing_mind_graph_v117_files")
+
+    prev_nodes_hash = _last_entry_hash(nodes_path) or None
+    fail_ato_dict = fail_ato.to_dict(include_sig=True)
+    nodes_entry = {
+        "time": deterministic_iso(step=int(step)),
+        "step": int(step),
+        "event": "NODE",
+        "payload": {"reason": "fail_event_v117", "ato": dict(fail_ato_dict)},
+    }
+    new_nodes_hash = append_chained_jsonl(nodes_path, dict(nodes_entry), prev_hash=prev_nodes_hash)
+
+    # Deterministic edges: FAIL -> GOAL, FAIL -> PLAN, FAIL -> TURN.
+    prev_edges_hash = _last_entry_hash(edges_path) or None
+    ev_refs_sorted = sorted([dict(x) for x in evidence_refs if isinstance(x, dict)], key=lambda d: canonical_json_dumps(d))
+
+    def _mk_edge(dst: str) -> Dict[str, Any]:
+        edge_sem_sig = {"src": str(fail_ato.ato_id), "dst": str(dst), "edge_type": "DERIVED_FROM", "evidence_refs": list(ev_refs_sorted)}
+        return dict(edge_sem_sig, edge_sig=str(stable_hash_obj(edge_sem_sig)))
+
+    dsts = [str(goal_ato_id), str(plan_ato_id), str(user_turn_id)]
+    appended = 0
+    for dst in sorted(set([d for d in dsts if d]), key=str):
+        edge = _mk_edge(dst=str(dst))
+        edge_entry = {"time": deterministic_iso(step=int(step)), "step": int(step), "event": "EDGE", "payload": {"reason": "fail_edges_v117", "edge": dict(edge)}}
+        prev_edges_hash = append_chained_jsonl(edges_path, dict(edge_entry), prev_hash=prev_edges_hash)
+        appended += 1
+
+    return {"nodes_entry_hash": str(new_nodes_hash), "edges_appended_total": int(appended)}
+
+
+@dataclass(frozen=True)
+class AttemptRecordV117:
+    attempt_index: int
+    seed_used: int
+    attempt_dir: str
+    goal_id: str
+    user_turn_id: str
+    plan_id: str
+    plan_hash: str
+    plan_cost: float
+    eval_satisfies: bool
+    dialogue_survival_ok: bool
+    fail_reason_code: str
+
+    def to_dict(self) -> Dict[str, Any]:
+        return {
+            "attempt_index": int(self.attempt_index),
+            "seed_used": int(self.seed_used),
+            "attempt_dir": str(self.attempt_dir),
+            "goal_id": str(self.goal_id),
+            "user_turn_id": str(self.user_turn_id),
+            "plan_id": str(self.plan_id),
+            "plan_hash": str(self.plan_hash),
+            "plan_cost": float(self.plan_cost),
+            "eval_satisfies": bool(self.eval_satisfies),
+            "dialogue_survival_ok": bool(self.dialogue_survival_ok),
+            "fail_reason_code": str(self.fail_reason_code),
+        }
+
+
+def _replan_trace_obj_v117(
+    *,
+    conversation_id: str,
+    attempts: List[AttemptRecordV117],
+    chosen_attempt_index: int,
+    budget_total: int,
+    final_ok: bool,
+    final_reason: str,
+) -> Dict[str, Any]:
+    body = {
+        "schema_version": 117,
+        "kind": "replan_trace_v117",
+        "conversation_id": str(conversation_id),
+        "budget_total": int(budget_total),
+        "chosen_attempt_index": int(chosen_attempt_index),
+        "final_ok": bool(final_ok),
+        "final_reason": str(final_reason),
+        "attempts": [a.to_dict() for a in list(attempts)],
+    }
+    body["trace_sig"] = sha256_hex(canonical_json_dumps(body).encode("utf-8"))
+    return dict(body)
+
+
+def run_conversation_v117(
+    *,
+    user_turn_texts: Sequence[str],
+    out_dir: str,
+    seed: int,
+    max_plan_attempts: int = 8,
+    max_replans_per_turn: int = 3,
+) -> Dict[str, Any]:
+    """
+    V117 wrapper around V116 enforcing "replan until satisfies or exhaust/budget".
+
+    Strategy (minimal, deterministic, WORM):
+      - run up to `max_plan_attempts` full V116 attempts with seeds: seed+0, seed+1, ...
+      - select the first attempt that yields final_response_v116.ok==true;
+      - if none succeed: FAIL with reason plan_search_budget_exhausted (no proof of impossibility).
+
+    The chosen attempt's artifacts are promoted (copied) into the V117 out_dir root (WORM),
+    and a replan trace + mind_graph_v117 are written for auditability.
+    """
+    od = str(out_dir)
+    _ensure_absent(od)
+    os.makedirs(od, exist_ok=False)
+
+    attempts: List[AttemptRecordV117] = []
+    chosen_attempt = -1
+    conversation_id_seen = ""
+
+    for a in range(int(max_plan_attempts)):
+        seed_used = int(seed) + int(a)
+        attempt_dir = os.path.join(od, f"attempt_{a:03d}")
+        conv = run_conversation_v116(
+            user_turn_texts=list(user_turn_texts),
+            out_dir=str(attempt_dir),
+            seed=int(seed_used),
+            max_replans_per_turn=int(max_replans_per_turn),
+        )
+        fr_path = os.path.join(str(attempt_dir), "final_response_v116.json")
+        fr = _read_json(fr_path) if os.path.exists(fr_path) else {}
+        ok_final = bool(fr.get("ok", False)) if isinstance(fr, dict) else False
+        reason_final = str(fr.get("reason") or "") if isinstance(fr, dict) else "missing_final_response_v116"
+
+        last_user = _extract_last_user_turn_payload(str(attempt_dir))
+        user_turn_id = str(last_user.get("turn_id") or "")
+        conversation_id = str(last_user.get("conversation_id") or str(conv.get("conversation_id") or ""))
+        if conversation_id and not conversation_id_seen:
+            conversation_id_seen = str(conversation_id)
+        user_turn_index = int(last_user.get("turn_index", 0) or 0)
+        refs = last_user.get("refs") if isinstance(last_user.get("refs"), dict) else {}
+        parse_sig = str(refs.get("parse_sig") or "")
+        user_text = str(last_user.get("text") or "")
+        goal_id = goal_id_v115(
+            conversation_id=str(conversation_id),
+            user_turn_id=str(user_turn_id),
+            user_turn_index=int(user_turn_index),
+            parse_sig=str(parse_sig),
+            user_text=str(user_text),
+        )
+        plan_row = _plan_row_for_user_turn(str(attempt_dir), user_turn_id)
+        plan_id = str(plan_row.get("plan_id") or plan_row.get("plan_sig") or "")
+        plan_hash = _plan_hash_from_row(dict(plan_row))
+        chosen_action = str(plan_row.get("chosen_action_id") or "")
+        plan_cost = _expected_cost_for_act(dict(plan_row), str(chosen_action)) if chosen_action else 0.0
+        eval_satisfies = bool(fr.get("gate_v115_ok", False)) if isinstance(fr, dict) else False
+        dialogue_ok = bool(fr.get("dialogue_survival_ok", False)) if isinstance(fr, dict) else False
+
+        attempts.append(
+            AttemptRecordV117(
+                attempt_index=int(a),
+                seed_used=int(seed_used),
+                attempt_dir=os.path.basename(str(attempt_dir)),
+                goal_id=str(goal_id),
+                user_turn_id=str(user_turn_id),
+                plan_id=str(plan_id),
+                plan_hash=str(plan_hash),
+                plan_cost=float(plan_cost),
+                eval_satisfies=bool(eval_satisfies),
+                dialogue_survival_ok=bool(dialogue_ok),
+                fail_reason_code=str(reason_final) if not ok_final else "",
+            )
+        )
+
+        if ok_final:
+            chosen_attempt = int(a)
+            break
+
+    if not attempts:
+        raise ValueError("no_attempts_v117")
+
+    final_ok = chosen_attempt >= 0
+    final_reason = "ok" if final_ok else FAIL_REASON_PLAN_SEARCH_BUDGET_EXHAUSTED_V117
+    chosen_idx = int(chosen_attempt if chosen_attempt >= 0 else (len(attempts) - 1))
+    chosen_attempt_dirname = f"attempt_{chosen_idx:03d}"
+    chosen_attempt_dir = os.path.join(od, chosen_attempt_dirname)
+
+    # Promote chosen attempt artifacts to root (WORM).
+    _promote_attempt_to_root(attempt_dir=str(chosen_attempt_dir), out_dir=str(od))
+
+    # Write replanning trace (WORM).
+    rep_obj = _replan_trace_obj_v117(
+        conversation_id=str(conversation_id_seen),
+        attempts=list(attempts),
+        chosen_attempt_index=int(chosen_attempt if chosen_attempt >= 0 else -1),
+        budget_total=int(max_plan_attempts),
+        final_ok=bool(final_ok),
+        final_reason=str(final_reason),
+    )
+    _write_once_json(os.path.join(od, "replan_trace_v117.json"), dict(rep_obj))
+
+    # Create mind_graph_v117 by copying the promoted mind_graph_v116 and appending per-attempt FAIL_EVENT_V117 nodes/edges.
+    mg116_dir = os.path.join(od, "mind_graph_v116")
+    mg117_dir = os.path.join(od, "mind_graph_v117")
+    if os.path.isdir(mg116_dir):
+        os.makedirs(mg117_dir, exist_ok=False)
+        _copy_file_worm(os.path.join(mg116_dir, "mind_nodes.jsonl"), os.path.join(mg117_dir, "mind_nodes.jsonl"))
+        _copy_file_worm(os.path.join(mg116_dir, "mind_edges.jsonl"), os.path.join(mg117_dir, "mind_edges.jsonl"))
+
+        # Append fail events for each failed attempt (including duplicates) deterministically by attempt_index.
+        nodes_path = os.path.join(mg117_dir, "mind_nodes.jsonl")
+        edges_path = os.path.join(mg117_dir, "mind_edges.jsonl")
+        if not verify_chained_jsonl(nodes_path) or not verify_chained_jsonl(edges_path):
+            raise ValueError("mind_graph_v117_chain_invalid_after_copy")
+
+        # Ensure referenced nodes exist (goal + turn are from chosen attempt; plan nodes may differ).
+        # We append plan nodes for failed attempts if missing.
+        existing_nodes: Dict[str, Dict[str, Any]] = {}
+        for row in _read_jsonl(nodes_path):
+            payload = row.get("payload") if isinstance(row, dict) else None
+            if not isinstance(payload, dict):
+                continue
+            ato = payload.get("ato")
+            if not isinstance(ato, dict):
+                continue
+            ato_id = str(ato.get("ato_id") or "")
+            if ato_id:
+                existing_nodes[ato_id] = dict(ato)
+
+        # Use chosen attempt's last user turn as the canonical turn reference.
+        chosen_last_user = _extract_last_user_turn_payload(str(chosen_attempt_dir))
+        chosen_user_turn_id = str(chosen_last_user.get("turn_id") or "")
+        chosen_conversation_id = str(chosen_last_user.get("conversation_id") or "")
+        chosen_user_turn_index = int(chosen_last_user.get("turn_index", 0) or 0)
+        chosen_refs = chosen_last_user.get("refs") if isinstance(chosen_last_user.get("refs"), dict) else {}
+        chosen_parse_sig = str(chosen_refs.get("parse_sig") or "")
+        chosen_user_text = str(chosen_last_user.get("text") or "")
+        chosen_goal_id = goal_id_v115(
+            conversation_id=str(chosen_conversation_id),
+            user_turn_id=str(chosen_user_turn_id),
+            user_turn_index=int(chosen_user_turn_index),
+            parse_sig=str(chosen_parse_sig),
+            user_text=str(chosen_user_text),
+        )
+        # chosen plan id from chosen attempt plan row.
+        chosen_plan_row = _plan_row_for_user_turn(str(chosen_attempt_dir), str(chosen_user_turn_id))
+        chosen_plan_id = str(chosen_plan_row.get("plan_id") or chosen_plan_row.get("plan_sig") or "")
+
+        for ar in list(attempts):
+            if ar.attempt_index == chosen_attempt:
+                continue
+            if not ar.fail_reason_code:
+                continue
+            # Add plan node (from that attempt) if not present.
+            plan_id = str(ar.plan_id or "")
+            if plan_id and plan_id not in existing_nodes:
+                plan_row = _plan_row_for_user_turn(os.path.join(od, str(ar.attempt_dir)), str(ar.user_turn_id))
+                if isinstance(plan_row, dict) and plan_row:
+                    plan_ato = _make_plan_ato_v117(plan_row=dict(plan_row))
+                    prev_nodes_hash = _last_entry_hash(nodes_path) or None
+                    plan_dict = plan_ato.to_dict(include_sig=True)
+                    nodes_entry = {
+                        "time": deterministic_iso(step=int(plan_ato.created_step)),
+                        "step": int(plan_ato.created_step),
+                        "event": "NODE",
+                        "payload": {"reason": "plan_import_v117", "ato": dict(plan_dict)},
+                    }
+                    append_chained_jsonl(nodes_path, dict(nodes_entry), prev_hash=prev_nodes_hash)
+                    existing_nodes[plan_id] = dict(plan_dict)
+
+            # Append FAIL_EVENT_V117 node/edges.
+            evidence = {
+                "attempt_index": int(ar.attempt_index),
+                "seed_used": int(ar.seed_used),
+                "attempt_dir": str(ar.attempt_dir),
+                "plan_hash": str(ar.plan_hash),
+                "replan_trace_sig": str(rep_obj.get("trace_sig") or ""),
+                "replan_trace_file": "replan_trace_v117.json",
+            }
+            step0 = int(chosen_last_user.get("created_step", 0) or 0)
+            fail_ato = _make_fail_event_ato_v117(
+                conversation_id=str(chosen_conversation_id),
+                user_turn_id=str(chosen_user_turn_id),
+                goal_ato_id=str(chosen_goal_id),
+                plan_ato_id=str(plan_id or chosen_plan_id),
+                reason_code=str(ar.fail_reason_code),
+                step=int(step0),
+                evidence=dict(evidence),
+            )
+            _append_fail_event_to_mind_graph_v117(
+                mind_graph_v117_dir=str(mg117_dir),
+                fail_ato=fail_ato,
+                goal_ato_id=str(chosen_goal_id),
+                plan_ato_id=str(plan_id or chosen_plan_id),
+                user_turn_id=str(chosen_user_turn_id),
+                step=int(step0),
+                evidence_refs=[
+                    {"kind": "turn", "turn_id": str(chosen_user_turn_id)},
+                    {"kind": "replan_trace", "trace_sig": str(rep_obj.get("trace_sig") or "")},
+                ],
+            )
+
+        if not verify_chained_jsonl(nodes_path) or not verify_chained_jsonl(edges_path):
+            raise ValueError("mind_graph_v117_chain_invalid_after_append")
+
+    # Write final_response_v117.json (WORM).
+    fail_text = ""
+    if not final_ok:
+        fail_text = render_fail_response_v115(str(final_reason))
+    fr117 = {
+        "schema_version": 117,
+        "kind": "final_response_v117",
+        "ok": bool(final_ok),
+        "reason": str(final_reason if not final_ok else "ok"),
+        "fail_response_text": str(fail_text),
+        "chosen_attempt_index": int(chosen_attempt if chosen_attempt >= 0 else -1),
+        "budget_total": int(max_plan_attempts),
+    }
+    fr117["final_sig"] = sha256_hex(canonical_json_dumps(fr117).encode("utf-8"))
+    _write_once_json(os.path.join(od, "final_response_v117.json"), dict(fr117))
+
+    out: Dict[str, Any] = {"final_response_v117": dict(fr117), "replan_trace_v117_sig": str(rep_obj.get("trace_sig") or "")}
+    out["attempts_total_v117"] = int(len(attempts))
+    out["chosen_attempt_v117"] = int(chosen_attempt if chosen_attempt >= 0 else -1)
+    out["gate_v117_ok"] = bool(final_ok)
+    out["gate_v117_reason"] = str(final_reason)
+    return dict(out)
--- /dev/null	2026-01-15 15:17:55
+++ atos_core/replan_law_v117.py	2026-01-15 15:00:04
@@ -0,0 +1,195 @@
+from __future__ import annotations
+
+import json
+import os
+from dataclasses import dataclass
+from typing import Any, Callable, Dict, List, Optional, Sequence, Set, Tuple
+
+from .act import canonical_json_dumps, sha256_hex
+
+REPLAN_REASON_OK_V117 = "ok"
+REPLAN_REASON_EXHAUSTED_PLANS_V117 = "exhausted_plans"
+REPLAN_REASON_PLAN_SEARCH_BUDGET_EXHAUSTED_V117 = "plan_search_budget_exhausted"
+REPLAN_REASON_DUPLICATE_PLAN_CANDIDATE_V117 = "duplicate_plan_candidate"
+
+
+def _ensure_absent(path: str) -> None:
+    if os.path.exists(path):
+        raise ValueError(f"worm_exists:{path}")
+
+
+def _write_once_json(path: str, obj: Any) -> None:
+    _ensure_absent(path)
+    tmp = path + ".tmp"
+    if os.path.exists(tmp):
+        raise ValueError(f"tmp_exists:{tmp}")
+    with open(tmp, "w", encoding="utf-8") as f:
+        f.write(json.dumps(obj, ensure_ascii=False, indent=2, sort_keys=True))
+        f.write("\n")
+    os.replace(tmp, path)
+
+
+def plan_hash_v117(plan_sem_sig: Dict[str, Any]) -> str:
+    return sha256_hex(canonical_json_dumps(plan_sem_sig).encode("utf-8"))
+
+
+@dataclass(frozen=True)
+class PlanCandidateV117:
+    plan_id: str
+    plan_cost: float
+    plan_sem_sig: Dict[str, Any]
+
+    def to_dict(self) -> Dict[str, Any]:
+        sem = {
+            "plan_id": str(self.plan_id),
+            "plan_cost": float(self.plan_cost),
+            "plan_sem_sig": dict(self.plan_sem_sig) if isinstance(self.plan_sem_sig, dict) else {},
+        }
+        sem["plan_hash"] = plan_hash_v117(dict(sem["plan_sem_sig"]))
+        return dict(sem)
+
+
+@dataclass(frozen=True)
+class PlanAttemptV117:
+    attempt_index: int
+    plan_id: str
+    plan_hash: str
+    plan_cost: float
+    eval_satisfies: bool
+    dialogue_survival_ok: bool
+    fail_reason_code: str
+
+    def to_dict(self) -> Dict[str, Any]:
+        return {
+            "attempt_index": int(self.attempt_index),
+            "plan_id": str(self.plan_id),
+            "plan_hash": str(self.plan_hash),
+            "plan_cost": float(self.plan_cost),
+            "eval_satisfies": bool(self.eval_satisfies),
+            "dialogue_survival_ok": bool(self.dialogue_survival_ok),
+            "fail_reason_code": str(self.fail_reason_code),
+        }
+
+
+@dataclass(frozen=True)
+class ReplanResultV117:
+    ok: bool
+    reason: str
+    attempts_total: int
+    attempts: List[PlanAttemptV117]
+    chosen_plan_hash: str
+    budget_total: int
+
+    def to_dict(self) -> Dict[str, Any]:
+        return {
+            "schema_version": 117,
+            "kind": "replan_result_v117",
+            "ok": bool(self.ok),
+            "reason": str(self.reason),
+            "attempts_total": int(self.attempts_total),
+            "attempts": [a.to_dict() for a in list(self.attempts)],
+            "chosen_plan_hash": str(self.chosen_plan_hash),
+            "budget_total": int(self.budget_total),
+        }
+
+
+def replan_until_satisfies_v117(
+    *,
+    next_plan: Callable[[], Optional[PlanCandidateV117]],
+    exec_plan: Callable[[PlanCandidateV117], Tuple[bool, bool, str]],
+    max_attempts: int,
+) -> ReplanResultV117:
+    """
+    Deterministic replanning loop:
+      - enumerates plan candidates in the caller-provided order,
+      - never retries a duplicate plan_hash,
+      - stops only on SATISFIES+dialogue_ok, enumerator exhaustion, or budget exhaustion.
+
+    exec_plan returns: (eval_satisfies, dialogue_survival_ok, fail_reason_code).
+    """
+    if int(max_attempts) <= 0:
+        raise ValueError("max_attempts_must_be_positive")
+
+    tried: Set[str] = set()
+    attempts: List[PlanAttemptV117] = []
+
+    while True:
+        if int(len(attempts)) >= int(max_attempts):
+            return ReplanResultV117(
+                ok=False,
+                reason=REPLAN_REASON_PLAN_SEARCH_BUDGET_EXHAUSTED_V117,
+                attempts_total=int(len(attempts)),
+                attempts=list(attempts),
+                chosen_plan_hash="",
+                budget_total=int(max_attempts),
+            )
+
+        cand = next_plan()
+        if cand is None:
+            return ReplanResultV117(
+                ok=False,
+                reason=REPLAN_REASON_EXHAUSTED_PLANS_V117,
+                attempts_total=int(len(attempts)),
+                attempts=list(attempts),
+                chosen_plan_hash="",
+                budget_total=int(max_attempts),
+            )
+
+        cand_dict = cand.to_dict()
+        ph = str(cand_dict.get("plan_hash") or "")
+        if not ph:
+            ph = plan_hash_v117(cand.plan_sem_sig if isinstance(cand.plan_sem_sig, dict) else {})
+
+        if ph in tried:
+            attempts.append(
+                PlanAttemptV117(
+                    attempt_index=int(len(attempts)),
+                    plan_id=str(cand.plan_id),
+                    plan_hash=str(ph),
+                    plan_cost=float(cand.plan_cost),
+                    eval_satisfies=False,
+                    dialogue_survival_ok=False,
+                    fail_reason_code=REPLAN_REASON_DUPLICATE_PLAN_CANDIDATE_V117,
+                )
+            )
+            continue
+
+        tried.add(ph)
+        eval_ok, dialogue_ok, fail_reason = exec_plan(cand)
+        attempts.append(
+            PlanAttemptV117(
+                attempt_index=int(len(attempts)),
+                plan_id=str(cand.plan_id),
+                plan_hash=str(ph),
+                plan_cost=float(cand.plan_cost),
+                eval_satisfies=bool(eval_ok),
+                dialogue_survival_ok=bool(dialogue_ok),
+                fail_reason_code=str(fail_reason or ""),
+            )
+        )
+
+        if bool(eval_ok) and bool(dialogue_ok):
+            return ReplanResultV117(
+                ok=True,
+                reason=REPLAN_REASON_OK_V117,
+                attempts_total=int(len(attempts)),
+                attempts=list(attempts),
+                chosen_plan_hash=str(ph),
+                budget_total=int(max_attempts),
+            )
+
+
+def write_replan_trace_v117(*, path: str, goal_id: str, result: ReplanResultV117) -> Dict[str, Any]:
+    """
+    Persist a write-once replanning trace artifact.
+    """
+    body = {
+        "schema_version": 117,
+        "kind": "replan_trace_v117",
+        "goal_id": str(goal_id),
+        "result": dict(result.to_dict()),
+    }
+    body["trace_sig"] = sha256_hex(canonical_json_dumps(body).encode("utf-8"))
+    _write_once_json(str(path), dict(body))
+    return dict(body)
+
--- /dev/null	2026-01-15 15:17:55
+++ scripts/run_family7_dla_v117.py	2026-01-15 15:08:35
@@ -0,0 +1,456 @@
+#!/usr/bin/env python3
+from __future__ import annotations
+
+import argparse
+import hashlib
+import json
+import os
+import sys
+from pathlib import Path
+from typing import Any, Dict, List, Sequence, Tuple
+
+sys.path.insert(0, os.path.dirname(os.path.dirname(__file__)))
+
+from atos_core.act import canonical_json_dumps, sha256_hex
+from atos_core.conversation_loop_v117 import run_conversation_v117
+from atos_core.external_world_gating_v113 import external_world_access_v113
+from atos_core.external_world_ledger_v111 import (
+    EXTERNAL_WORLD_ACTION_SEARCH_V111,
+    EXTERNAL_WORLD_REASON_CODES_V111,
+    compute_external_world_chain_hash_v111,
+    verify_external_world_event_sig_chain_v111,
+)
+from atos_core.fluency_survival_v112 import fluency_contract_v112, fluency_survival_plan_v112, summarize_fluency_fail_code_v112
+
+
+def _fail(msg: str, *, code: int = 2) -> None:
+    print(msg, file=sys.stderr)
+    raise SystemExit(code)
+
+
+def _sha256_file(path: Path) -> str:
+    h = hashlib.sha256()
+    with open(path, "rb") as f:
+        while True:
+            b = f.read(1024 * 1024)
+            if not b:
+                break
+            h.update(b)
+    return h.hexdigest()
+
+
+def _ensure_absent(path: Path) -> None:
+    if path.exists():
+        _fail(f"worm_exists:{path}")
+
+
+ACK_TO_CHOICE_LABEL_V112 = {
+    "ok",
+    "okay",
+    "certo",
+    "beleza",
+    "blz",
+    "continua",
+    "continue",
+    "segue",
+    "vai",
+    "faz",
+    "pode",
+    "sim",
+}
+
+
+def _canon_ack_token_v112(s: str) -> str:
+    t = str(s or "").strip().lower()
+    t = " ".join([x for x in t.split() if x])
+    return t
+
+
+def _choiceify_minimal_ack_v112(user_turn_texts: Sequence[str]) -> List[str]:
+    out: List[str] = []
+    for s in user_turn_texts:
+        cs = _canon_ack_token_v112(str(s))
+        if cs in ACK_TO_CHOICE_LABEL_V112:
+            out.append("A")
+        else:
+            out.append(str(s))
+    return out
+
+
+def _load_jsonl_payload_view(path: Path) -> List[Dict[str, Any]]:
+    out: List[Dict[str, Any]] = []
+    if not path.exists():
+        return out
+    with open(path, "r", encoding="utf-8") as f:
+        for line in f:
+            line = line.strip()
+            if not line:
+                continue
+            obj = json.loads(line)
+            if not isinstance(obj, dict):
+                continue
+            payload = obj.get("payload")
+            if not isinstance(payload, dict):
+                continue
+            out.append(dict(payload))
+    return out
+
+
+def _load_json(path: Path) -> Any:
+    return json.loads(path.read_text(encoding="utf-8"))
+
+
+def _load_jsonl(path: Path) -> List[Dict[str, Any]]:
+    out: List[Dict[str, Any]] = []
+    if not path.exists():
+        return out
+    with open(path, "r", encoding="utf-8") as f:
+        for line in f:
+            line = line.strip()
+            if not line:
+                continue
+            out.append(json.loads(line))
+    return out
+
+
+def _write_once_json(path: Path, obj: Any) -> None:
+    _ensure_absent(path)
+    tmp = path.with_suffix(path.suffix + ".tmp")
+    if tmp.exists():
+        _fail(f"tmp_exists:{tmp}")
+    tmp.write_text(json.dumps(obj, ensure_ascii=False, indent=2, sort_keys=True) + "\n", encoding="utf-8")
+    os.replace(str(tmp), str(path))
+
+
+def _compute_external_world_access_once_v113(
+    *,
+    world_manifest: str,
+    reason_code: str,
+    query: str,
+    seed: int,
+) -> List[Dict[str, Any]]:
+    evs, _ = external_world_access_v113(
+        allowed=True,
+        world_manifest=str(world_manifest),
+        action=EXTERNAL_WORLD_ACTION_SEARCH_V111,
+        reason_code=str(reason_code),
+        args={"query": str(query), "limit": 3, "roles": ["user"]},
+        seed=int(seed),
+        turn_index=0,
+        prev_event_sig="",
+    )
+    return list(evs)
+
+
+def _count_unresolved_reference_events(binding_events: Sequence[Dict[str, Any]]) -> int:
+    bad = 0
+    for ev in binding_events:
+        if not isinstance(ev, dict):
+            continue
+        t = str(ev.get("type") or "")
+        if t in {"BIND_MISS", "BIND_AMBIGUOUS"}:
+            bad += 1
+    return int(bad)
+
+
+def _unresolved_reference_final_from_flow(flow_events: Sequence[Dict[str, Any]]) -> int:
+    if not flow_events:
+        return 0
+    last = flow_events[-1] if isinstance(flow_events[-1], dict) else {}
+    flags = last.get("flow_flags_v108")
+    if not isinstance(flags, dict):
+        return 0
+    return 1 if bool(flags.get("UNRESOLVED_REFERENCE")) else 0
+
+
+def _count_semantic_contradiction_flags(semantic_events: Sequence[Dict[str, Any]]) -> int:
+    cnt = 0
+    for ev in semantic_events:
+        if not isinstance(ev, dict):
+            continue
+        flags = ev.get("flags_v109")
+        if not isinstance(flags, dict):
+            continue
+        if bool(flags.get("CONTRADICTION_UNREPAIRED")):
+            cnt += 1
+    return int(cnt)
+
+
+def _write_external_world_ledger(*, task_dir: Path, events: Sequence[Dict[str, Any]]) -> Dict[str, Any]:
+    events_path = task_dir / "external_world_events.jsonl"
+    _ensure_absent(events_path)
+    if events:
+        with open(events_path, "x", encoding="utf-8") as f:
+            for e in events:
+                f.write(canonical_json_dumps(e))
+                f.write("\n")
+    else:
+        events_path.write_text("", encoding="utf-8")
+
+    ok_sig, reason_sig, _ = verify_external_world_event_sig_chain_v111(list(events))
+    if not ok_sig:
+        _fail(f"external_world_sig_chain_fail:{reason_sig}")
+    chain_hash = compute_external_world_chain_hash_v111(list(events))
+    snap = {
+        "schema_version": 111,
+        "kind": "external_world_registry_snapshot_v111",
+        "events_total": int(len(events)),
+        "external_world_chain_hash_v111": str(chain_hash),
+    }
+    snap_path = task_dir / "external_world_registry_snapshot_v111.json"
+    _write_once_json(snap_path, snap)
+    return {
+        "events_total": int(len(events)),
+        "external_world_chain_hash_v111": str(chain_hash),
+        "external_world_events_jsonl": str(events_path),
+        "external_world_registry_snapshot_v111_json": str(snap_path),
+    }
+
+
+def _compute_freeze_manifest_v117(*, task_dir: Path, sha256_paths: Dict[str, str]) -> Dict[str, Any]:
+    sha256: Dict[str, str] = {}
+    sha256_rel: Dict[str, str] = {}
+    for k, p in sorted(sha256_paths.items(), key=lambda kv: str(kv[0])):
+        pp = str(p or "")
+        sha256_rel[str(k)] = str(os.path.basename(pp)) if pp else ""
+        if pp and os.path.exists(pp):
+            sha256[str(k)] = _sha256_file(Path(pp))
+    body = {
+        "schema_version": 117,
+        "kind": "freeze_manifest_v117",
+        "sha256": dict(sha256),
+        "sha256_paths": dict(sha256_rel),
+    }
+    body["manifest_sig"] = sha256_hex(canonical_json_dumps(body).encode("utf-8"))
+    return body
+
+
+def main() -> None:
+    ap = argparse.ArgumentParser()
+    ap.add_argument("--tasks", required=True)
+    ap.add_argument("--out", required=True)
+    ap.add_argument("--seed", required=True, type=int)
+    ap.add_argument("--max_tasks", default="9999")
+    ap.add_argument("--max_rewrites", default="4")
+    ap.add_argument("--max_replans_per_turn", default="3")
+    ap.add_argument("--max_plan_attempts", default="8")
+    args = ap.parse_args()
+
+    seed = int(args.seed)
+    out_dir = Path(str(args.out))
+    _ensure_absent(out_dir)
+    out_dir.parent.mkdir(parents=True, exist_ok=True)
+    out_dir.mkdir(parents=True, exist_ok=False)
+
+    tasks: List[Dict[str, Any]] = []
+    with open(str(args.tasks), "r", encoding="utf-8") as f:
+        for line in f:
+            line = line.strip()
+            if not line:
+                continue
+            tasks.append(json.loads(line))
+    if not tasks:
+        _fail("empty_tasks")
+
+    max_tasks = int(args.max_tasks)
+    max_rewrites = int(args.max_rewrites)
+    max_replans = int(args.max_replans_per_turn)
+    max_plan_attempts = int(args.max_plan_attempts)
+
+    results: List[Dict[str, Any]] = []
+    failures: List[Dict[str, Any]] = []
+
+    for i, task in enumerate(tasks[:max_tasks]):
+        if not isinstance(task, dict):
+            continue
+        task_id = str(task.get("task_id") or f"task_{i:03d}")
+        user_turns = task.get("user_turns") if isinstance(task.get("user_turns"), list) else []
+        user_turn_texts = [str(x) for x in user_turns if isinstance(x, str)]
+        user_turn_texts = _choiceify_minimal_ack_v112(user_turn_texts)
+        require_fluency = bool(task.get("require_fluency", True))
+        allow_external = bool(task.get("allow_external_world_once", False))
+        world_manifest = str(task.get("world_manifest") or "")
+        probe_reason = str(task.get("external_world_probe_reason_code") or "validator_failed_fluency_contract")
+
+        task_dir = out_dir / "task_{i:03d}".format(i=i)
+        _ensure_absent(task_dir)
+        task_dir.mkdir(parents=True, exist_ok=False)
+
+        attempts: List[Dict[str, Any]] = []
+        chosen_attempt = -1
+
+        rewrite_seeds = fluency_survival_plan_v112(base_seed=int(seed), max_attempts=int(max_rewrites))
+        ext_used = False
+        ext_used_reason = ""
+        ext_events_final: List[Dict[str, Any]] = []
+
+        for a, seed_used in enumerate(rewrite_seeds):
+            attempt_dir = task_dir / "attempt_{a:03d}".format(a=a)
+            _ensure_absent(attempt_dir)
+            run_conversation_v117(
+                user_turn_texts=list(user_turn_texts),
+                out_dir=str(attempt_dir),
+                seed=int(seed_used),
+                max_replans_per_turn=int(max_replans),
+                max_plan_attempts=int(max_plan_attempts),
+            )
+
+            fr115 = _load_json(attempt_dir / "final_response_v115.json")
+            fr116 = _load_json(attempt_dir / "final_response_v116.json")
+            fr117 = _load_json(attempt_dir / "final_response_v117.json")
+
+            ok_gate = bool(fr115.get("ok", False)) if isinstance(fr115, dict) else False
+            gate_reason = str(fr115.get("reason") or "") if isinstance(fr115, dict) else "missing_final_response_v115"
+            ok_dialogue = bool(fr116.get("dialogue_survival_ok", False)) if isinstance(fr116, dict) else False
+            reason_dialogue = str(fr116.get("dialogue_survival_reason") or "") if isinstance(fr116, dict) else "missing_final_response_v116"
+            ok_v117 = bool(fr117.get("ok", False)) if isinstance(fr117, dict) else False
+            reason_v117 = str(fr117.get("reason") or "") if isinstance(fr117, dict) else "missing_final_response_v117"
+
+            transcript_rows = _load_jsonl_payload_view(attempt_dir / "transcript.jsonl")
+            user_i = 0
+            transcript_view: List[Dict[str, Any]] = []
+            for r in transcript_rows:
+                role = str(r.get("role") or "")
+                text = str(r.get("text") or "")
+                if role == "user" and user_i < len(user_turn_texts):
+                    text = str(user_turn_texts[user_i])
+                    user_i += 1
+                transcript_view.append({"role": role, "text": text})
+
+            ok_fc, reason_fc, details_fc = fluency_contract_v112(transcript_view=transcript_view)
+            # Deterministic external world gating exercise: force probe on attempt 0 for the single allow_external task.
+            if allow_external and (not ext_used) and a == 0:
+                ok_fc = False
+                reason_fc = "forced_external_world_probe"
+
+            binding_events = _load_jsonl(attempt_dir / "binding_events.jsonl")
+            unresolved_refs_total = _count_unresolved_reference_events(binding_events)
+            flow_events = _load_jsonl(attempt_dir / "flow_events.jsonl")
+            unresolved_refs_final = _unresolved_reference_final_from_flow(flow_events)
+            semantic_events = _load_jsonl(attempt_dir / "semantic_events.jsonl")
+            contradiction_flags = _count_semantic_contradiction_flags(semantic_events)
+
+            ok_unresolved = unresolved_refs_final == 0
+            ok_semantic = contradiction_flags == 0
+
+            ok_attempt = bool(ok_gate) and bool(ok_unresolved) and bool(ok_semantic) and bool(ok_dialogue) and bool(ok_v117)
+            if require_fluency:
+                ok_attempt = bool(ok_attempt) and bool(ok_fc)
+
+            attempts.append(
+                {
+                    "attempt_index": int(a),
+                    "seed_used": int(seed_used),
+                    "ok_gate_v115": bool(ok_gate),
+                    "reason_gate_v115": str(gate_reason),
+                    "ok_dialogue_survival_v116": bool(ok_dialogue),
+                    "reason_dialogue_survival_v116": str(reason_dialogue),
+                    "ok_final_v117": bool(ok_v117),
+                    "reason_final_v117": str(reason_v117),
+                    "ok_fluency": bool(ok_fc),
+                    "reason_fluency": str(summarize_fluency_fail_code_v112(str(reason_fc))),
+                    "unresolved_reference_events_total": int(unresolved_refs_total),
+                    "unresolved_reference_final": int(unresolved_refs_final),
+                    "semantic_contradiction_flags_total": int(contradiction_flags),
+                    "fluency_details": dict(details_fc),
+                }
+            )
+
+            if allow_external and (not ext_used) and (not ok_fc) and world_manifest and str(probe_reason) in set(EXTERNAL_WORLD_REASON_CODES_V111):
+                ext_events_final = _compute_external_world_access_once_v113(
+                    world_manifest=str(world_manifest),
+                    reason_code=str(probe_reason),
+                    query="nÃ£o invente",
+                    seed=int(seed),
+                )
+                ext_used = True
+                ext_used_reason = str(probe_reason)
+
+            if ok_attempt:
+                chosen_attempt = int(a)
+                break
+
+        _write_once_json(
+            task_dir / "fluency_survival_v117.json",
+            {
+                "schema_version": 117,
+                "task_id": str(task_id),
+                "chosen_attempt_index": int(chosen_attempt),
+                "attempts": list(attempts),
+                "external_world_used": bool(ext_used),
+                "external_world_used_reason_code": str(ext_used_reason),
+            },
+        )
+
+        ext_info = _write_external_world_ledger(task_dir=task_dir, events=list(ext_events_final))
+
+        # Choose attempt dir for summary paths: either chosen or last.
+        chosen_dir = task_dir / "attempt_{a:03d}".format(a=(chosen_attempt if chosen_attempt >= 0 else (len(attempts) - 1)))
+
+        sha256_paths: Dict[str, str] = {
+            "task_fluency_survival": str(task_dir / "fluency_survival_v117.json"),
+            "attempt_final_response_v117": str(chosen_dir / "final_response_v117.json"),
+            "attempt_final_response_v116": str(chosen_dir / "final_response_v116.json"),
+            "attempt_goal_plan_eval_summary_v116": str(chosen_dir / "goal_plan_eval_summary_v116.json"),
+            "attempt_replan_trace_v117": str(chosen_dir / "replan_trace_v117.json"),
+            "attempt_transcript": str(chosen_dir / "transcript.jsonl"),
+            "external_world_events": str(ext_info.get("external_world_events_jsonl") or ""),
+            "external_world_snapshot": str(ext_info.get("external_world_registry_snapshot_v111_json") or ""),
+        }
+
+        manifest = _compute_freeze_manifest_v117(task_dir=task_dir, sha256_paths=sha256_paths)
+        _write_once_json(task_dir / "freeze_manifest_v117.json", manifest)
+
+        ok_task = chosen_attempt >= 0
+        if ok_task:
+            results.append(
+                {
+                    "task_id": str(task_id),
+                    "ok": True,
+                    "chosen_attempt_index": int(chosen_attempt),
+                    "external_world_events_total": int(ext_info.get("events_total") or 0),
+                }
+            )
+        else:
+            failures.append(
+                {
+                    "task_id": str(task_id),
+                    "ok": False,
+                    "chosen_attempt_index": int(chosen_attempt),
+                    "attempts": list(attempts),
+                    "external_world_events_total": int(ext_info.get("events_total") or 0),
+                }
+            )
+            results.append({"task_id": str(task_id), "ok": False, "external_world_events_total": int(ext_info.get("events_total") or 0)})
+
+    tasks_total = len([t for t in tasks[:max_tasks] if isinstance(t, dict)])
+    tasks_ok = len([r for r in results if isinstance(r, dict) and bool(r.get("ok", False))])
+
+    eval_obj = {
+        "schema_version": 117,
+        "kind": "family7_eval_v117",
+        "seed": int(seed),
+        "tasks_total": int(tasks_total),
+        "tasks_ok": int(tasks_ok),
+        "results": list(results),
+        "failures": list(failures),
+    }
+    _write_once_json(out_dir / "eval.json", eval_obj)
+    eval_sha256 = _sha256_file(out_dir / "eval.json")
+
+    summary_obj = {
+        "schema_version": 117,
+        "kind": "family7_summary_v117",
+        "seed": int(seed),
+        "tasks_total": int(tasks_total),
+        "tasks_ok": int(tasks_ok),
+        "eval_sha256": str(eval_sha256),
+    }
+    _write_once_json(out_dir / "summary.json", summary_obj)
+    fail_catalog = {"schema_version": 117, "failures_total": int(len(failures)), "failures": list(failures[:20])}
+    _write_once_json(out_dir / "fail_catalog_v117.json", fail_catalog)
+
+
+if __name__ == "__main__":
+    main()
+
--- /dev/null	2026-01-15 15:17:55
+++ scripts/smoke_v117_family7_real_history_stress.py	2026-01-15 15:09:07
@@ -0,0 +1,183 @@
+#!/usr/bin/env python3
+from __future__ import annotations
+
+import argparse
+import hashlib
+import json
+import os
+import subprocess
+import sys
+from pathlib import Path
+from typing import Any, Dict, List
+
+sys.path.insert(0, os.path.dirname(os.path.dirname(__file__)))
+
+from atos_core.act import canonical_json_dumps, sha256_hex
+from atos_core.external_world_gating_v113 import external_world_access_v113
+from atos_core.external_world_ledger_v111 import EXTERNAL_WORLD_ACTION_SEARCH_V111
+
+
+def _sha256_file(path: Path) -> str:
+    h = hashlib.sha256()
+    with open(path, "rb") as f:
+        while True:
+            b = f.read(1024 * 1024)
+            if not b:
+                break
+            h.update(b)
+    return h.hexdigest()
+
+
+def _ensure_absent(path: Path) -> None:
+    if path.exists():
+        raise SystemExit(f"worm_exists:{path}")
+
+
+def _load_json(path: Path) -> Any:
+    return json.loads(path.read_text(encoding="utf-8"))
+
+
+def _run_runner(*, tasks: str, out_dir: Path, seed: int) -> None:
+    _ensure_absent(out_dir)
+    out_dir.parent.mkdir(parents=True, exist_ok=True)
+    env = dict(os.environ)
+    cmd = [
+        sys.executable,
+        "scripts/run_family7_dla_v117.py",
+        "--tasks",
+        str(tasks),
+        "--out",
+        str(out_dir),
+        "--seed",
+        str(seed),
+        "--max_tasks",
+        "9999",
+        "--max_rewrites",
+        "4",
+        "--max_replans_per_turn",
+        "3",
+        "--max_plan_attempts",
+        "8",
+    ]
+    p = subprocess.run(cmd, env=env, cwd=str(Path(__file__).resolve().parent.parent), capture_output=True, text=True)
+    if p.returncode != 0:
+        raise SystemExit("runner_failed:\nSTDOUT:\n{out}\nSTDERR:\n{err}".format(out=p.stdout, err=p.stderr))
+
+
+def _negative_tests(*, world_manifest: str) -> Dict[str, Any]:
+    ok1 = False
+    reason1 = ""
+    try:
+        external_world_access_v113(
+            allowed=False,
+            world_manifest=str(world_manifest),
+            action=EXTERNAL_WORLD_ACTION_SEARCH_V111,
+            reason_code="validator_failed_fluency_contract",
+            args={"query": "x", "limit": 1, "roles": ["user"]},
+            seed=0,
+            turn_index=0,
+            prev_event_sig="",
+        )
+        ok1 = True
+    except ValueError as e:
+        reason1 = str(e)
+
+    ok2 = False
+    reason2 = ""
+    try:
+        external_world_access_v113(
+            allowed=True,
+            world_manifest=str(world_manifest),
+            action=EXTERNAL_WORLD_ACTION_SEARCH_V111,
+            reason_code="invalid_reason_code_x",
+            args={"query": "x", "limit": 1, "roles": ["user"]},
+            seed=0,
+            turn_index=0,
+            prev_event_sig="",
+        )
+        ok2 = True
+    except ValueError as e:
+        reason2 = str(e)
+
+    return {
+        "access_not_allowed": {"ok": bool(ok1), "reason": str(reason1)},
+        "invalid_reason_code": {"ok": bool(ok2), "reason": str(reason2)},
+    }
+
+
+def main() -> None:
+    ap = argparse.ArgumentParser()
+    ap.add_argument("--tasks", required=True)
+    ap.add_argument("--out_base", required=True)
+    ap.add_argument("--seed", required=True, type=int)
+    args = ap.parse_args()
+
+    seed = int(args.seed)
+    tasks_path = str(args.tasks)
+    out_base = Path(str(args.out_base))
+
+    tasks: List[Dict[str, Any]] = []
+    with open(tasks_path, "r", encoding="utf-8") as f:
+        for line in f:
+            line = line.strip()
+            if not line:
+                continue
+            tasks.append(json.loads(line))
+    if not tasks:
+        raise SystemExit("empty_tasks")
+    world_manifest = str(tasks[0].get("world_manifest") or "")
+
+    neg = _negative_tests(world_manifest=world_manifest)
+    if neg["access_not_allowed"]["reason"] != "external_world_access_not_allowed":
+        raise SystemExit("negative_failed:access_not_allowed")
+    if neg["invalid_reason_code"]["reason"] != "invalid_reason_code":
+        raise SystemExit("negative_failed:invalid_reason_code")
+
+    out1 = Path(str(out_base) + "_try1")
+    out2 = Path(str(out_base) + "_try2")
+    _run_runner(tasks=tasks_path, out_dir=out1, seed=seed)
+    _run_runner(tasks=tasks_path, out_dir=out2, seed=seed)
+
+    s1 = _load_json(out1 / "summary.json")
+    s2 = _load_json(out2 / "summary.json")
+    eval_sha1 = str(s1.get("eval_sha256") or "")
+    eval_sha2 = str(s2.get("eval_sha256") or "")
+    if eval_sha1 != eval_sha2:
+        raise SystemExit("determinism_failed:eval_sha")
+
+    ev1 = _load_json(out1 / "eval.json")
+    ev2 = _load_json(out2 / "eval.json")
+    if canonical_json_dumps(ev1) != canonical_json_dumps(ev2):
+        raise SystemExit("determinism_failed:eval_json")
+
+    if int(ev1.get("tasks_ok") or 0) != int(ev1.get("tasks_total") or 0):
+        raise SystemExit("tasks_not_all_ok")
+
+    res1 = ev1.get("results") if isinstance(ev1.get("results"), list) else []
+    ext_counts = [int(r.get("external_world_events_total") or 0) for r in res1 if isinstance(r, dict)]
+    if sum(1 for c in ext_counts if c == 1) != 1:
+        raise SystemExit("external_world_in_cycle_expected_one_call")
+
+    core = {
+        "schema_version": 117,
+        "seed": int(seed),
+        "try1": {"eval_sha256": eval_sha1, "tasks_ok": int(s1.get("tasks_ok") or 0)},
+        "try2": {"eval_sha256": eval_sha2, "tasks_ok": int(s2.get("tasks_ok") or 0)},
+        "negative_tests": dict(neg),
+    }
+    summary_sha256 = sha256_hex(canonical_json_dumps(core).encode("utf-8"))
+    out = {
+        "ok": True,
+        "determinism_ok": True,
+        "summary_sha256": str(summary_sha256),
+        "core": core,
+        "try1_dir": str(out1),
+        "try2_dir": str(out2),
+        "sha256_eval_json": _sha256_file(out1 / "eval.json"),
+    }
+    print(json.dumps(out, ensure_ascii=False, indent=2, sort_keys=True))
+
+
+if __name__ == "__main__":
+    main()
+
--- /dev/null	2026-01-15 15:17:55
+++ scripts/smoke_v117_replan_law.py	2026-01-15 15:13:43
@@ -0,0 +1,376 @@
+#!/usr/bin/env python3
+from __future__ import annotations
+
+import argparse
+import hashlib
+import json
+import os
+import sys
+from pathlib import Path
+from typing import Any, Dict, List, Optional
+
+sys.path.insert(0, os.path.dirname(os.path.dirname(__file__)))
+
+from atos_core.act import canonical_json_dumps, deterministic_iso, sha256_hex
+from atos_core.ato_v71 import ATOv71
+from atos_core.goal_persistence_v115 import render_fail_response_v115
+from atos_core.mind_graph_v71 import MindGraphV71
+from atos_core.replan_law_v117 import (
+    PlanCandidateV117,
+    REPLAN_REASON_EXHAUSTED_PLANS_V117,
+    REPLAN_REASON_OK_V117,
+    REPLAN_REASON_PLAN_SEARCH_BUDGET_EXHAUSTED_V117,
+    ReplanResultV117,
+    replan_until_satisfies_v117,
+    write_replan_trace_v117,
+)
+
+
+def _fail(msg: str) -> None:
+    print(msg, file=sys.stderr)
+    raise SystemExit(2)
+
+
+def _sha256_file(path: Path) -> str:
+    h = hashlib.sha256()
+    with open(path, "rb") as f:
+        while True:
+            b = f.read(1024 * 1024)
+            if not b:
+                break
+            h.update(b)
+    return h.hexdigest()
+
+
+def _ensure_absent(path: Path) -> None:
+    if path.exists():
+        _fail(f"worm_exists:{path}")
+
+
+def _write_once_json(path: Path, obj: Any) -> None:
+    _ensure_absent(path)
+    tmp = path.with_suffix(path.suffix + ".tmp")
+    if tmp.exists():
+        _fail(f"tmp_exists:{tmp}")
+    tmp.write_text(json.dumps(obj, ensure_ascii=False, indent=2, sort_keys=True) + "\n", encoding="utf-8")
+    os.replace(str(tmp), str(path))
+
+
+def _make_turn_obs(turn_id: str, *, step: int) -> ATOv71:
+    return ATOv71(
+        ato_id=str(turn_id),
+        ato_type="OBS",
+        subgraph={"schema_version": 117, "kind": "turn_obs_v117"},
+        slots={},
+        bindings={},
+        cost=0.0,
+        evidence_refs=[],
+        invariants={"schema_version": 117, "obs_kind": "turn_v117"},
+        created_step=int(step),
+        last_step=int(step),
+    )
+
+
+def _make_goal(goal_id: str, *, turn_id: str, step: int) -> ATOv71:
+    return ATOv71(
+        ato_id=str(goal_id),
+        ato_type="GOAL",
+        subgraph={"schema_version": 117, "kind": "goal_demo_v117", "turn_id": str(turn_id)},
+        slots={},
+        bindings={},
+        cost=1.0,
+        evidence_refs=[{"kind": "turn", "turn_id": str(turn_id)}],
+        invariants={"schema_version": 117, "goal_kind": "demo"},
+        created_step=int(step),
+        last_step=int(step),
+    )
+
+
+def _make_plan(plan_id: str, *, turn_id: str, step: int) -> ATOv71:
+    return ATOv71(
+        ato_id=str(plan_id),
+        ato_type="PLAN",
+        subgraph={"schema_version": 117, "kind": "plan_demo_v117", "turn_id": str(turn_id)},
+        slots={},
+        bindings={},
+        cost=1.0,
+        evidence_refs=[{"kind": "turn", "turn_id": str(turn_id)}],
+        invariants={"schema_version": 117, "plan_kind": "demo"},
+        created_step=int(step),
+        last_step=int(step),
+    )
+
+
+def _make_fail_event(
+    *,
+    conversation_id: str,
+    user_turn_id: str,
+    goal_ato_id: str,
+    plan_ato_id: str,
+    reason_code: str,
+    step: int,
+    evidence: Dict[str, Any],
+) -> ATOv71:
+    sem = {
+        "schema_version": 117,
+        "conversation_id": str(conversation_id),
+        "user_turn_id": str(user_turn_id),
+        "goal_ato_id": str(goal_ato_id),
+        "plan_ato_id": str(plan_ato_id),
+        "reason_code": str(reason_code),
+        "evidence": dict(evidence),
+    }
+    fail_id = "fail_event_v117_" + sha256_hex(canonical_json_dumps(sem).encode("utf-8"))
+    return ATOv71(
+        ato_id=str(fail_id),
+        ato_type="EVAL",
+        subgraph=dict(sem, satisfies=False),
+        slots={},
+        bindings={},
+        cost=0.0,
+        evidence_refs=[{"kind": "turn", "turn_id": str(user_turn_id)}],
+        invariants={"schema_version": 117, "eval_kind": "FAIL_EVENT_V117"},
+        created_step=int(step),
+        last_step=int(step),
+    )
+
+
+def _write_final_response_v117(path: Path, *, ok: bool, reason: str) -> Dict[str, Any]:
+    fail_text = ""
+    if not ok:
+        fail_text = render_fail_response_v115(str(reason))
+    obj = {
+        "schema_version": 117,
+        "kind": "final_response_v117",
+        "ok": bool(ok),
+        "reason": str(reason if not ok else "ok"),
+        "fail_response_text": str(fail_text),
+    }
+    obj["final_sig"] = sha256_hex(canonical_json_dumps(obj).encode("utf-8"))
+    _write_once_json(path, obj)
+    return dict(obj)
+
+
+def _run_case_first_fails_second_passes(case_dir: Path) -> Dict[str, Any]:
+    _ensure_absent(case_dir)
+    case_dir.mkdir(parents=True, exist_ok=False)
+    goal_id = "goal_demo_v117"
+    turn_id = "turn_user_0"
+    conversation_id = "conv_demo_v117"
+    step0 = 0
+
+    plans: List[PlanCandidateV117] = [
+        PlanCandidateV117(plan_id="planA", plan_cost=1.0, plan_sem_sig={"p": "A"}),
+        PlanCandidateV117(plan_id="planB", plan_cost=1.0, plan_sem_sig={"p": "B"}),
+    ]
+
+    def next_plan() -> Optional[PlanCandidateV117]:
+        return plans.pop(0) if plans else None
+
+    def exec_plan(p: PlanCandidateV117):
+        if p.plan_id == "planA":
+            return False, True, "planA_failed"
+        return True, True, ""
+
+    res: ReplanResultV117 = replan_until_satisfies_v117(next_plan=next_plan, exec_plan=exec_plan, max_attempts=8)
+    if not res.ok:
+        _fail("case_first_fails_second_passes_expected_ok")
+
+    trace_obj = write_replan_trace_v117(path=str(case_dir / "replan_trace_v117.json"), goal_id=str(goal_id), result=res)
+    _write_final_response_v117(case_dir / "final_response_v117.json", ok=True, reason="ok")
+
+    mg = MindGraphV71(run_dir=str(case_dir / "mind_graph_v117"))
+    mg.add_node(step=step0, ato=_make_turn_obs(turn_id, step=step0), reason="turn_obs")
+    mg.add_node(step=step0, ato=_make_goal(goal_id, turn_id=turn_id, step=step0), reason="goal")
+    mg.add_node(step=step0, ato=_make_plan("planA", turn_id=turn_id, step=step0), reason="plan")
+    mg.add_node(step=step0, ato=_make_plan("planB", turn_id=turn_id, step=step0), reason="plan")
+
+    # One FAIL_EVENT for planA failure.
+    fail = _make_fail_event(
+        conversation_id=conversation_id,
+        user_turn_id=turn_id,
+        goal_ato_id=goal_id,
+        plan_ato_id="planA",
+        reason_code="planA_failed",
+        step=step0,
+        evidence={"trace_sig": str(trace_obj.get("trace_sig") or ""), "attempt_index": 0},
+    )
+    mg.add_node(step=step0, ato=fail, reason="fail_event")
+    mg.add_edge(step=step0, src_ato_id=str(fail.ato_id), dst_ato_id=str(goal_id), edge_type="DERIVED_FROM", evidence_refs=[], reason="fail->goal")
+    mg.add_edge(step=step0, src_ato_id=str(fail.ato_id), dst_ato_id="planA", edge_type="DERIVED_FROM", evidence_refs=[], reason="fail->plan")
+    mg.add_edge(step=step0, src_ato_id=str(fail.ato_id), dst_ato_id=str(turn_id), edge_type="DERIVED_FROM", evidence_refs=[], reason="fail->turn")
+
+    chains = mg.verify_chains()
+    if not bool(chains.get("mind_nodes_chain_ok")) or not bool(chains.get("mind_edges_chain_ok")):
+        _fail("case_first_fails_second_passes_mind_graph_chain_fail")
+
+    return {"ok": True, "reason": REPLAN_REASON_OK_V117, "attempts_total": int(res.attempts_total), "trace_sig": str(trace_obj.get("trace_sig") or "")}
+
+
+def _run_case_exhausted(case_dir: Path) -> Dict[str, Any]:
+    _ensure_absent(case_dir)
+    case_dir.mkdir(parents=True, exist_ok=False)
+    goal_id = "goal_demo_exhausted_v117"
+    turn_id = "turn_user_0"
+    conversation_id = "conv_demo_v117"
+    step0 = 0
+
+    plans: List[PlanCandidateV117] = [
+        PlanCandidateV117(plan_id="planA", plan_cost=1.0, plan_sem_sig={"p": "A"}),
+    ]
+
+    def next_plan() -> Optional[PlanCandidateV117]:
+        return plans.pop(0) if plans else None
+
+    def exec_plan(_p: PlanCandidateV117):
+        return False, True, "failed"
+
+    res = replan_until_satisfies_v117(next_plan=next_plan, exec_plan=exec_plan, max_attempts=8)
+    if res.ok or res.reason != REPLAN_REASON_EXHAUSTED_PLANS_V117:
+        _fail("case_exhausted_expected_exhausted_plans")
+
+    trace_obj = write_replan_trace_v117(path=str(case_dir / "replan_trace_v117.json"), goal_id=str(goal_id), result=res)
+    _write_final_response_v117(case_dir / "final_response_v117.json", ok=False, reason=REPLAN_REASON_EXHAUSTED_PLANS_V117)
+
+    mg = MindGraphV71(run_dir=str(case_dir / "mind_graph_v117"))
+    mg.add_node(step=step0, ato=_make_turn_obs(turn_id, step=step0), reason="turn_obs")
+    mg.add_node(step=step0, ato=_make_goal(goal_id, turn_id=turn_id, step=step0), reason="goal")
+    mg.add_node(step=step0, ato=_make_plan("planA", turn_id=turn_id, step=step0), reason="plan")
+
+    fail = _make_fail_event(
+        conversation_id=conversation_id,
+        user_turn_id=turn_id,
+        goal_ato_id=goal_id,
+        plan_ato_id="planA",
+        reason_code="failed",
+        step=step0,
+        evidence={"trace_sig": str(trace_obj.get("trace_sig") or ""), "attempt_index": 0},
+    )
+    mg.add_node(step=step0, ato=fail, reason="fail_event")
+    mg.add_edge(step=step0, src_ato_id=str(fail.ato_id), dst_ato_id=str(goal_id), edge_type="DERIVED_FROM", evidence_refs=[], reason="fail->goal")
+    mg.add_edge(step=step0, src_ato_id=str(fail.ato_id), dst_ato_id="planA", edge_type="DERIVED_FROM", evidence_refs=[], reason="fail->plan")
+    mg.add_edge(step=step0, src_ato_id=str(fail.ato_id), dst_ato_id=str(turn_id), edge_type="DERIVED_FROM", evidence_refs=[], reason="fail->turn")
+
+    chains = mg.verify_chains()
+    if not bool(chains.get("mind_nodes_chain_ok")) or not bool(chains.get("mind_edges_chain_ok")):
+        _fail("case_exhausted_mind_graph_chain_fail")
+
+    return {"ok": False, "reason": REPLAN_REASON_EXHAUSTED_PLANS_V117, "attempts_total": int(res.attempts_total), "trace_sig": str(trace_obj.get("trace_sig") or "")}
+
+
+def _run_case_budget(case_dir: Path) -> Dict[str, Any]:
+    _ensure_absent(case_dir)
+    case_dir.mkdir(parents=True, exist_ok=False)
+    goal_id = "goal_demo_budget_v117"
+    turn_id = "turn_user_0"
+    conversation_id = "conv_demo_v117"
+    step0 = 0
+
+    plans: List[PlanCandidateV117] = [
+        PlanCandidateV117(plan_id="planA", plan_cost=1.0, plan_sem_sig={"p": "A"}),
+        PlanCandidateV117(plan_id="planB", plan_cost=1.0, plan_sem_sig={"p": "B"}),
+        PlanCandidateV117(plan_id="planC", plan_cost=1.0, plan_sem_sig={"p": "C"}),
+        PlanCandidateV117(plan_id="planD", plan_cost=1.0, plan_sem_sig={"p": "D"}),
+    ]
+
+    def next_plan() -> Optional[PlanCandidateV117]:
+        return plans.pop(0) if plans else None
+
+    def exec_plan(_p: PlanCandidateV117):
+        return False, True, "failed"
+
+    res = replan_until_satisfies_v117(next_plan=next_plan, exec_plan=exec_plan, max_attempts=3)
+    if res.ok or res.reason != REPLAN_REASON_PLAN_SEARCH_BUDGET_EXHAUSTED_V117:
+        _fail("case_budget_expected_budget_exhausted")
+
+    trace_obj = write_replan_trace_v117(path=str(case_dir / "replan_trace_v117.json"), goal_id=str(goal_id), result=res)
+    _write_final_response_v117(case_dir / "final_response_v117.json", ok=False, reason=REPLAN_REASON_PLAN_SEARCH_BUDGET_EXHAUSTED_V117)
+
+    mg = MindGraphV71(run_dir=str(case_dir / "mind_graph_v117"))
+    mg.add_node(step=step0, ato=_make_turn_obs(turn_id, step=step0), reason="turn_obs")
+    mg.add_node(step=step0, ato=_make_goal(goal_id, turn_id=turn_id, step=step0), reason="goal")
+    mg.add_node(step=step0, ato=_make_plan("planA", turn_id=turn_id, step=step0), reason="plan")
+    mg.add_node(step=step0, ato=_make_plan("planB", turn_id=turn_id, step=step0), reason="plan")
+    mg.add_node(step=step0, ato=_make_plan("planC", turn_id=turn_id, step=step0), reason="plan")
+
+    for i, plan_id in enumerate(["planA", "planB", "planC"]):
+        fail = _make_fail_event(
+            conversation_id=conversation_id,
+            user_turn_id=turn_id,
+            goal_ato_id=goal_id,
+            plan_ato_id=str(plan_id),
+            reason_code="failed",
+            step=step0,
+            evidence={"trace_sig": str(trace_obj.get("trace_sig") or ""), "attempt_index": int(i)},
+        )
+        mg.add_node(step=step0, ato=fail, reason="fail_event")
+        mg.add_edge(step=step0, src_ato_id=str(fail.ato_id), dst_ato_id=str(goal_id), edge_type="DERIVED_FROM", evidence_refs=[], reason="fail->goal")
+        mg.add_edge(step=step0, src_ato_id=str(fail.ato_id), dst_ato_id=str(plan_id), edge_type="DERIVED_FROM", evidence_refs=[], reason="fail->plan")
+        mg.add_edge(step=step0, src_ato_id=str(fail.ato_id), dst_ato_id=str(turn_id), edge_type="DERIVED_FROM", evidence_refs=[], reason="fail->turn")
+
+    chains = mg.verify_chains()
+    if not bool(chains.get("mind_nodes_chain_ok")) or not bool(chains.get("mind_edges_chain_ok")):
+        _fail("case_budget_mind_graph_chain_fail")
+
+    return {"ok": False, "reason": REPLAN_REASON_PLAN_SEARCH_BUDGET_EXHAUSTED_V117, "attempts_total": int(res.attempts_total), "trace_sig": str(trace_obj.get("trace_sig") or "")}
+
+
+def _run_try(out_dir: Path) -> Dict[str, Any]:
+    _ensure_absent(out_dir)
+    out_dir.mkdir(parents=True, exist_ok=False)
+
+    cases = {
+        "case_first_fails_second_passes": _run_case_first_fails_second_passes(out_dir / "case_00_first_fails_second_passes"),
+        "case_exhausted_plans": _run_case_exhausted(out_dir / "case_01_exhausted_plans"),
+        "case_budget_exhausted": _run_case_budget(out_dir / "case_02_budget_exhausted"),
+    }
+    eval_obj = {"schema_version": 117, "kind": "smoke_eval_v117", "cases": dict(cases)}
+    _write_once_json(out_dir / "eval.json", eval_obj)
+    eval_sha256 = _sha256_file(out_dir / "eval.json")
+    summary = {"schema_version": 117, "kind": "smoke_summary_v117", "eval_sha256": str(eval_sha256)}
+    _write_once_json(out_dir / "summary.json", summary)
+    fail_catalog = {"schema_version": 117, "failures_total": 0, "failures": []}
+    _write_once_json(out_dir / "fail_catalog_v117.json", fail_catalog)
+    return {"eval_json": eval_obj, "eval_sha256": str(eval_sha256)}
+
+
+def main() -> None:
+    ap = argparse.ArgumentParser()
+    ap.add_argument("--out_base", default="results/run_smoke_v117_replan_law")
+    ap.add_argument("--seed", required=True, type=int)
+    args = ap.parse_args()
+
+    # Seed is unused in this deterministic smoke, but kept for CLI consistency.
+    _ = int(args.seed)
+    out_base = Path(str(args.out_base))
+    out1 = Path(str(out_base) + "_try1")
+    out2 = Path(str(out_base) + "_try2")
+
+    r1 = _run_try(out_dir=out1)
+    r2 = _run_try(out_dir=out2)
+
+    if canonical_json_dumps(r1["eval_json"]) != canonical_json_dumps(r2["eval_json"]):
+        _fail("determinism_failed:eval_json")
+    if str(r1["eval_sha256"]) != str(r2["eval_sha256"]):
+        _fail("determinism_failed:eval_sha256")
+
+    core = {"schema_version": 117, "eval_sha256": str(r1["eval_sha256"])}
+    summary_sha256 = sha256_hex(canonical_json_dumps(core).encode("utf-8"))
+    print(
+        json.dumps(
+            {
+                "ok": True,
+                "determinism_ok": True,
+                "summary_sha256": str(summary_sha256),
+                "try1_dir": str(out1),
+                "try2_dir": str(out2),
+            },
+            ensure_ascii=False,
+            indent=2,
+            sort_keys=True,
+        )
+    )
+
+
+if __name__ == "__main__":
+    main()
--- /dev/null	2026-01-15 15:17:55
+++ tests/test_replan_law_v117.py	2026-01-15 15:04:52
@@ -0,0 +1,76 @@
+from __future__ import annotations
+
+import unittest
+from typing import List, Optional
+
+from atos_core.replan_law_v117 import (
+    PlanCandidateV117,
+    REPLAN_REASON_EXHAUSTED_PLANS_V117,
+    REPLAN_REASON_OK_V117,
+    REPLAN_REASON_PLAN_SEARCH_BUDGET_EXHAUSTED_V117,
+    replan_until_satisfies_v117,
+)
+
+
+class TestReplanLawV117(unittest.TestCase):
+    def test_first_fails_second_passes(self) -> None:
+        plans: List[PlanCandidateV117] = [
+            PlanCandidateV117(plan_id="planA", plan_cost=1.0, plan_sem_sig={"k": "A"}),
+            PlanCandidateV117(plan_id="planB", plan_cost=1.0, plan_sem_sig={"k": "B"}),
+        ]
+
+        def next_plan() -> Optional[PlanCandidateV117]:
+            return plans.pop(0) if plans else None
+
+        def exec_plan(p: PlanCandidateV117):
+            if p.plan_id == "planA":
+                return False, True, "planA_failed"
+            return True, True, ""
+
+        res = replan_until_satisfies_v117(next_plan=next_plan, exec_plan=exec_plan, max_attempts=8)
+        self.assertTrue(res.ok)
+        self.assertEqual(res.reason, REPLAN_REASON_OK_V117)
+        self.assertEqual(res.attempts_total, 2)
+        self.assertEqual(res.attempts[-1].plan_id, "planB")
+        self.assertTrue(res.attempts[-1].eval_satisfies)
+        self.assertTrue(res.attempts[-1].dialogue_survival_ok)
+
+    def test_exhausted_plans(self) -> None:
+        plans: List[PlanCandidateV117] = [
+            PlanCandidateV117(plan_id="planA", plan_cost=1.0, plan_sem_sig={"k": "A"}),
+        ]
+
+        def next_plan() -> Optional[PlanCandidateV117]:
+            return plans.pop(0) if plans else None
+
+        def exec_plan(_p: PlanCandidateV117):
+            return False, True, "failed"
+
+        res = replan_until_satisfies_v117(next_plan=next_plan, exec_plan=exec_plan, max_attempts=8)
+        self.assertFalse(res.ok)
+        self.assertEqual(res.reason, REPLAN_REASON_EXHAUSTED_PLANS_V117)
+        self.assertEqual(res.attempts_total, 1)
+
+    def test_budget_exhausted(self) -> None:
+        plans: List[PlanCandidateV117] = [
+            PlanCandidateV117(plan_id="planA", plan_cost=1.0, plan_sem_sig={"k": "A"}),
+            PlanCandidateV117(plan_id="planB", plan_cost=1.0, plan_sem_sig={"k": "B"}),
+            PlanCandidateV117(plan_id="planC", plan_cost=1.0, plan_sem_sig={"k": "C"}),
+            PlanCandidateV117(plan_id="planD", plan_cost=1.0, plan_sem_sig={"k": "D"}),
+        ]
+
+        def next_plan() -> Optional[PlanCandidateV117]:
+            return plans.pop(0) if plans else None
+
+        def exec_plan(_p: PlanCandidateV117):
+            return False, True, "failed"
+
+        res = replan_until_satisfies_v117(next_plan=next_plan, exec_plan=exec_plan, max_attempts=3)
+        self.assertFalse(res.ok)
+        self.assertEqual(res.reason, REPLAN_REASON_PLAN_SEARCH_BUDGET_EXHAUSTED_V117)
+        self.assertEqual(res.attempts_total, 3)
+
+
+if __name__ == "__main__":
+    unittest.main()
+
