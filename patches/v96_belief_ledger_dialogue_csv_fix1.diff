--- /dev/null	2026-01-13 15:24:17
+++ atos_core/conversation_loop_v96.py	2026-01-13 15:19:47
@@ -0,0 +1,1681 @@
+from __future__ import annotations
+
+import hashlib
+import json
+import os
+from typing import Any, Dict, List, Optional, Sequence, Tuple
+
+from .act import canonical_json_dumps, deterministic_iso, sha256_hex
+from .conversation_actions_v90 import action_concepts_for_dsl_v90
+from .conversation_objectives_v90 import COMM_OBJECTIVES_V90, comm_objective_ids_v90, make_comm_objective_eq_text_v90
+from .conversation_v96 import (
+    ActionPlanV96,
+    BeliefEventV96,
+    BeliefItemV96,
+    ConversationStateV96,
+    MemoryEventV96,
+    MemoryItemV96,
+    TurnV96,
+    append_chained_jsonl_v96,
+    compute_belief_chain_hash_v96,
+    compute_learned_chain_hash_v96,
+    compute_memory_chain_hash_v96,
+    compute_parse_chain_hash_v96,
+    compute_plan_chain_hash_v96,
+    compute_state_chain_hash_v96,
+    compute_transcript_hash_v96,
+    normalize_text_v96,
+    render_belief_added_ack_text_v96,
+    render_belief_retracted_ack_text_v96,
+    render_belief_revised_ack_text_v96,
+    render_beliefs_text_v96,
+    render_forget_ack_text_v96,
+    render_note_ack_text_v96,
+    render_recall_text_v96,
+    render_explain_text_v96,
+    text_sig_v96,
+    verify_chained_jsonl_v96,
+    verify_conversation_chain_v96,
+)
+from .engine_v80 import EngineV80
+from .goal_supports_v89 import SupportClaimV89, fold_support_stats_v89, list_supporting_concepts_for_goal_v89, make_goal_support_evidence_event_v89
+from .intent_grammar_v92 import (
+    INTENT_ADD_V92,
+    INTENT_COMPOUND_V92,
+    INTENT_END_V92,
+    INTENT_GET_V92,
+    INTENT_SET_V92,
+    INTENT_SUMMARY_V92,
+    INTENT_UNKNOWN_V92,
+    default_intent_rule_acts_v92,
+    default_intent_rules_v92,
+    grammar_hash_v92,
+    intent_grammar_snapshot_v92,
+    parse_intent_v92,
+)
+from .intent_grammar_v93 import (
+    INTENT_TEACH_V93,
+    IntentRuleV93,
+    canonize_lhs_for_learned_rule_v93,
+    is_teach_command_v93,
+    make_learned_intent_rule_v93,
+    parse_teach_command_v93,
+)
+from .intent_grammar_v94 import INTENT_EXPLAIN_V94, is_explain_command_v94, parse_explain_command_v94
+from .intent_grammar_v96 import (
+    INTENT_BELIEF_ADD_V96,
+    INTENT_BELIEF_FORGET_V96,
+    INTENT_BELIEF_LIST_V96,
+    INTENT_BELIEF_REVISE_V96,
+    INTENT_FORGET_V96,
+    INTENT_NOTE_V96,
+    INTENT_RECALL_V96,
+    is_belief_add_command_v96,
+    is_belief_revise_command_v96,
+    is_beliefs_list_command_v96,
+    is_forget_command_v96,
+    is_note_command_v96,
+    is_recall_command_v96,
+    parse_belief_add_command_v96,
+    parse_belief_revise_command_v96,
+    parse_beliefs_list_command_v96,
+    parse_forget_command_v96,
+    parse_note_command_v96,
+    parse_recall_command_v96,
+)
+from .objective_v88 import execute_objective_csv_v88
+from .store import ActStore
+
+
+def _fail(msg: str) -> None:
+    raise ValueError(msg)
+
+
+def ensure_absent(path: str) -> None:
+    if os.path.exists(path):
+        _fail(f"path_exists:{path}")
+
+
+def sha256_file(path: str) -> str:
+    h = hashlib.sha256()
+    with open(path, "rb") as f:
+        while True:
+            b = f.read(1024 * 1024)
+            if not b:
+                break
+            h.update(b)
+    return h.hexdigest()
+
+
+def _stable_hash_obj(obj: Any) -> str:
+    return sha256_hex(canonical_json_dumps(obj).encode("utf-8"))
+
+
+def _round6(x: Any) -> float:
+    try:
+        return float(round(float(x), 6))
+    except Exception:
+        return 0.0
+
+
+def _rank_action_candidates_v96(
+    *,
+    candidates: Sequence[Tuple[str, SupportClaimV89]],
+    events: Sequence[Dict[str, Any]],
+    goal_id: str,
+) -> List[Tuple[str, SupportClaimV89, float, float]]:
+    scored: List[Tuple[str, SupportClaimV89, float, float]] = []
+    for act_id, claim in candidates:
+        stats = fold_support_stats_v89(events=events, goal_id=str(goal_id), concept_key=str(act_id), claim=claim)
+        scored.append((str(act_id), claim, float(stats.expected_success), float(stats.expected_cost)))
+    scored.sort(key=lambda t: (-float(t[2]), float(t[3]), str(t[0])))
+    return scored
+
+
+def _is_int_literal(s: str) -> bool:
+    ss = str(s or "")
+    return bool(ss) and ss.isdigit()
+
+
+def _parse_int_or_var(*, vars_map: Dict[str, Any], tok: str, last_answer: Any) -> Tuple[Optional[int], str]:
+    t = str(tok or "")
+    if _is_int_literal(t):
+        return int(t), "ok"
+    if t == "last_answer":
+        try:
+            return int(last_answer), "ok"
+        except Exception:
+            return None, "missing_last_answer"
+    if t in vars_map:
+        try:
+            return int(vars_map.get(t)), "ok"
+        except Exception:
+            return None, "bad_var_type"
+    return None, "missing_key"
+
+
+def _summarize_bindings_v96(*, vars_map: Dict[str, Any], last_answer: Any) -> str:
+    parts: List[str] = []
+    for k in sorted(vars_map.keys(), key=str):
+        parts.append(f"{k}={vars_map.get(k)}")
+    if last_answer != "":
+        parts.append(f"last_answer={last_answer}")
+    inner = "; ".join(parts)
+    return f"Resumo: {inner}".rstrip()
+
+
+def _simulate_compound_execution_v96(
+    *, parse: Dict[str, Any], vars_map: Dict[str, Any], last_answer: Any, beliefs_by_key: Dict[str, Dict[str, Any]]
+) -> Tuple[bool, str, Dict[str, Any]]:
+    segs = parse.get("segments") if isinstance(parse.get("segments"), list) else []
+    cur_vars = dict(vars_map)
+    cur_last = last_answer
+    lines: List[str] = []
+    stop_after = False
+
+    for seg in segs:
+        if not isinstance(seg, dict):
+            return False, "", {"reason": "segment_not_dict"}
+        sp = seg.get("segment_parse") if isinstance(seg.get("segment_parse"), dict) else {}
+        intent_id = str(sp.get("intent_id") or "")
+        slots = sp.get("slots") if isinstance(sp.get("slots"), dict) else {}
+
+        if intent_id == INTENT_SET_V92:
+            k = str(slots.get("k") or "")
+            v = str(slots.get("v") or "")
+            if not k or not v:
+                return False, "", {"reason": "segment_missing_slot", "missing_slot": "k/v"}
+            cur_vars[k] = int(v) if _is_int_literal(v) else v
+            lines.append(f"OK: {k}={v}")
+            continue
+
+        if intent_id == INTENT_GET_V92:
+            k = str(slots.get("k") or "")
+            if not k:
+                return False, "", {"reason": "segment_missing_key", "missing_key": k}
+            if k in cur_vars:
+                lines.append(f"{k}={cur_vars.get(k)}")
+                continue
+            if k in beliefs_by_key:
+                bv = beliefs_by_key.get(k) if isinstance(beliefs_by_key.get(k), dict) else {}
+                lines.append(f"{k}={bv.get('belief_value')}")
+                continue
+            return False, "", {"reason": "segment_missing_key", "missing_key": k}
+
+        if intent_id == INTENT_ADD_V92:
+            a = str(slots.get("a") or "")
+            b = str(slots.get("b") or "")
+            va, ra = _parse_int_or_var(vars_map=cur_vars, tok=a, last_answer=cur_last)
+            if va is None:
+                return False, "", {"reason": "segment_missing_key", "missing_key": a, "detail": ra}
+            vb, rb = _parse_int_or_var(vars_map=cur_vars, tok=b, last_answer=cur_last)
+            if vb is None:
+                return False, "", {"reason": "segment_missing_key", "missing_key": b, "detail": rb}
+            s = int(va) + int(vb)
+            cur_last = int(s)
+            lines.append(f"SUM={s}")
+            continue
+
+        if intent_id == INTENT_SUMMARY_V92:
+            lines.append(_summarize_bindings_v96(vars_map=cur_vars, last_answer=cur_last))
+            continue
+
+        if intent_id == INTENT_END_V92:
+            lines.append("Encerrado.")
+            stop_after = True
+            break
+
+        return False, "", {"reason": "segment_intent_unsupported", "intent_id": intent_id}
+
+    agg = "\n".join(lines)
+    return True, str(agg), {"vars_map": dict(cur_vars), "last_answer": cur_last, "stop_after": bool(stop_after)}
+
+
+def _choose_comm_objective_v96(
+    *, parse: Dict[str, Any], vars_map: Dict[str, Any], last_answer: Any, beliefs_by_key: Dict[str, Dict[str, Any]]
+) -> Tuple[str, Dict[str, Any]]:
+    intent_id = str(parse.get("intent_id") or "")
+    slots = parse.get("slots") if isinstance(parse.get("slots"), dict) else {}
+    missing = parse.get("missing_slots") if isinstance(parse.get("missing_slots"), list) else []
+    if str(intent_id) == INTENT_UNKNOWN_V92:
+        return "COMM_CORRECT", {"reason": "unknown_intent"}
+    if missing:
+        missing_slot = str(missing[0])
+        return "COMM_ASK_CLARIFY", {"missing_slot": missing_slot}
+    if intent_id == INTENT_SUMMARY_V92:
+        return "COMM_SUMMARIZE", {}
+    if intent_id == INTENT_END_V92:
+        return "COMM_END", {}
+    if intent_id == INTENT_GET_V92:
+        k = str(slots.get("k") or "")
+        if not k:
+            return "COMM_ASK_CLARIFY", {"missing_slot": "k"}
+        if k in vars_map:
+            return "COMM_RESPOND", {}
+        if k in beliefs_by_key:
+            return "COMM_RESPOND", {"belief_key": k}
+        return "COMM_ASK_CLARIFY", {"missing_key": k}
+    if intent_id == INTENT_SET_V92:
+        return "COMM_RESPOND", {}
+    if intent_id == INTENT_ADD_V92:
+        a = str(slots.get("a") or "")
+        b = str(slots.get("b") or "")
+        va, _ra = _parse_int_or_var(vars_map=vars_map, tok=a, last_answer=last_answer)
+        if va is None:
+            return "COMM_ASK_CLARIFY", {"missing_key": a}
+        vb, _rb = _parse_int_or_var(vars_map=vars_map, tok=b, last_answer=last_answer)
+        if vb is None:
+            return "COMM_ASK_CLARIFY", {"missing_key": b}
+        return "COMM_RESPOND", {}
+    return "COMM_CORRECT", {"reason": f"unsupported_intent:{intent_id}"}
+
+
+def _build_expected_and_action_inputs_v96(
+    *,
+    objective_kind: str,
+    parse: Dict[str, Any],
+    vars_map: Dict[str, Any],
+    last_answer: Any,
+    beliefs_by_key: Dict[str, Dict[str, Any]],
+    ctx: Dict[str, Any],
+    user_text: str,
+) -> Tuple[str, Dict[str, Any], str]:
+    intent_id = str(parse.get("intent_id") or "")
+    slots = parse.get("slots") if isinstance(parse.get("slots"), dict) else {}
+
+    if intent_id == INTENT_TEACH_V93:
+        if bool(parse.get("teach_ok", False)):
+            text = str(ctx.get("teach_ack_text") or "")
+            return text, {"text": text}, "concept_v90_emit_text_v0"
+        if str(parse.get("reason") or "") == "ambiguous":
+            amb = ctx.get("ambiguous")
+            amb_list = amb if isinstance(amb, list) else []
+            opts: List[str] = []
+            for x in amb_list:
+                if not isinstance(x, dict):
+                    continue
+                rid = str(x.get("rule_id") or "")
+                iid = str(x.get("intent_id") or "")
+                if rid and iid:
+                    opts.append(f"{rid}:{iid}")
+            opts = sorted(set(opts))
+            text = "Confirme: " + "; ".join(opts) if opts else "Confirme."
+            return text, {"text": text}, "concept_v90_emit_text_v0"
+        msg = str(ctx.get("msg") or "")
+        return f"Comando inválido: {msg}", {"msg": msg}, "concept_v90_correct_user_v0"
+
+    if intent_id == INTENT_EXPLAIN_V94:
+        if bool(parse.get("parse_ok", False)) and str(parse.get("explained_plan_id") or ""):
+            text = str(ctx.get("explain_text") or "")
+            return text, {"text": text}, "concept_v90_emit_text_v0"
+        msg = str(ctx.get("msg") or "")
+        return f"Comando inválido: {msg}", {"msg": msg}, "concept_v90_correct_user_v0"
+
+    if intent_id == INTENT_NOTE_V96:
+        if bool(parse.get("parse_ok", False)):
+            text = str(ctx.get("note_ack_text") or "")
+            return text, {"text": text}, "concept_v90_emit_text_v0"
+        msg = str(ctx.get("msg") or "")
+        return f"Comando inválido: {msg}", {"msg": msg}, "concept_v90_correct_user_v0"
+
+    if intent_id == INTENT_RECALL_V96:
+        if bool(parse.get("parse_ok", False)):
+            text = str(ctx.get("recall_text") or "")
+            return text, {"text": text}, "concept_v90_emit_text_v0"
+        msg = str(ctx.get("msg") or "")
+        return f"Comando inválido: {msg}", {"msg": msg}, "concept_v90_correct_user_v0"
+
+    if intent_id == INTENT_FORGET_V96:
+        if bool(parse.get("parse_ok", False)) and str(ctx.get("forget_ack_text") or ""):
+            text = str(ctx.get("forget_ack_text") or "")
+            return text, {"text": text}, "concept_v90_emit_text_v0"
+        msg = str(ctx.get("msg") or "")
+        return f"Comando inválido: {msg}", {"msg": msg}, "concept_v90_correct_user_v0"
+
+    if intent_id in {INTENT_BELIEF_ADD_V96, INTENT_BELIEF_REVISE_V96, INTENT_BELIEF_LIST_V96, INTENT_BELIEF_FORGET_V96}:
+        if bool(parse.get("parse_ok", False)):
+            text = str(ctx.get("belief_text") or ctx.get("belief_ack_text") or "")
+            return text, {"text": text}, "concept_v90_emit_text_v0"
+        msg = str(ctx.get("msg") or "")
+        return f"Comando inválido: {msg}", {"msg": msg}, "concept_v90_correct_user_v0"
+
+    if bool(ctx.get("compound", False)) and objective_kind == "COMM_RESPOND":
+        text = str(ctx.get("compound_text") or "")
+        return text, {"text": text}, "concept_v90_emit_text_v0"
+
+    if objective_kind == "COMM_END":
+        return "Encerrado.", {}, "concept_v90_end_conversation_v0"
+    if objective_kind == "COMM_ADMIT_UNKNOWN":
+        return "Não sei.", {}, "concept_v90_admit_unknown_v0"
+    if objective_kind == "COMM_CORRECT":
+        msg = normalize_text_v96(str(user_text))
+        return f"Comando inválido: {msg}", {"msg": msg}, "concept_v90_correct_user_v0"
+    if objective_kind == "COMM_CONFIRM":
+        amb = ctx.get("ambiguous")
+        amb_list = amb if isinstance(amb, list) else []
+        opts2: List[str] = []
+        for x in amb_list:
+            if not isinstance(x, dict):
+                continue
+            rid = str(x.get("rule_id") or "")
+            iid = str(x.get("intent_id") or "")
+            if rid and iid:
+                opts2.append(f"{rid}:{iid}")
+        opts2 = sorted(set(opts2))
+        text = "Confirme: " + "; ".join(opts2) if opts2 else "Confirme."
+        return text, {"text": text}, "concept_v90_emit_text_v0"
+    if objective_kind == "COMM_SUMMARIZE":
+        summ = _summarize_bindings_v96(vars_map=vars_map, last_answer=last_answer)
+        return summ, {"text": summ}, "concept_v90_emit_text_v0"
+    if objective_kind == "COMM_ASK_CLARIFY":
+        missing_key = str(ctx.get("missing_key") or "")
+        missing_slot = str(ctx.get("missing_slot") or "")
+        if missing_key:
+            return f"Qual é o valor de {missing_key}?", {"k": missing_key}, "concept_v90_ask_clarify_v0"
+        if missing_slot == "v":
+            k = str(slots.get("k") or "")
+            if k:
+                return f"Qual é o valor de {k}?", {"k": k}, "concept_v90_ask_clarify_v0"
+        q = f"Faltando: {missing_slot}" if missing_slot else "Faltando: dados"
+        return q, {"text": q}, "concept_v90_emit_text_v0"
+
+    if intent_id == INTENT_SET_V92:
+        k = str(slots.get("k") or "")
+        v = str(slots.get("v") or "")
+        return f"OK: {k}={v}", {"k": k, "v": v}, "concept_v90_confirm_set_v0"
+    if intent_id == INTENT_GET_V92:
+        k = str(slots.get("k") or "")
+        if k in vars_map:
+            text = f"{k}={vars_map.get(k)}"
+            return text, {"text": text}, "concept_v90_emit_text_v0"
+        if k in beliefs_by_key:
+            bv = beliefs_by_key.get(k) if isinstance(beliefs_by_key.get(k), dict) else {}
+            text = f"{k}={bv.get('belief_value')}"
+            return text, {"text": text}, "concept_v90_emit_text_v0"
+        return "Não sei.", {}, "concept_v90_admit_unknown_v0"
+    if intent_id == INTENT_ADD_V92:
+        a = str(slots.get("a") or "")
+        b = str(slots.get("b") or "")
+        va, _ = _parse_int_or_var(vars_map=vars_map, tok=a, last_answer=last_answer)
+        vb, _ = _parse_int_or_var(vars_map=vars_map, tok=b, last_answer=last_answer)
+        if va is None or vb is None:
+            return "Não sei.", {}, "concept_v90_admit_unknown_v0"
+        s = int(int(va) + int(vb))
+        text = f"SUM={s}"
+        return text, {"sum": str(s)}, "concept_v90_emit_sum_v0"
+
+    return "Não sei.", {}, "concept_v90_admit_unknown_v0"
+
+
+def _parse_user_text_compound_v96(*, user_text: str, rules: Sequence[Any]) -> Dict[str, Any]:
+    raw = str(user_text or "")
+    if (";" in raw) or ("\n" in raw):
+        parts: List[str] = []
+        for seg in raw.replace("\n", ";").split(";"):
+            seg2 = seg.strip()
+            if seg2:
+                parts.append(seg2)
+        if len(parts) <= 1:
+            return parse_intent_v92(user_text=str(user_text), rules=list(rules))
+        segments: List[Dict[str, Any]] = []
+        seg_fail: Optional[Dict[str, Any]] = None
+        for i, seg_text in enumerate(parts):
+            sp = parse_intent_v92(user_text=str(seg_text), rules=list(rules))
+            seg_entry = {"segment_index": int(i), "segment_text": str(seg_text), "segment_parse": dict(sp)}
+            segments.append(seg_entry)
+            if seg_fail is None:
+                if not bool(sp.get("parse_ok", False)) or (isinstance(sp.get("missing_slots"), list) and sp.get("missing_slots")):
+                    seg_fail = dict(sp)
+        sem = {
+            "schema_version": 96,
+            "intent_id": INTENT_COMPOUND_V92,
+            "compound": True,
+            "policy": "all_or_nothing",
+            "segments": list(segments),
+            "matched_rule_id": "COMPOUND",
+        }
+        parse_ok = seg_fail is None
+        reason = "ok"
+        if seg_fail is not None:
+            reason = str(seg_fail.get("reason") or "segment_fail")
+        sem["parse_ok"] = bool(parse_ok)
+        sem["reason"] = str(reason)
+        sig = _stable_hash_obj(sem)
+        return dict(sem, parse_sig=str(sig))
+    return parse_intent_v92(user_text=str(user_text), rules=list(rules))
+
+
+def run_conversation_v96(
+    *,
+    user_turn_texts: Sequence[str],
+    out_dir: str,
+    seed: int,
+) -> Dict[str, Any]:
+    ensure_absent(str(out_dir))
+    os.makedirs(str(out_dir), exist_ok=False)
+
+    store_path = os.path.join(str(out_dir), "store.jsonl")
+    grammar_snapshot_path = os.path.join(str(out_dir), "intent_grammar_snapshot.json")
+    turns_path = os.path.join(str(out_dir), "conversation_turns.jsonl")
+    parses_path = os.path.join(str(out_dir), "intent_parses.jsonl")
+    learned_path = os.path.join(str(out_dir), "learned_intent_rules.jsonl")
+    plans_path = os.path.join(str(out_dir), "action_plans.jsonl")
+    memory_path = os.path.join(str(out_dir), "memory_events.jsonl")
+    belief_path = os.path.join(str(out_dir), "belief_events.jsonl")
+    states_path = os.path.join(str(out_dir), "conversation_states.jsonl")
+    trials_path = os.path.join(str(out_dir), "dialogue_trials.jsonl")
+    evals_path = os.path.join(str(out_dir), "objective_evals.jsonl")
+    transcript_path = os.path.join(str(out_dir), "transcript.jsonl")
+    verify_path = os.path.join(str(out_dir), "verify_chain_v96.json")
+    manifest_path = os.path.join(str(out_dir), "freeze_manifest_v96.json")
+    summary_path = os.path.join(str(out_dir), "summary.json")
+
+    store = ActStore()
+
+    obj_ids = comm_objective_ids_v90()
+    for okind, oid in sorted(obj_ids.items(), key=lambda kv: str(kv[0])):
+        store.add(make_comm_objective_eq_text_v90(objective_id=str(oid), objective_kind=str(okind), created_step=0))
+
+    goal_ids = {k: str(k) for k in COMM_OBJECTIVES_V90}
+    for act in action_concepts_for_dsl_v90(goal_ids=goal_ids):
+        store.add(act)
+
+    rules = default_intent_rules_v92()
+    for act in default_intent_rule_acts_v92(created_step=0):
+        store.add(act)
+
+    if os.path.exists(store_path):
+        _fail(f"store_path_exists:{store_path}")
+    store.save_jsonl(store_path)
+    store_hash = store.content_hash()
+
+    if os.path.exists(grammar_snapshot_path):
+        _fail(f"grammar_snapshot_exists:{grammar_snapshot_path}")
+    grammar_snapshot = intent_grammar_snapshot_v92(rules)
+    tmpg = grammar_snapshot_path + ".tmp"
+    with open(tmpg, "w", encoding="utf-8") as f:
+        f.write(json.dumps(grammar_snapshot, ensure_ascii=False, indent=2, sort_keys=True))
+        f.write("\n")
+    os.replace(tmpg, grammar_snapshot_path)
+
+    # Ensure ledgers exist even if empty (write-once; WORM).
+    with open(memory_path, "x", encoding="utf-8") as _f:
+        pass
+    with open(belief_path, "x", encoding="utf-8") as _f:
+        pass
+
+    engine = EngineV80(store, seed=int(seed))
+
+    conv_body = {"turns": list(user_turn_texts), "grammar_hash": str(grammar_hash_v92(rules))}
+    conversation_id = f"conv_v96_{sha256_hex(canonical_json_dumps(conv_body).encode('utf-8'))}"
+
+    vars_map: Dict[str, Any] = {}
+    last_answer: Any = ""
+
+    turns: List[Dict[str, Any]] = []
+    states: List[Dict[str, Any]] = []
+    transcript: List[Dict[str, Any]] = []
+    parse_events: List[Dict[str, Any]] = []
+    trials: List[Dict[str, Any]] = []
+    learned_rule_events: List[Dict[str, Any]] = []
+    action_plans: List[Dict[str, Any]] = []
+    memory_events: List[Dict[str, Any]] = []
+    belief_events: List[Dict[str, Any]] = []
+
+    prev_turns_hash: Optional[str] = None
+    prev_parses_hash: Optional[str] = None
+    prev_learned_hash: Optional[str] = None
+    prev_plans_hash: Optional[str] = None
+    prev_memory_hash: Optional[str] = None
+    prev_belief_hash: Optional[str] = None
+    prev_states_hash: Optional[str] = None
+    prev_trials_hash: Optional[str] = None
+    prev_evals_hash: Optional[str] = None
+    prev_transcript_hash: Optional[str] = None
+
+    support_events: List[Dict[str, Any]] = []
+    learned_rules_active: Dict[str, IntentRuleV93] = {}
+
+    memory_items_by_id: Dict[str, Dict[str, Any]] = {}
+    memory_active_ids: Dict[str, bool] = {}
+
+    belief_items_by_id: Dict[str, Dict[str, Any]] = {}
+    belief_active_by_key: Dict[str, str] = {}
+
+    state_index = 0
+    turn_index = 0
+    step = 0
+
+    def _objective_act_id(okind: str) -> str:
+        return str(obj_ids.get(okind) or "")
+
+    def _active_memory_items_sorted() -> List[Dict[str, Any]]:
+        items: List[Dict[str, Any]] = []
+        for mid in sorted(memory_active_ids.keys(), key=str):
+            if not bool(memory_active_ids.get(mid, False)):
+                continue
+            mi = memory_items_by_id.get(mid)
+            if isinstance(mi, dict):
+                items.append(dict(mi))
+        items.sort(key=lambda it: (int(it.get("created_step", 0)), str(it.get("memory_id") or "")))
+        return items
+
+    def _last_active_memory_id() -> str:
+        items = _active_memory_items_sorted()
+        if not items:
+            return ""
+        items.sort(key=lambda it: (int(it.get("created_step", 0)), str(it.get("memory_id") or "")))
+        return str(items[-1].get("memory_id") or "")
+
+    def _active_beliefs_by_key() -> Dict[str, Dict[str, Any]]:
+        out: Dict[str, Dict[str, Any]] = {}
+        for k in sorted(belief_active_by_key.keys(), key=str):
+            bid = str(belief_active_by_key.get(k) or "")
+            bi = belief_items_by_id.get(bid)
+            if isinstance(bi, dict) and bid:
+                out[str(k)] = dict(bi)
+        return dict(out)
+
+    def _last_explainable_plan() -> Optional[Dict[str, Any]]:
+        for p in reversed(action_plans):
+            if not isinstance(p, dict):
+                continue
+            if str(p.get("intent_id") or "") == INTENT_EXPLAIN_V94:
+                continue
+            return dict(p)
+        return None
+
+    def _execute_action(act_id: str, *, goal_kind: str, inputs: Dict[str, Any]) -> Tuple[bool, str, Dict[str, Any], float]:
+        concept_act = store.get_concept_act(str(act_id))
+        if concept_act is None:
+            return False, "", {"ok": False, "reason": "action_not_found"}, 0.0
+        iface = concept_act.evidence.get("interface") if isinstance(concept_act.evidence, dict) else {}
+        in_schema = iface.get("input_schema") if isinstance(iface, dict) else {}
+        in_schema = in_schema if isinstance(in_schema, dict) else {}
+        inps: Dict[str, Any] = {}
+        for k in sorted(in_schema.keys(), key=str):
+            ks = str(k)
+            val = inputs.get(ks)
+            if isinstance(in_schema.get(k), str) and str(in_schema.get(k)) == "str":
+                inps[ks] = "" if val is None else str(val)
+            else:
+                inps[ks] = val
+        exec_res = engine.execute_concept_csv(
+            concept_act_id=str(act_id),
+            inputs=dict(inps),
+            goal_kind=str(goal_kind),
+            expected=None,
+            step=int(step),
+            max_depth=6,
+            max_events=256,
+            validate_output=False,
+        )
+        meta = exec_res.get("meta") if isinstance(exec_res.get("meta"), dict) else {}
+        if not bool(meta.get("ok", False)):
+            return False, "", dict(meta), 0.0
+        out_text = str(meta.get("output_text") or exec_res.get("output") or "")
+        trace = exec_res.get("trace") if isinstance(exec_res.get("trace"), dict) else {}
+        calls = trace.get("concept_calls") if isinstance(trace.get("concept_calls"), list) else []
+        cost_used = 0.0
+        for c in calls:
+            if not isinstance(c, dict):
+                continue
+            cost_used += float(c.get("cost") or 0.0)
+        return True, str(out_text), dict(meta), float(cost_used)
+
+    for user_text in list(user_turn_texts):
+        active_learned_rules = [learned_rules_active[k] for k in sorted(learned_rules_active.keys(), key=str)]
+        rules_for_parse: List[Any] = list(rules) + list(active_learned_rules)
+
+        parse: Dict[str, Any] = {}
+        ctx: Dict[str, Any] = {}
+
+        # Intercepts: TEACH -> EXPLAIN -> BELIEFS -> BELIEF/REVISE -> FORGET (memory/belief) -> NOTE/RECALL -> parser V92/compound.
+        if is_teach_command_v93(str(user_text)):
+            te = parse_teach_command_v93(str(user_text))
+            teach_ok = False
+            teach_reason = str(te.get("reason") or "not_recognized")
+            lhs_raw = str(te.get("lhs_raw") or "")
+            rhs_raw = str(te.get("rhs_raw") or "")
+            rhs_parse_sig = ""
+            rhs_intent_id = ""
+            rhs_rule_id = ""
+            rhs_reason = ""
+            lhs_info: Dict[str, Any] = {}
+            ambiguous_rule_ids: List[str] = []
+            ambiguous_intents: List[Dict[str, Any]] = []
+            pending_learned_rule: Optional[IntentRuleV93] = None
+
+            if bool(te.get("recognized", False)) and bool(te.get("ok", False)):
+                lhs_info = canonize_lhs_for_learned_rule_v93(lhs_raw)
+                stripped = lhs_info.get("lhs_tokens_canon_stripped")
+                stripped_list = [str(x) for x in stripped if isinstance(stripped, list) and isinstance(x, str) and x]
+                if not stripped_list:
+                    teach_ok = False
+                    teach_reason = "lhs_empty_after_normalization"
+                else:
+                    rhs_parse = parse_intent_v92(user_text=str(rhs_raw), rules=list(rules))
+                    rhs_parse_sig = str(rhs_parse.get("parse_sig") or "")
+                    rhs_intent_id = str(rhs_parse.get("intent_id") or "")
+                    rhs_rule_id = str(rhs_parse.get("matched_rule_id") or "")
+                    rhs_reason = str(rhs_parse.get("reason") or "")
+                    if not bool(rhs_parse.get("parse_ok", False)):
+                        teach_reason = f"rhs_parse_fail:{rhs_reason or 'no_match'}"
+                    elif rhs_parse.get("missing_slots"):
+                        teach_reason = "rhs_missing_slots"
+                    elif rhs_intent_id not in {INTENT_SUMMARY_V92, INTENT_END_V92}:
+                        teach_reason = "rhs_intent_disallowed"
+                    else:
+                        learned_rule = make_learned_intent_rule_v93(intent_id=str(rhs_intent_id), lhs_tokens_canon=stripped_list)
+                        conflicts = []
+                        for r in rules:
+                            try:
+                                rid = str(getattr(r, "rule_id", ""))
+                                pat = getattr(r, "pattern", [])
+                            except Exception:
+                                rid = ""
+                                pat = []
+                            if not isinstance(pat, list):
+                                continue
+                            if [str(x) for x in pat] == stripped_list:
+                                conflicts.append({"rule_id": str(rid), "intent_id": str(getattr(r, "intent_id", ""))})
+                        conflicts = sorted(conflicts, key=lambda d: str(d.get("rule_id") or ""))
+                        if conflicts:
+                            teach_ok = False
+                            teach_reason = "ambiguous"
+                            ambiguous_rule_ids = [str(x.get("rule_id") or "") for x in conflicts]
+                            ambiguous_intents = list(conflicts)
+                        else:
+                            teach_ok = True
+                            teach_reason = "ok"
+                            pending_learned_rule = learned_rule
+
+            sem = {
+                "schema_version": 96,
+                "intent_id": INTENT_TEACH_V93,
+                "matched_rule_id": "",
+                "compound": False,
+                "parse_ok": bool(teach_ok),
+                "reason": str(teach_reason),
+                "lhs_raw": str(lhs_raw),
+                "rhs_raw": str(rhs_raw),
+                "rhs_parse_sig": str(rhs_parse_sig),
+                "rhs_intent_id": str(rhs_intent_id),
+                "rhs_rule_id": str(rhs_rule_id),
+                "rhs_reason": str(rhs_reason),
+                "teach_ok": bool(teach_ok),
+                "learned_rule_id": str(pending_learned_rule.rule_id) if pending_learned_rule else "",
+            }
+            sig = _stable_hash_obj(sem)
+            parse = dict(sem, parse_sig=str(sig))
+            if teach_ok and pending_learned_rule is not None:
+                learned_row = {
+                    "kind": "learned_intent_rule_v96",
+                    "time": deterministic_iso(step=int(step)),
+                    "step": int(step),
+                    "teacher_turn_id": "",  # filled after user turn exists
+                    "lhs_raw": str(lhs_raw),
+                    "rhs_raw": str(rhs_raw),
+                    "rhs_parse_sig": str(rhs_parse_sig),
+                    "rhs_intent_id": str(rhs_intent_id),
+                    "rhs_rule_id": str(rhs_rule_id),
+                    "learned_rule": dict(pending_learned_rule.to_dict()),
+                    "provenance": {
+                        "lhs_raw": str(lhs_raw),
+                        "rhs_raw": str(rhs_raw),
+                    },
+                }
+                ctx["pending_learned_rule"] = pending_learned_rule
+                ctx["pending_learned_row"] = learned_row
+            if teach_reason == "ambiguous":
+                ctx["ambiguous"] = list(ambiguous_intents)
+
+        elif is_explain_command_v94(str(user_text)):
+            ex = parse_explain_command_v94(str(user_text))
+            ok = bool(ex.get("recognized", False)) and bool(ex.get("ok", False))
+            reason = str(ex.get("reason") or "not_recognized")
+            explained_plan_id = ""
+            explain_text = ""
+            if ok:
+                lastp = _last_explainable_plan()
+                if lastp is None:
+                    ok = False
+                    reason = "no_prior_plan"
+                else:
+                    explained_plan_id = str(lastp.get("plan_id") or "")
+                    explain_text = render_explain_text_v96(lastp)
+            sem = {
+                "schema_version": 96,
+                "intent_id": INTENT_EXPLAIN_V94,
+                "matched_rule_id": "",
+                "compound": False,
+                "parse_ok": bool(ok),
+                "reason": str(reason),
+                "explained_plan_id": str(explained_plan_id),
+                "prefix": str(ex.get("prefix") or ""),
+            }
+            sig = _stable_hash_obj(sem)
+            parse = dict(sem, parse_sig=str(sig))
+            ctx["explain_text"] = str(explain_text)
+            ctx["msg"] = str(reason or "")
+
+        elif is_beliefs_list_command_v96(str(user_text)):
+            be = parse_beliefs_list_command_v96(str(user_text))
+            ok = bool(be.get("recognized", False)) and bool(be.get("ok", False))
+            reason = str(be.get("reason") or "not_recognized")
+            sem = {
+                "schema_version": 96,
+                "intent_id": INTENT_BELIEF_LIST_V96,
+                "matched_rule_id": "",
+                "compound": False,
+                "parse_ok": bool(ok),
+                "reason": str(reason),
+                "prefix": str(be.get("prefix") or ""),
+            }
+            sig = _stable_hash_obj(sem)
+            parse = dict(sem, parse_sig=str(sig))
+
+        elif is_belief_add_command_v96(str(user_text)):
+            be = parse_belief_add_command_v96(str(user_text))
+            ok = bool(be.get("recognized", False)) and bool(be.get("ok", False))
+            reason = str(be.get("reason") or "not_recognized")
+            key = str(be.get("belief_key") or "")
+            val = str(be.get("belief_value") or "")
+            if ok and key in belief_active_by_key:
+                ok = False
+                reason = "key_exists_use_revise"
+            sem = {
+                "schema_version": 96,
+                "intent_id": INTENT_BELIEF_ADD_V96,
+                "matched_rule_id": "",
+                "compound": False,
+                "parse_ok": bool(ok),
+                "reason": str(reason),
+                "prefix": str(be.get("prefix") or ""),
+                "belief_key": str(key),
+                "belief_value": str(val),
+            }
+            sig = _stable_hash_obj(sem)
+            parse = dict(sem, parse_sig=str(sig))
+
+        elif is_belief_revise_command_v96(str(user_text)):
+            be = parse_belief_revise_command_v96(str(user_text))
+            ok = bool(be.get("recognized", False)) and bool(be.get("ok", False))
+            reason = str(be.get("reason") or "not_recognized")
+            key = str(be.get("belief_key") or "")
+            val = str(be.get("belief_value") or "")
+            if ok and key not in belief_active_by_key:
+                ok = False
+                reason = "missing_key_use_belief"
+            sem = {
+                "schema_version": 96,
+                "intent_id": INTENT_BELIEF_REVISE_V96,
+                "matched_rule_id": "",
+                "compound": False,
+                "parse_ok": bool(ok),
+                "reason": str(reason),
+                "prefix": str(be.get("prefix") or ""),
+                "belief_key": str(key),
+                "belief_value": str(val),
+            }
+            sig = _stable_hash_obj(sem)
+            parse = dict(sem, parse_sig=str(sig))
+
+        elif is_forget_command_v96(str(user_text)):
+            fe = parse_forget_command_v96(str(user_text))
+            ok = bool(fe.get("recognized", False)) and bool(fe.get("ok", False))
+            reason = str(fe.get("reason") or "not_recognized")
+            target_kind = str(fe.get("target_kind") or "")
+            belief_key = str(fe.get("belief_key") or "")
+            if ok and target_kind == "belief":
+                if belief_key not in belief_active_by_key:
+                    ok = False
+                    reason = "missing_key"
+            sem = {
+                "schema_version": 96,
+                "intent_id": INTENT_BELIEF_FORGET_V96 if target_kind == "belief" else INTENT_FORGET_V96,
+                "matched_rule_id": "",
+                "compound": False,
+                "parse_ok": bool(ok),
+                "reason": str(reason),
+                "prefix": str(fe.get("prefix") or ""),
+                "target_kind": str(target_kind),
+                "target": str(fe.get("target") or ""),
+                "belief_key": str(belief_key),
+            }
+            sig = _stable_hash_obj(sem)
+            parse = dict(sem, parse_sig=str(sig))
+
+        elif is_note_command_v96(str(user_text)):
+            ne = parse_note_command_v96(str(user_text))
+            ok = bool(ne.get("recognized", False)) and bool(ne.get("ok", False))
+            reason = str(ne.get("reason") or "not_recognized")
+            sem = {
+                "schema_version": 96,
+                "intent_id": INTENT_NOTE_V96,
+                "matched_rule_id": "",
+                "compound": False,
+                "parse_ok": bool(ok),
+                "reason": str(reason),
+                "prefix": str(ne.get("prefix") or ""),
+                "memory_text_raw": str(ne.get("memory_text_raw") or ""),
+            }
+            sig = _stable_hash_obj(sem)
+            parse = dict(sem, parse_sig=str(sig))
+
+        elif is_recall_command_v96(str(user_text)):
+            re = parse_recall_command_v96(str(user_text))
+            ok = bool(re.get("recognized", False)) and bool(re.get("ok", False))
+            reason = str(re.get("reason") or "not_recognized")
+            sem = {
+                "schema_version": 96,
+                "intent_id": INTENT_RECALL_V96,
+                "matched_rule_id": "",
+                "compound": False,
+                "parse_ok": bool(ok),
+                "reason": str(reason),
+                "prefix": str(re.get("prefix") or ""),
+            }
+            sig = _stable_hash_obj(sem)
+            parse = dict(sem, parse_sig=str(sig))
+
+        else:
+            parse = _parse_user_text_compound_v96(user_text=str(user_text), rules=list(rules_for_parse))
+
+        # Create user turn.
+        ut = TurnV96(
+            conversation_id=str(conversation_id),
+            turn_index=int(turn_index),
+            role="user",
+            text=str(user_text),
+            created_step=int(step),
+            offset_us=0,
+            parse_sig=str(parse.get("parse_sig") or ""),
+            intent_id=str(parse.get("intent_id") or ""),
+            matched_rule_id=str(parse.get("matched_rule_id") or ""),
+        ).to_dict()
+        turn_index += 1
+        step += 1
+        turns.append(dict(ut))
+        prev_turns_hash = append_chained_jsonl_v96(
+            turns_path,
+            {"time": deterministic_iso(step=int(ut["created_step"])), "step": int(ut["created_step"]), "event": "TURN", "payload": dict(ut)},
+            prev_hash=prev_turns_hash,
+        )
+        transcript.append({"role": "user", "text": str(ut.get("text") or ""), "turn_id": str(ut.get("turn_id") or "")})
+        prev_transcript_hash = append_chained_jsonl_v96(
+            transcript_path,
+            {"time": deterministic_iso(step=int(ut["created_step"])), "step": int(ut["created_step"]), "event": "UTTERANCE", "payload": dict(transcript[-1])},
+            prev_hash=prev_transcript_hash,
+        )
+
+        # Log parse (WORM, hash-chained).
+        parse_event = {
+            "kind": "intent_parse_v96",
+            "time": deterministic_iso(step=int(step)),
+            "step": int(step),
+            "turn_id": str(ut.get("turn_id") or ""),
+            "turn_index": int(ut.get("turn_index") or 0),
+            "payload": dict(parse),
+        }
+        prev_parses_hash = append_chained_jsonl_v96(parses_path, dict(parse_event), prev_hash=prev_parses_hash)
+        parse_events.append({"turn_id": str(parse_event["turn_id"]), "turn_index": int(parse_event["turn_index"]), "payload": dict(parse)})
+
+        # Apply learning (TEACH) after user turn exists, before executing actions.
+        if str(parse.get("intent_id") or "") == "INTENT_TEACH" and bool(parse.get("teach_ok", False)):
+            lr = ctx.get("pending_learned_rule")
+            row = ctx.get("pending_learned_row")
+            if isinstance(lr, IntentRuleV93) and isinstance(row, dict):
+                learned_row = dict(row)
+                learned_row["teacher_turn_id"] = str(ut.get("turn_id") or "")
+                learned_row["provenance"] = dict(learned_row.get("provenance") or {})
+                learned_row["provenance"]["teacher_turn_id"] = str(ut.get("turn_id") or "")
+                prev_learned_hash = append_chained_jsonl_v96(learned_path, dict(learned_row), prev_hash=prev_learned_hash)
+                learned_rule_events.append(dict(learned_row))
+                learned_rules_active[str(lr.rule_id)] = lr
+
+        # Memory/belief ops produce read/write refs for plan.
+        memory_read_ids: List[str] = []
+        memory_write_event_ids: List[str] = []
+        belief_read_keys: List[str] = []
+        belief_read_ids: List[str] = []
+        belief_write_event_ids: List[str] = []
+
+        objective_kind = ""
+        ctx2: Dict[str, Any] = {}
+
+        beliefs_active = _active_beliefs_by_key()
+
+        if str(parse.get("intent_id") or "") == INTENT_NOTE_V96:
+            if bool(parse.get("parse_ok", False)):
+                txt = str(parse.get("memory_text_raw") or "")
+                mi = MemoryItemV96(conversation_id=str(conversation_id), memory_text=str(txt), source_turn_id=str(ut.get("turn_id") or ""), created_step=int(step)).to_dict()
+                mid = str(mi.get("memory_id") or "")
+                ev = MemoryEventV96(
+                    conversation_id=str(conversation_id),
+                    event_kind="ADD",
+                    created_step=int(step),
+                    source_turn_id=str(ut.get("turn_id") or ""),
+                    memory_item=dict(mi),
+                ).to_dict()
+                prev_memory_hash = append_chained_jsonl_v96(memory_path, dict(ev), prev_hash=prev_memory_hash)
+                memory_events.append(dict(ev))
+                if mid:
+                    memory_items_by_id[mid] = dict(mi)
+                    memory_active_ids[mid] = True
+                memory_write_event_ids.append(str(ev.get("event_id") or ""))
+                objective_kind = "COMM_RESPOND"
+                ctx2 = {"note_ack_text": render_note_ack_text_v96(mid)}
+            else:
+                objective_kind = "COMM_CORRECT"
+                ctx2 = {"msg": f"note_reject:{str(parse.get('reason') or '')}"}
+
+        elif str(parse.get("intent_id") or "") == INTENT_RECALL_V96:
+            if bool(parse.get("parse_ok", False)):
+                items = _active_memory_items_sorted()
+                memory_read_ids = [str(it.get("memory_id") or "") for it in items if isinstance(it, dict) and str(it.get("memory_id") or "")]
+                objective_kind = "COMM_RESPOND"
+                ctx2 = {"recall_text": render_recall_text_v96(items)}
+            else:
+                objective_kind = "COMM_CORRECT"
+                ctx2 = {"msg": f"recall_reject:{str(parse.get('reason') or '')}"}
+
+        elif str(parse.get("intent_id") or "") == INTENT_FORGET_V96:
+            if bool(parse.get("parse_ok", False)):
+                target_mid = _last_active_memory_id()
+                if not target_mid:
+                    objective_kind = "COMM_CORRECT"
+                    ctx2 = {"msg": "no_active_memory"}
+                else:
+                    ev = MemoryEventV96(
+                        conversation_id=str(conversation_id),
+                        event_kind="RETRACT",
+                        created_step=int(step),
+                        source_turn_id=str(ut.get("turn_id") or ""),
+                        target_memory_id=str(target_mid),
+                        retract_reason="user_forget_last",
+                    ).to_dict()
+                    prev_memory_hash = append_chained_jsonl_v96(memory_path, dict(ev), prev_hash=prev_memory_hash)
+                    memory_events.append(dict(ev))
+                    memory_active_ids.pop(str(target_mid), None)
+                    memory_read_ids = [str(target_mid)]
+                    memory_write_event_ids.append(str(ev.get("event_id") or ""))
+                    objective_kind = "COMM_RESPOND"
+                    ctx2 = {"forget_ack_text": render_forget_ack_text_v96(target_mid)}
+            else:
+                objective_kind = "COMM_CORRECT"
+                ctx2 = {"msg": f"forget_reject:{str(parse.get('reason') or '')}"}
+
+        elif str(parse.get("intent_id") or "") == INTENT_BELIEF_ADD_V96:
+            if bool(parse.get("parse_ok", False)):
+                key = str(parse.get("belief_key") or "").strip()
+                val = str(parse.get("belief_value") or "").strip()
+                bi = BeliefItemV96(conversation_id=str(conversation_id), belief_key=str(key), belief_value=str(val), source_turn_id=str(ut.get("turn_id") or ""), created_step=int(step)).to_dict()
+                bid = str(bi.get("belief_id") or "")
+                ev = BeliefEventV96(
+                    conversation_id=str(conversation_id),
+                    event_kind="ADD",
+                    created_step=int(step),
+                    source_turn_id=str(ut.get("turn_id") or ""),
+                    belief_item=dict(bi),
+                ).to_dict()
+                prev_belief_hash = append_chained_jsonl_v96(belief_path, dict(ev), prev_hash=prev_belief_hash)
+                belief_events.append(dict(ev))
+                if bid and key:
+                    belief_items_by_id[bid] = dict(bi)
+                    belief_active_by_key[key] = bid
+                belief_write_event_ids.append(str(ev.get("event_id") or ""))
+                objective_kind = "COMM_RESPOND"
+                ctx2 = {"belief_ack_text": render_belief_added_ack_text_v96(belief_id=bid, key=key)}
+            else:
+                objective_kind = "COMM_CORRECT"
+                ctx2 = {"msg": f"belief_reject:{str(parse.get('reason') or '')}"}
+
+        elif str(parse.get("intent_id") or "") == INTENT_BELIEF_REVISE_V96:
+            if bool(parse.get("parse_ok", False)):
+                key = str(parse.get("belief_key") or "").strip()
+                val = str(parse.get("belief_value") or "").strip()
+                old_id = str(belief_active_by_key.get(key) or "")
+                if not old_id:
+                    objective_kind = "COMM_CORRECT"
+                    ctx2 = {"msg": "missing_key_use_belief"}
+                else:
+                    belief_read_keys = [str(key)]
+                    belief_read_ids = [str(old_id)]
+                    evr = BeliefEventV96(
+                        conversation_id=str(conversation_id),
+                        event_kind="RETRACT",
+                        created_step=int(step),
+                        source_turn_id=str(ut.get("turn_id") or ""),
+                        target_belief_id=str(old_id),
+                        retract_reason="user_revise",
+                    ).to_dict()
+                    prev_belief_hash = append_chained_jsonl_v96(belief_path, dict(evr), prev_hash=prev_belief_hash)
+                    belief_events.append(dict(evr))
+                    bi = BeliefItemV96(conversation_id=str(conversation_id), belief_key=str(key), belief_value=str(val), source_turn_id=str(ut.get("turn_id") or ""), created_step=int(step)).to_dict()
+                    bid = str(bi.get("belief_id") or "")
+                    eva = BeliefEventV96(
+                        conversation_id=str(conversation_id),
+                        event_kind="ADD",
+                        created_step=int(step),
+                        source_turn_id=str(ut.get("turn_id") or ""),
+                        belief_item=dict(bi),
+                    ).to_dict()
+                    prev_belief_hash = append_chained_jsonl_v96(belief_path, dict(eva), prev_hash=prev_belief_hash)
+                    belief_events.append(dict(eva))
+                    if bid and key:
+                        belief_items_by_id[bid] = dict(bi)
+                        belief_active_by_key[key] = bid
+                    belief_write_event_ids.extend([str(evr.get("event_id") or ""), str(eva.get("event_id") or "")])
+                    objective_kind = "COMM_RESPOND"
+                    ctx2 = {"belief_ack_text": render_belief_revised_ack_text_v96(key=key, old_id=old_id, new_id=bid)}
+            else:
+                objective_kind = "COMM_CORRECT"
+                ctx2 = {"msg": f"revise_reject:{str(parse.get('reason') or '')}"}
+
+        elif str(parse.get("intent_id") or "") == INTENT_BELIEF_LIST_V96:
+            if bool(parse.get("parse_ok", False)):
+                beliefs_active = _active_beliefs_by_key()
+                belief_read_keys = sorted(beliefs_active.keys(), key=str)
+                belief_read_ids = [str(beliefs_active[k].get("belief_id") or "") for k in belief_read_keys if isinstance(beliefs_active.get(k), dict)]
+                objective_kind = "COMM_RESPOND"
+                ctx2 = {"belief_text": render_beliefs_text_v96(beliefs_active)}
+            else:
+                objective_kind = "COMM_CORRECT"
+                ctx2 = {"msg": f"beliefs_reject:{str(parse.get('reason') or '')}"}
+
+        elif str(parse.get("intent_id") or "") == INTENT_BELIEF_FORGET_V96:
+            if bool(parse.get("parse_ok", False)):
+                key = str(parse.get("belief_key") or "").strip()
+                old_id = str(belief_active_by_key.get(key) or "")
+                if not old_id:
+                    objective_kind = "COMM_CORRECT"
+                    ctx2 = {"msg": "missing_key"}
+                else:
+                    belief_read_keys = [str(key)]
+                    belief_read_ids = [str(old_id)]
+                    ev = BeliefEventV96(
+                        conversation_id=str(conversation_id),
+                        event_kind="RETRACT",
+                        created_step=int(step),
+                        source_turn_id=str(ut.get("turn_id") or ""),
+                        target_belief_id=str(old_id),
+                        retract_reason="user_forget_belief",
+                    ).to_dict()
+                    prev_belief_hash = append_chained_jsonl_v96(belief_path, dict(ev), prev_hash=prev_belief_hash)
+                    belief_events.append(dict(ev))
+                    belief_active_by_key.pop(str(key), None)
+                    belief_write_event_ids.append(str(ev.get("event_id") or ""))
+                    objective_kind = "COMM_RESPOND"
+                    ctx2 = {"belief_ack_text": render_belief_retracted_ack_text_v96(belief_id=old_id, key=key)}
+            else:
+                objective_kind = "COMM_CORRECT"
+                ctx2 = {"msg": f"forget_belief_reject:{str(parse.get('reason') or '')}"}
+
+        elif str(parse.get("intent_id") or "") == INTENT_TEACH_V93:
+            teach_ok = bool(parse.get("teach_ok", False))
+            teach_reason = str(parse.get("reason") or "")
+            if teach_ok:
+                objective_kind = "COMM_RESPOND"
+                lrid = str(parse.get("learned_rule_id") or "")
+                rhs_intent_id = str(parse.get("rhs_intent_id") or "")
+                lhs_raw = str(parse.get("lhs_raw") or "")
+                ack = f'Aprendido: "{lhs_raw}" → {rhs_intent_id} (rule_id={lrid})'
+                ctx2 = {"teach_ack_text": str(ack)}
+            elif teach_reason == "ambiguous":
+                objective_kind = "COMM_CONFIRM"
+                ctx2 = {"ambiguous": list(ctx.get("ambiguous") if isinstance(ctx.get("ambiguous"), list) else [])}
+            else:
+                objective_kind = "COMM_CORRECT"
+                ctx2 = {"msg": f"teach_reject:{teach_reason}"}
+
+        elif str(parse.get("intent_id") or "") == INTENT_EXPLAIN_V94:
+            if bool(parse.get("parse_ok", False)) and str(parse.get("explained_plan_id") or ""):
+                objective_kind = "COMM_RESPOND"
+                ctx2 = {"explain_text": str(ctx.get("explain_text") or "")}
+            else:
+                r = str(parse.get("reason") or "")
+                objective_kind = "COMM_CORRECT"
+                ctx2 = {"msg": f"explain_reject:{r or 'parse_fail'}"}
+
+        else:
+            objective_kind, ctx2 = _choose_comm_objective_v96(
+                parse=dict(parse), vars_map=dict(vars_map), last_answer=last_answer, beliefs_by_key=dict(beliefs_active)
+            )
+
+        # Compound execution (same as V92/V95).
+        compound_stop_after = False
+        if bool(parse.get("compound", False)) and bool(parse.get("parse_ok", False)):
+            ok_comp, agg_text, info = _simulate_compound_execution_v96(
+                parse=dict(parse), vars_map=dict(vars_map), last_answer=last_answer, beliefs_by_key=dict(beliefs_active)
+            )
+            if ok_comp:
+                vars_map = dict(info.get("vars_map") or {})
+                last_answer = info.get("last_answer")
+                compound_stop_after = bool(info.get("stop_after", False))
+                objective_kind = "COMM_RESPOND"
+                ctx2 = {"compound": True, "compound_text": str(agg_text)}
+            else:
+                r = str(info.get("reason") or "")
+                if r == "segment_missing_key":
+                    objective_kind = "COMM_ASK_CLARIFY"
+                    ctx2 = {"missing_key": str(info.get("missing_key") or "")}
+                else:
+                    objective_kind = "COMM_CORRECT"
+                    ctx2 = {"reason": f"compound_exec_fail:{r}"}
+
+        # Apply DSL state mutation for non-compound, parse_ok and complete.
+        slots = parse.get("slots") if isinstance(parse.get("slots"), dict) else {}
+        if (not bool(parse.get("compound", False))) and bool(parse.get("parse_ok", False)) and not (parse.get("missing_slots") or []):
+            if str(parse.get("intent_id") or "") == INTENT_SET_V92:
+                k = str(slots.get("k") or "")
+                v = str(slots.get("v") or "")
+                if k and v:
+                    vars_map[k] = int(v) if _is_int_literal(v) else v
+            elif str(parse.get("intent_id") or "") == INTENT_ADD_V92:
+                a = str(slots.get("a") or "")
+                b = str(slots.get("b") or "")
+                va, _ra = _parse_int_or_var(vars_map=vars_map, tok=a, last_answer=last_answer)
+                vb, _rb = _parse_int_or_var(vars_map=vars_map, tok=b, last_answer=last_answer)
+                if va is not None and vb is not None:
+                    last_answer = int(int(va) + int(vb))
+
+        # GET reads belief if var missing.
+        if str(parse.get("intent_id") or "") == INTENT_GET_V92:
+            k = str(slots.get("k") or "")
+            if k and (k not in vars_map) and (k in beliefs_active):
+                it = beliefs_active.get(k) if isinstance(beliefs_active.get(k), dict) else {}
+                belief_read_keys = [str(k)]
+                belief_read_ids = [str(it.get("belief_id") or "")]
+
+        expected_text, action_inputs, hint_action_id = _build_expected_and_action_inputs_v96(
+            objective_kind=str(objective_kind),
+            parse=dict(parse),
+            vars_map=dict(vars_map),
+            last_answer=last_answer,
+            beliefs_by_key=dict(beliefs_active),
+            ctx=dict(ctx2),
+            user_text=str(user_text),
+        )
+
+        chosen_action_id = ""
+        chosen_objective_id = ""
+        chosen_eval_id = ""
+        chosen_ok = False
+        chosen_cost = 0.0
+        assistant_text = ""
+        plan_ranked_candidates: List[Dict[str, Any]] = []
+        plan_attempted_actions: List[Dict[str, Any]] = []
+        plan_objective_kind = ""
+        plan_objective_id = ""
+
+        if str(objective_kind) == "COMM_END":
+            assistant_text = "Encerrado."
+            chosen_action_id = "concept_v90_end_conversation_v0"
+            chosen_objective_id = _objective_act_id("COMM_END")
+            chosen_eval_id = _stable_hash_obj({"turn_id": str(ut.get("turn_id") or ""), "kind": "end"})
+            chosen_ok = True
+            chosen_cost = 0.0
+            plan_ranked_candidates = [{"act_id": chosen_action_id, "expected_success": 1.0, "expected_cost": 0.0}]
+            plan_attempted_actions = [{"act_id": chosen_action_id, "eval_id": chosen_eval_id, "ok": True}]
+            plan_objective_kind = "COMM_END"
+            plan_objective_id = chosen_objective_id
+        else:
+            goal_id = str(objective_kind)
+            goal_kind = str(objective_kind)
+            candidates0 = list_supporting_concepts_for_goal_v89(store=store, goal_id=str(goal_id))
+            ranked = _rank_action_candidates_v96(candidates=list(candidates0), events=list(support_events), goal_id=str(goal_id))
+
+            hint = str(hint_action_id or "")
+            ranked_ids = [str(act_id) for act_id, _claim, _es, _ec in ranked]
+            if hint and hint in set(ranked_ids):
+                ranked.sort(key=lambda t: (0 if str(t[0]) == hint else 1, -float(t[2]), float(t[3]), str(t[0])))
+
+            plan_ranked_candidates = [{"act_id": str(a), "expected_success": _round6(es), "expected_cost": _round6(ec)} for a, _c, es, ec in ranked]
+            plan_objective_kind = str(goal_kind)
+            plan_objective_id = _objective_act_id(str(goal_kind))
+
+            # Attempt in ranked order until objective passes.
+            def _try_actions() -> bool:
+                nonlocal chosen_action_id, chosen_objective_id, chosen_eval_id, chosen_ok, chosen_cost, assistant_text
+                for act_id, _claim, _es, _ec in ranked:
+                    ok_exec, out_text, _meta, cost_used = _execute_action(str(act_id), goal_kind=str(goal_kind), inputs=dict(action_inputs))
+                    eval_id = _stable_hash_obj(
+                        {
+                            "conversation_id": str(conversation_id),
+                            "turn_id": str(ut.get("turn_id") or ""),
+                            "step": int(step),
+                            "objective_kind": str(goal_kind),
+                            "objective_id": str(plan_objective_id),
+                            "act_id": str(act_id),
+                            "expected_text_sig": text_sig_v96(str(expected_text)),
+                            "output_text_sig": text_sig_v96(str(out_text)),
+                        }
+                    )
+                    objective_inputs = {
+                        "__output": str(out_text),
+                        "expected": str(expected_text),
+                        "__goal": str(goal_kind),
+                        "__step": int(step),
+                    }
+                    verdict_ok = False
+                    verdict: Dict[str, Any] = {}
+                    if not ok_exec:
+                        verdict_ok = False
+                        verdict = {
+                            "ok": False,
+                            "score": 0,
+                            "reason": f"action_exec_failed:{str(_meta.get('reason') or '')}",
+                            "details": {"meta": dict(_meta) if isinstance(_meta, dict) else {}},
+                        }
+                    else:
+                        verdict_obj = execute_objective_csv_v88(
+                            store=store,
+                            seed=int(seed),
+                            objective_act_id=str(plan_objective_id),
+                            inputs=dict(objective_inputs),
+                            step=int(step),
+                            goal_kind=str(goal_kind),
+                        )
+                        verdict = verdict_obj.to_dict()
+                        verdict_ok = bool(verdict_obj.ok)
+                    expected_sig = text_sig_v96(str(expected_text))
+                    output_sig = text_sig_v96(str(out_text))
+                    eval_row = {
+                        "kind": "objective_eval_v96",
+                        "time": deterministic_iso(step=int(step)),
+                        "step": int(step),
+                        "eval_id": str(eval_id),
+                        "conversation_id": str(conversation_id),
+                        "turn_id": str(ut.get("turn_id") or ""),
+                        "objective_kind": str(goal_kind),
+                        "objective_id": str(plan_objective_id),
+                        "action_concept_id": str(act_id),
+                        "expected_text": str(expected_text),
+                        "output_text": str(out_text),
+                        "expected_text_sig": str(expected_sig),
+                        "output_text_sig": str(output_sig),
+                        "verdict": dict(verdict),
+                    }
+                    nonlocal prev_evals_hash
+                    prev_evals_hash = append_chained_jsonl_v96(evals_path, dict(eval_row), prev_hash=prev_evals_hash)
+
+                    trial_id = _stable_hash_obj(
+                        {
+                            "conversation_id": str(conversation_id),
+                            "turn_id": str(ut.get("turn_id") or ""),
+                            "step": int(step),
+                            "objective_kind": str(goal_kind),
+                            "objective_id": str(plan_objective_id),
+                            "act_id": str(act_id),
+                            "eval_id": str(eval_id),
+                        }
+                    )
+                    trial_row = {
+                        "kind": "dialogue_trial_v96",
+                        "time": deterministic_iso(step=int(step)),
+                        "step": int(step),
+                        "trial_id": str(trial_id),
+                        "conversation_id": str(conversation_id),
+                        "turn_id": str(ut.get("turn_id") or ""),
+                        "user_turn_id": str(ut.get("turn_id") or ""),
+                        "objective_kind": str(goal_kind),
+                        "objective_id": str(plan_objective_id),
+                        "action_concept_id": str(act_id),
+                        "eval_id": str(eval_id),
+                        "expected_text": str(expected_text),
+                        "expected_text_sig": str(expected_sig),
+                        "assistant_text": str(out_text),
+                        "assistant_text_sig": str(output_sig),
+                        "ok": bool(verdict_ok),
+                        "cost_used": float(cost_used),
+                    }
+                    nonlocal prev_trials_hash
+                    prev_trials_hash = append_chained_jsonl_v96(trials_path, dict(trial_row), prev_hash=prev_trials_hash)
+
+                    support_ev = make_goal_support_evidence_event_v89(
+                        step=int(step),
+                        goal_id=str(goal_kind),
+                        concept_key=str(act_id),
+                        attempt_id=str(trial_id),
+                        ok=bool(verdict_ok),
+                        cost_used=float(cost_used),
+                        note=str(verdict.get("reason") or ""),
+                    )
+                    support_events.append(dict(support_ev))
+
+                    plan_attempted_actions.append({"act_id": str(act_id), "eval_id": str(eval_id), "ok": bool(verdict_ok)})
+
+                    if verdict_ok and ok_exec:
+                        assistant_text = str(out_text)
+                        chosen_action_id = str(act_id)
+                        chosen_objective_id = str(plan_objective_id)
+                        chosen_eval_id = str(eval_id)
+                        chosen_ok = True
+                        chosen_cost = float(cost_used)
+                        return True
+                return False
+
+            ok_any = _try_actions()
+            if not ok_any:
+                objective_kind = "COMM_ADMIT_UNKNOWN"
+                expected_text, action_inputs, hint_action_id = _build_expected_and_action_inputs_v96(
+                    objective_kind=str(objective_kind),
+                    parse=dict(parse),
+                    vars_map=dict(vars_map),
+                    last_answer=last_answer,
+                    beliefs_by_key=dict(_active_beliefs_by_key()),
+                    ctx=dict(ctx2),
+                    user_text=str(user_text),
+                )
+                # minimal fallback attempt: admit_unknown
+                ranked2 = [("concept_v90_admit_unknown_v0", SupportClaimV89(goal_id="COMM_ADMIT_UNKNOWN", prior_success=1.0, prior_strength=1, prior_cost=1.0, note=""))]
+                plan_ranked_candidates = [{"act_id": "concept_v90_admit_unknown_v0", "expected_success": 1.0, "expected_cost": 1.0}]
+                plan_attempted_actions = []
+                ok_exec, out_text, _meta, cost_used = _execute_action("concept_v90_admit_unknown_v0", goal_kind="COMM_ADMIT_UNKNOWN", inputs=dict(action_inputs))
+                eval_id = _stable_hash_obj({"conversation_id": str(conversation_id), "turn_id": str(ut.get("turn_id") or ""), "step": int(step), "kind": "fallback"})
+                plan_attempted_actions.append({"act_id": "concept_v90_admit_unknown_v0", "eval_id": str(eval_id), "ok": bool(ok_exec)})
+                assistant_text = str(out_text) if ok_exec else "Não sei."
+                chosen_action_id = "concept_v90_admit_unknown_v0"
+                chosen_objective_id = _objective_act_id("COMM_ADMIT_UNKNOWN")
+                chosen_eval_id = str(eval_id)
+                chosen_ok = bool(ok_exec)
+                chosen_cost = float(cost_used)
+                plan_objective_kind = "COMM_ADMIT_UNKNOWN"
+                plan_objective_id = chosen_objective_id
+
+        # Create assistant turn.
+        at = TurnV96(
+            conversation_id=str(conversation_id),
+            turn_index=int(turn_index),
+            role="assistant",
+            text=str(assistant_text),
+            created_step=int(step),
+            offset_us=0,
+            objective_id=str(chosen_objective_id),
+            objective_kind=str(plan_objective_kind or objective_kind),
+            action_concept_id=str(chosen_action_id),
+            eval_id=str(chosen_eval_id),
+        ).to_dict()
+        turn_index += 1
+        step += 1
+        turns.append(dict(at))
+        prev_turns_hash = append_chained_jsonl_v96(
+            turns_path,
+            {"time": deterministic_iso(step=int(at["created_step"])), "step": int(at["created_step"]), "event": "TURN", "payload": dict(at)},
+            prev_hash=prev_turns_hash,
+        )
+        transcript.append({"role": "assistant", "text": str(at.get("text") or ""), "turn_id": str(at.get("turn_id") or "")})
+        prev_transcript_hash = append_chained_jsonl_v96(
+            transcript_path,
+            {"time": deterministic_iso(step=int(at["created_step"])), "step": int(at["created_step"]), "event": "UTTERANCE", "payload": dict(transcript[-1])},
+            prev_hash=prev_transcript_hash,
+        )
+
+        # Plan record (1 per user turn).
+        notes = "max expected_success, tie-break min expected_cost, tie-break act_id"
+        plan_obj = ActionPlanV96(
+            conversation_id=str(conversation_id),
+            user_turn_id=str(ut.get("turn_id") or ""),
+            user_turn_index=int(ut.get("turn_index") or 0),
+            intent_id=str(parse.get("intent_id") or ""),
+            parse_sig=str(parse.get("parse_sig") or ""),
+            objective_kind=str(plan_objective_kind or objective_kind),
+            objective_id=str(plan_objective_id or chosen_objective_id),
+            ranked_candidates=list(plan_ranked_candidates),
+            attempted_actions=list(plan_attempted_actions),
+            chosen_action_id=str(chosen_action_id),
+            chosen_eval_id=str(chosen_eval_id),
+            chosen_ok=bool(chosen_ok),
+            notes=str(notes),
+            created_step=int(step),
+            memory_read_ids=list(memory_read_ids),
+            memory_write_event_ids=list(memory_write_event_ids),
+            belief_read_keys=list(belief_read_keys),
+            belief_read_ids=list(belief_read_ids),
+            belief_write_event_ids=list(belief_write_event_ids),
+        ).to_dict()
+        prev_plans_hash = append_chained_jsonl_v96(plans_path, dict(plan_obj), prev_hash=prev_plans_hash)
+        action_plans.append(dict(plan_obj))
+
+        trials.append(
+            {
+                "objective_kind": str(plan_objective_kind or objective_kind),
+                "user_turn_id": str(ut.get("turn_id") or ""),
+                "assistant_turn_id": str(at.get("turn_id") or ""),
+                "ok": bool(chosen_ok),
+                "cost_used": float(chosen_cost),
+            }
+        )
+
+        teach_rejected = str(parse.get("intent_id") or "") == "INTENT_TEACH" and not bool(parse.get("teach_ok", False))
+        if str(plan_objective_kind or objective_kind) not in {"COMM_ASK_CLARIFY", "COMM_CONFIRM"} and not bool(teach_rejected):
+            end_idx = int(turn_index) - 1
+            start_idx = max(0, end_idx - (6 - 1))
+            tail_turn_ids = [str(turns[i]["turn_id"]) for i in range(start_idx, end_idx + 1)]
+            lra = sorted(learned_rules_active.keys())
+            mem_active = sorted([mid for mid, okv in memory_active_ids.items() if bool(okv)], key=str)
+            beliefs_active_keys = sorted([str(k) for k in belief_active_by_key.keys() if str(k)], key=str)
+            st = ConversationStateV96(
+                conversation_id=str(conversation_id),
+                state_index=int(state_index),
+                prev_state_id=str(states[-1]["state_id"] if states else ""),
+                active_goals=[],
+                bindings={
+                    "vars": {str(k): vars_map.get(k) for k in sorted(vars_map.keys(), key=str)},
+                    "last_answer": last_answer,
+                    "learned_rules_active": list(lra),
+                    "learned_rule_count": int(len(lra)),
+                    "memory_active": list(mem_active),
+                    "memory_active_count": int(len(mem_active)),
+                    "belief_active_keys": list(beliefs_active_keys),
+                    "belief_active_count": int(len(beliefs_active_keys)),
+                },
+                tail_turn_ids=list(tail_turn_ids),
+                last_user_turn_id=str(ut.get("turn_id") or ""),
+                last_assistant_turn_id=str(at.get("turn_id") or ""),
+                created_step=int(step),
+                last_step=int(step),
+            ).to_dict()
+            state_index += 1
+            step += 1
+            states.append(dict(st))
+            prev_states_hash = append_chained_jsonl_v96(
+                states_path,
+                {"time": deterministic_iso(step=int(st["created_step"])), "step": int(st["created_step"]), "event": "STATE", "payload": dict(st)},
+                prev_hash=prev_states_hash,
+            )
+
+        if bool(compound_stop_after) or str(parse.get("intent_id") or "") == INTENT_END_V92:
+            break
+
+    chains = {
+        "turns_chain_ok": bool(verify_chained_jsonl_v96(turns_path)),
+        "parses_chain_ok": bool(verify_chained_jsonl_v96(parses_path)),
+        "learned_chain_ok": bool(verify_chained_jsonl_v96(learned_path)) if os.path.exists(learned_path) else True,
+        "plans_chain_ok": bool(verify_chained_jsonl_v96(plans_path)),
+        "memory_chain_ok": bool(verify_chained_jsonl_v96(memory_path)),
+        "belief_chain_ok": bool(verify_chained_jsonl_v96(belief_path)),
+        "states_chain_ok": bool(verify_chained_jsonl_v96(states_path)) if os.path.exists(states_path) else True,
+        "trials_chain_ok": bool(verify_chained_jsonl_v96(trials_path)),
+        "evals_chain_ok": bool(verify_chained_jsonl_v96(evals_path)),
+        "transcript_chain_ok": bool(verify_chained_jsonl_v96(transcript_path)),
+    }
+    ok_chain, chain_reason, chain_details = verify_conversation_chain_v96(
+        turns=list(turns),
+        states=list(states),
+        parse_events=list(parse_events),
+        trials=list(trials),
+        learned_rule_events=list(learned_rule_events),
+        action_plans=list(action_plans),
+        memory_events=list(memory_events),
+        belief_events=list(belief_events),
+        tail_k=6,
+    )
+
+    transcript_hash = compute_transcript_hash_v96(turns)
+    state_chain_hash = compute_state_chain_hash_v96(states)
+    parse_chain_hash = compute_parse_chain_hash_v96(parse_events)
+    learned_chain_hash = compute_learned_chain_hash_v96(learned_rule_events)
+    plan_chain_hash = compute_plan_chain_hash_v96(action_plans)
+    memory_chain_hash = compute_memory_chain_hash_v96(memory_events)
+    belief_chain_hash = compute_belief_chain_hash_v96(belief_events)
+
+    verify_obj = {
+        "ok": bool(all(chains.values())) and bool(ok_chain),
+        "chains": dict(chains),
+        "chain_invariants": {"ok": bool(ok_chain), "reason": str(chain_reason), "details": dict(chain_details)},
+        "store_hash": str(store_hash),
+        "transcript_hash": str(transcript_hash),
+        "state_chain_hash": str(state_chain_hash),
+        "parse_chain_hash": str(parse_chain_hash),
+        "learned_chain_hash": str(learned_chain_hash),
+        "plan_chain_hash": str(plan_chain_hash),
+        "memory_chain_hash": str(memory_chain_hash),
+        "belief_chain_hash": str(belief_chain_hash),
+    }
+    tmpv = verify_path + ".tmp"
+    with open(tmpv, "w", encoding="utf-8") as f:
+        f.write(json.dumps(verify_obj, ensure_ascii=False, indent=2, sort_keys=True))
+        f.write("\n")
+    os.replace(tmpv, verify_path)
+
+    manifest_core = {
+        "schema_version": 5,
+        "conversation_id": str(conversation_id),
+        "seed": int(seed),
+        "store_hash": str(store_hash),
+        "grammar_hash": str(grammar_snapshot.get("grammar_hash") or ""),
+        "transcript_hash": str(transcript_hash),
+        "state_chain_hash": str(state_chain_hash),
+        "parse_chain_hash": str(parse_chain_hash),
+        "learned_chain_hash": str(learned_chain_hash),
+        "plan_chain_hash": str(plan_chain_hash),
+        "memory_chain_hash": str(memory_chain_hash),
+        "belief_chain_hash": str(belief_chain_hash),
+        "verify_ok": bool(verify_obj.get("ok", False)),
+        "sha256": {
+            "store_jsonl": str(sha256_file(store_path)),
+            "intent_grammar_snapshot_json": str(sha256_file(grammar_snapshot_path)),
+            "conversation_turns_jsonl": str(sha256_file(turns_path)),
+            "intent_parses_jsonl": str(sha256_file(parses_path)),
+            "learned_intent_rules_jsonl": str(sha256_file(learned_path)) if os.path.exists(learned_path) else "",
+            "action_plans_jsonl": str(sha256_file(plans_path)),
+            "memory_events_jsonl": str(sha256_file(memory_path)),
+            "belief_events_jsonl": str(sha256_file(belief_path)),
+            "conversation_states_jsonl": str(sha256_file(states_path)) if os.path.exists(states_path) else "",
+            "dialogue_trials_jsonl": str(sha256_file(trials_path)),
+            "objective_evals_jsonl": str(sha256_file(evals_path)),
+            "transcript_jsonl": str(sha256_file(transcript_path)),
+            "verify_chain_v96_json": str(sha256_file(verify_path)),
+        },
+    }
+    tmpm = manifest_path + ".tmp"
+    with open(tmpm, "w", encoding="utf-8") as f:
+        f.write(json.dumps(manifest_core, ensure_ascii=False, indent=2, sort_keys=True))
+        f.write("\n")
+    os.replace(tmpm, manifest_path)
+    ledger_hash = sha256_file(manifest_path)
+
+    user_turns_total = (len(turns) + 1) // 2 if turns else 0
+    parses_ok = sum(
+        1
+        for p in parse_events
+        if isinstance(p, dict) and isinstance(p.get("payload"), dict) and bool(p["payload"].get("parse_ok", False))
+    )
+    clarifications = sum(1 for tr in trials if isinstance(tr, dict) and str(tr.get("objective_kind") or "") == "COMM_ASK_CLARIFY")
+    unknowns = sum(
+        1
+        for p in parse_events
+        if isinstance(p, dict) and isinstance(p.get("payload"), dict) and str(p["payload"].get("intent_id") or "") == INTENT_UNKNOWN_V92
+    )
+
+    beliefs_add_total = sum(
+        1
+        for p in parse_events
+        if isinstance(p, dict) and isinstance(p.get("payload"), dict) and str(p["payload"].get("intent_id") or "") == INTENT_BELIEF_ADD_V96
+    )
+    beliefs_revise_total = sum(
+        1
+        for p in parse_events
+        if isinstance(p, dict) and isinstance(p.get("payload"), dict) and str(p["payload"].get("intent_id") or "") == INTENT_BELIEF_REVISE_V96
+    )
+    beliefs_list_total = sum(
+        1
+        for p in parse_events
+        if isinstance(p, dict) and isinstance(p.get("payload"), dict) and str(p["payload"].get("intent_id") or "") == INTENT_BELIEF_LIST_V96
+    )
+    beliefs_forget_total = sum(
+        1
+        for p in parse_events
+        if isinstance(p, dict) and isinstance(p.get("payload"), dict) and str(p["payload"].get("intent_id") or "") == INTENT_BELIEF_FORGET_V96
+    )
+
+    core = {
+        "schema_version": 5,
+        "seed": int(seed),
+        "store_hash": str(store_hash),
+        "transcript_hash": str(transcript_hash),
+        "state_chain_hash": str(state_chain_hash),
+        "parse_chain_hash": str(parse_chain_hash),
+        "learned_chain_hash": str(learned_chain_hash),
+        "plan_chain_hash": str(plan_chain_hash),
+        "memory_chain_hash": str(memory_chain_hash),
+        "belief_chain_hash": str(belief_chain_hash),
+        "ledger_hash": str(ledger_hash),
+        "turns_total": int(len(turns)),
+        "user_turns_total": int(user_turns_total),
+        "states_total": int(len(states)),
+        "plans_total": int(len(action_plans)),
+        "memory_events_total": int(len(memory_events)),
+        "belief_events_total": int(len(belief_events)),
+        "parses_total": int(len(parse_events)),
+        "parses_ok": int(parses_ok),
+        "clarifications": int(clarifications),
+        "unknowns": int(unknowns),
+        "belief_add_total": int(beliefs_add_total),
+        "belief_revise_total": int(beliefs_revise_total),
+        "belief_list_total": int(beliefs_list_total),
+        "belief_forget_total": int(beliefs_forget_total),
+        "verify_ok": bool(verify_obj.get("ok", False)),
+    }
+    summary_sha256 = sha256_hex(canonical_json_dumps(core).encode("utf-8"))
+    summary = dict(core, summary_sha256=str(summary_sha256))
+    tmps = summary_path + ".tmp"
+    with open(tmps, "w", encoding="utf-8") as f:
+        f.write(json.dumps(summary, ensure_ascii=False, indent=2, sort_keys=True))
+        f.write("\n")
+    os.replace(tmps, summary_path)
+
+    return {
+        "schema_version": 5,
+        "out_dir": str(out_dir),
+        "conversation_id": str(conversation_id),
+        "store_hash": str(store_hash),
+        "transcript_hash": str(transcript_hash),
+        "state_chain_hash": str(state_chain_hash),
+        "parse_chain_hash": str(parse_chain_hash),
+        "learned_chain_hash": str(learned_chain_hash),
+        "plan_chain_hash": str(plan_chain_hash),
+        "memory_chain_hash": str(memory_chain_hash),
+        "belief_chain_hash": str(belief_chain_hash),
+        "ledger_hash": str(ledger_hash),
+        "summary_sha256": str(summary_sha256),
+        "paths": {
+            "store_jsonl": str(store_path),
+            "grammar_snapshot_json": str(grammar_snapshot_path),
+            "turns_jsonl": str(turns_path),
+            "parses_jsonl": str(parses_path),
+            "learned_rules_jsonl": str(learned_path),
+            "plans_jsonl": str(plans_path),
+            "memory_events_jsonl": str(memory_path),
+            "belief_events_jsonl": str(belief_path),
+            "states_jsonl": str(states_path),
+            "trials_jsonl": str(trials_path),
+            "evals_jsonl": str(evals_path),
+            "transcript_jsonl": str(transcript_path),
+            "verify_json": str(verify_path),
+            "manifest_json": str(manifest_path),
+            "summary_json": str(summary_path),
+        },
+    }
--- /dev/null	2026-01-13 15:24:17
+++ atos_core/conversation_v96.py	2026-01-13 15:14:19
@@ -0,0 +1,1406 @@
+from __future__ import annotations
+
+import copy
+import json
+import os
+from dataclasses import dataclass
+from typing import Any, Dict, Iterator, List, Optional, Sequence, Tuple
+
+from .act import canonical_json_dumps, deterministic_iso, sha256_hex
+from .conversation_v94 import render_explain_text_v94
+from .intent_grammar_v93 import expected_learned_rule_id_v93, verify_learned_rule_sig_v93
+from .intent_grammar_v92 import INTENT_GET_V92
+from .intent_grammar_v96 import (
+    INTENT_BELIEF_ADD_V96,
+    INTENT_BELIEF_FORGET_V96,
+    INTENT_BELIEF_LIST_V96,
+    INTENT_BELIEF_REVISE_V96,
+    INTENT_FORGET_V96,
+    INTENT_NOTE_V96,
+    INTENT_RECALL_V96,
+)
+
+
+def _stable_hash_obj(obj: Any) -> str:
+    return sha256_hex(canonical_json_dumps(obj).encode("utf-8"))
+
+
+def _safe_deepcopy(obj: Any) -> Any:
+    try:
+        return copy.deepcopy(obj)
+    except Exception:
+        if isinstance(obj, dict):
+            return dict(obj)
+        if isinstance(obj, list):
+            return list(obj)
+        return obj
+
+
+def normalize_text_v96(text: str) -> str:
+    return str(text or "").replace("\r\n", "\n").strip()
+
+
+def text_sig_v96(text: str) -> str:
+    return sha256_hex(normalize_text_v96(text).encode("utf-8"))
+
+
+def render_explain_text_v96(plan: Dict[str, Any]) -> str:
+    """
+    Extend v94 explain with explicit memory/belief read/write refs.
+    Always renders all fields (even empty) deterministically.
+    """
+    base = render_explain_text_v94(plan)
+    mem_read = _canon_str_list(plan.get("memory_read_ids"))
+    mem_write = _canon_str_list(plan.get("memory_write_event_ids"))
+    bel_read_keys = _canon_str_list(plan.get("belief_read_keys"))
+    bel_read_ids = _canon_str_list(plan.get("belief_read_ids"))
+    bel_write = _canon_str_list(plan.get("belief_write_event_ids"))
+
+    lines = [
+        base,
+        f"MEMORY_READ_IDS={json.dumps(mem_read, ensure_ascii=False)}",
+        f"MEMORY_WRITE_EVENT_IDS={json.dumps(mem_write, ensure_ascii=False)}",
+        f"BELIEF_READ_KEYS={json.dumps(bel_read_keys, ensure_ascii=False)}",
+        f"BELIEF_READ_IDS={json.dumps(bel_read_ids, ensure_ascii=False)}",
+        f"BELIEF_WRITE_EVENT_IDS={json.dumps(bel_write, ensure_ascii=False)}",
+    ]
+    return "\n".join(lines)
+
+
+def _canon_str_list(items: Any) -> List[str]:
+    out: List[str] = []
+    if not isinstance(items, list):
+        return out
+    for x in items:
+        if not isinstance(x, str) or not x:
+            continue
+        out.append(str(x))
+    out2 = sorted(set(out))
+    return list(out2)
+
+
+def _canon_bindings(obj: Any) -> Dict[str, Any]:
+    if not isinstance(obj, dict):
+        return {}
+    out: Dict[str, Any] = {}
+    for k in sorted(obj.keys(), key=str):
+        kk = str(k)
+        v = obj.get(k)
+        if isinstance(v, dict):
+            out[kk] = _canon_bindings(v)
+        elif isinstance(v, list):
+            out[kk] = [_safe_deepcopy(x) for x in v]
+        else:
+            out[kk] = _safe_deepcopy(v)
+    return dict(out)
+
+
+def turn_id_v96(*, conversation_id: str, turn_index: int, role: str, text_sig: str) -> str:
+    body = {
+        "conversation_id": str(conversation_id),
+        "turn_index": int(turn_index),
+        "role": str(role),
+        "text_sig": str(text_sig),
+    }
+    return f"turn_v96_{_stable_hash_obj(body)}"
+
+
+@dataclass(frozen=True)
+class TurnV96:
+    conversation_id: str
+    turn_index: int
+    role: str  # "user" | "assistant"
+    text: str
+    created_step: int
+    offset_us: int = 0
+    objective_id: str = ""
+    objective_kind: str = ""
+    action_concept_id: str = ""
+    eval_id: str = ""
+    parse_sig: str = ""
+    intent_id: str = ""
+    matched_rule_id: str = ""
+
+    def to_dict(self) -> Dict[str, Any]:
+        text_norm = normalize_text_v96(self.text)
+        sig = text_sig_v96(text_norm)
+        tid = turn_id_v96(conversation_id=str(self.conversation_id), turn_index=int(self.turn_index), role=str(self.role), text_sig=str(sig))
+        return {
+            "kind": "turn_v96",
+            "turn_id": str(tid),
+            "conversation_id": str(self.conversation_id),
+            "turn_index": int(self.turn_index),
+            "role": str(self.role),
+            "text": str(text_norm),
+            "text_sig": str(sig),
+            "created_step": int(self.created_step),
+            "created_at": deterministic_iso(step=int(self.created_step), offset_us=int(self.offset_us)),
+            "refs": {
+                "objective_id": str(self.objective_id or ""),
+                "objective_kind": str(self.objective_kind or ""),
+                "action_concept_id": str(self.action_concept_id or ""),
+                "eval_id": str(self.eval_id or ""),
+                "parse_sig": str(self.parse_sig or ""),
+                "intent_id": str(self.intent_id or ""),
+                "matched_rule_id": str(self.matched_rule_id or ""),
+            },
+        }
+
+
+def state_sig_v96(state_sem_sig: Dict[str, Any]) -> str:
+    return sha256_hex(canonical_json_dumps(state_sem_sig).encode("utf-8"))
+
+
+def state_id_v96(state_sig: str) -> str:
+    return f"conversation_state_v96_{str(state_sig)}"
+
+
+@dataclass(frozen=True)
+class ConversationStateV96:
+    conversation_id: str
+    state_index: int
+    prev_state_id: str
+    active_goals: List[str]
+    bindings: Dict[str, Any]
+    tail_turn_ids: List[str]
+    last_user_turn_id: str
+    last_assistant_turn_id: str
+    created_step: int
+    last_step: int
+
+    def to_dict(self) -> Dict[str, Any]:
+        sem = {
+            "schema_version": 96,
+            "kind": "conversation_state_v96",
+            "conversation_id": str(self.conversation_id),
+            "state_index": int(self.state_index),
+            "prev_state_id": str(self.prev_state_id or ""),
+            "active_goals": _canon_str_list(self.active_goals),
+            "bindings": _canon_bindings(self.bindings),
+            "tail_turn_ids": [str(x) for x in self.tail_turn_ids if isinstance(x, str) and x],
+            "last_user_turn_id": str(self.last_user_turn_id or ""),
+            "last_assistant_turn_id": str(self.last_assistant_turn_id or ""),
+            "created_step": int(self.created_step),
+            "last_step": int(self.last_step),
+            "invariants": {"schema_version": 96, "tail_k_fixed": True},
+        }
+        sig = state_sig_v96(sem)
+        sid = state_id_v96(sig)
+        return dict(sem, state_sig=str(sig), state_id=str(sid))
+
+
+def action_plan_sig_v96(plan_sem_sig: Dict[str, Any]) -> str:
+    return sha256_hex(canonical_json_dumps(plan_sem_sig).encode("utf-8"))
+
+
+def action_plan_id_v96(plan_sig: str) -> str:
+    return f"action_plan_v96_{str(plan_sig)}"
+
+
+def _round6(x: Any) -> float:
+    try:
+        return float(round(float(x), 6))
+    except Exception:
+        return 0.0
+
+
+def _canon_ranked_candidates_v96(items: Any) -> List[Dict[str, Any]]:
+    out: List[Dict[str, Any]] = []
+    if not isinstance(items, list):
+        return out
+    for it in items:
+        if not isinstance(it, dict):
+            continue
+        act_id = str(it.get("act_id") or "")
+        if not act_id:
+            continue
+        out.append({"act_id": act_id, "expected_success": _round6(it.get("expected_success")), "expected_cost": _round6(it.get("expected_cost"))})
+    return list(out)
+
+
+def _canon_attempted_actions_v96(items: Any) -> List[Dict[str, Any]]:
+    out: List[Dict[str, Any]] = []
+    if not isinstance(items, list):
+        return out
+    for it in items:
+        if not isinstance(it, dict):
+            continue
+        act_id = str(it.get("act_id") or "")
+        eval_id = str(it.get("eval_id") or "")
+        if not act_id or not eval_id:
+            continue
+        out.append({"act_id": act_id, "eval_id": eval_id, "ok": bool(it.get("ok", False))})
+    return list(out)
+
+
+@dataclass(frozen=True)
+class ActionPlanV96:
+    conversation_id: str
+    user_turn_id: str
+    user_turn_index: int
+    intent_id: str
+    parse_sig: str
+    objective_kind: str
+    objective_id: str
+    ranked_candidates: List[Dict[str, Any]]
+    attempted_actions: List[Dict[str, Any]]
+    chosen_action_id: str
+    chosen_eval_id: str
+    chosen_ok: bool
+    notes: str
+    created_step: int
+    memory_read_ids: List[str]
+    memory_write_event_ids: List[str]
+    belief_read_keys: List[str]
+    belief_read_ids: List[str]
+    belief_write_event_ids: List[str]
+
+    def to_dict(self) -> Dict[str, Any]:
+        sem = {
+            "schema_version": 96,
+            "kind": "action_plan_v96",
+            "conversation_id": str(self.conversation_id),
+            "user_turn_id": str(self.user_turn_id),
+            "user_turn_index": int(self.user_turn_index),
+            "intent_id": str(self.intent_id),
+            "parse_sig": str(self.parse_sig),
+            "objective_kind": str(self.objective_kind),
+            "objective_id": str(self.objective_id),
+            "ranked_candidates": _canon_ranked_candidates_v96(self.ranked_candidates),
+            "attempted_actions": _canon_attempted_actions_v96(self.attempted_actions),
+            "chosen_action_id": str(self.chosen_action_id),
+            "chosen_eval_id": str(self.chosen_eval_id),
+            "chosen_ok": bool(self.chosen_ok),
+            "notes": str(self.notes),
+            "created_step": int(self.created_step),
+            "memory_read_ids": _canon_str_list(self.memory_read_ids),
+            "memory_write_event_ids": _canon_str_list(self.memory_write_event_ids),
+            "belief_read_keys": _canon_str_list(self.belief_read_keys),
+            "belief_read_ids": _canon_str_list(self.belief_read_ids),
+            "belief_write_event_ids": _canon_str_list(self.belief_write_event_ids),
+        }
+        sig = action_plan_sig_v96(sem)
+        pid = action_plan_id_v96(sig)
+        return dict(sem, plan_sig=str(sig), plan_id=str(pid))
+
+
+def memory_item_sig_v96(item_sem_sig: Dict[str, Any]) -> str:
+    return sha256_hex(canonical_json_dumps(item_sem_sig).encode("utf-8"))
+
+
+def memory_item_id_v96(memory_sig: str) -> str:
+    return f"memory_v96_{str(memory_sig)}"
+
+
+@dataclass(frozen=True)
+class MemoryItemV96:
+    conversation_id: str
+    memory_text: str
+    source_turn_id: str
+    created_step: int
+
+    def to_dict(self) -> Dict[str, Any]:
+        sem = {
+            "schema_version": 96,
+            "kind": "memory_item_v96",
+            "conversation_id": str(self.conversation_id),
+            "memory_text": normalize_text_v96(self.memory_text),
+            "source_turn_id": str(self.source_turn_id),
+            "created_step": int(self.created_step),
+            "created_at": deterministic_iso(step=int(self.created_step)),
+        }
+        sig = memory_item_sig_v96(sem)
+        mid = memory_item_id_v96(sig)
+        return dict(sem, memory_sig=str(sig), memory_id=str(mid))
+
+
+def memory_event_sig_v96(event_sem_sig: Dict[str, Any]) -> str:
+    return sha256_hex(canonical_json_dumps(event_sem_sig).encode("utf-8"))
+
+
+def memory_event_id_v96(event_sig: str) -> str:
+    return f"memory_event_v96_{str(event_sig)}"
+
+
+@dataclass(frozen=True)
+class MemoryEventV96:
+    conversation_id: str
+    event_kind: str  # "ADD" | "RETRACT"
+    created_step: int
+    source_turn_id: str
+    memory_item: Optional[Dict[str, Any]] = None
+    target_memory_id: str = ""
+    retract_reason: str = ""
+
+    def to_dict(self) -> Dict[str, Any]:
+        sem = {
+            "schema_version": 96,
+            "kind": "memory_event_v96",
+            "conversation_id": str(self.conversation_id),
+            "event_kind": str(self.event_kind),
+            "created_step": int(self.created_step),
+            "created_at": deterministic_iso(step=int(self.created_step)),
+            "source_turn_id": str(self.source_turn_id or ""),
+            "memory_item": dict(self.memory_item) if isinstance(self.memory_item, dict) else None,
+            "target_memory_id": str(self.target_memory_id or ""),
+            "retract_reason": str(self.retract_reason or ""),
+        }
+        sig = memory_event_sig_v96(sem)
+        eid = memory_event_id_v96(sig)
+        return dict(sem, event_sig=str(sig), event_id=str(eid))
+
+
+def belief_item_sig_v96(item_sem_sig: Dict[str, Any]) -> str:
+    return sha256_hex(canonical_json_dumps(item_sem_sig).encode("utf-8"))
+
+
+def belief_item_id_v96(belief_sig: str) -> str:
+    return f"belief_v96_{str(belief_sig)}"
+
+
+@dataclass(frozen=True)
+class BeliefItemV96:
+    conversation_id: str
+    belief_key: str
+    belief_value: str
+    source_turn_id: str
+    created_step: int
+
+    def to_dict(self) -> Dict[str, Any]:
+        sem = {
+            "schema_version": 96,
+            "kind": "belief_item_v96",
+            "conversation_id": str(self.conversation_id),
+            "belief_key": str(self.belief_key).strip(),
+            "belief_value": str(self.belief_value).strip(),
+            "source_turn_id": str(self.source_turn_id),
+            "created_step": int(self.created_step),
+            "created_at": deterministic_iso(step=int(self.created_step)),
+        }
+        sig = belief_item_sig_v96(sem)
+        bid = belief_item_id_v96(sig)
+        return dict(sem, belief_sig=str(sig), belief_id=str(bid))
+
+
+def belief_event_sig_v96(event_sem_sig: Dict[str, Any]) -> str:
+    return sha256_hex(canonical_json_dumps(event_sem_sig).encode("utf-8"))
+
+
+def belief_event_id_v96(event_sig: str) -> str:
+    return f"belief_event_v96_{str(event_sig)}"
+
+
+@dataclass(frozen=True)
+class BeliefEventV96:
+    conversation_id: str
+    event_kind: str  # "ADD" | "RETRACT"
+    created_step: int
+    source_turn_id: str
+    belief_item: Optional[Dict[str, Any]] = None
+    target_belief_id: str = ""
+    retract_reason: str = ""
+
+    def to_dict(self) -> Dict[str, Any]:
+        sem = {
+            "schema_version": 96,
+            "kind": "belief_event_v96",
+            "conversation_id": str(self.conversation_id),
+            "event_kind": str(self.event_kind),
+            "created_step": int(self.created_step),
+            "created_at": deterministic_iso(step=int(self.created_step)),
+            "source_turn_id": str(self.source_turn_id or ""),
+            "belief_item": dict(self.belief_item) if isinstance(self.belief_item, dict) else None,
+            "target_belief_id": str(self.target_belief_id or ""),
+            "retract_reason": str(self.retract_reason or ""),
+        }
+        sig = belief_event_sig_v96(sem)
+        eid = belief_event_id_v96(sig)
+        return dict(sem, event_sig=str(sig), event_id=str(eid))
+
+
+def render_recall_text_v96(active_items: Sequence[Dict[str, Any]]) -> str:
+    items: List[Tuple[int, str, str]] = []
+    for it in active_items:
+        if not isinstance(it, dict):
+            continue
+        mid = str(it.get("memory_id") or "")
+        mtext = str(it.get("memory_text") or "")
+        try:
+            cstep = int(it.get("created_step", -1))
+        except Exception:
+            cstep = -1
+        if not mid:
+            continue
+        items.append((int(cstep), mid, mtext))
+    items.sort(key=lambda t: (int(t[0]), str(t[1])))
+    if not items:
+        return "MEMORY: (empty)"
+    lines: List[str] = ["MEMORY:"]
+    for i, (_cs, mid, txt) in enumerate(items):
+        lines.append(f"{i+1}) {mid} text={json.dumps(str(txt), ensure_ascii=False)}")
+    return "\n".join(lines)
+
+
+def render_note_ack_text_v96(memory_id: str) -> str:
+    return f"MEMORY ADDED: {str(memory_id)}"
+
+
+def render_forget_ack_text_v96(target_memory_id: str) -> str:
+    return f"MEMORY RETRACTED: {str(target_memory_id)}"
+
+
+def render_beliefs_text_v96(active_by_key: Dict[str, Dict[str, Any]]) -> str:
+    keys = sorted([str(k) for k in active_by_key.keys() if isinstance(k, str) and k], key=str)
+    if not keys:
+        return "BELIEFS: (empty)"
+    lines: List[str] = ["BELIEFS:"]
+    for i, k in enumerate(keys):
+        it = active_by_key.get(k) if isinstance(active_by_key.get(k), dict) else {}
+        bid = str(it.get("belief_id") or "")
+        bval = str(it.get("belief_value") or "")
+        lines.append(f"{i+1}) key={k} id={bid} value={json.dumps(bval, ensure_ascii=False)}")
+    return "\n".join(lines)
+
+
+def render_belief_added_ack_text_v96(*, belief_id: str, key: str) -> str:
+    return f"BELIEF ADDED: {str(belief_id)} key={str(key)}"
+
+
+def render_belief_revised_ack_text_v96(*, key: str, old_id: str, new_id: str) -> str:
+    return f"BELIEF REVISED: {str(key)} old={str(old_id)} new={str(new_id)}"
+
+
+def render_belief_retracted_ack_text_v96(*, belief_id: str, key: str) -> str:
+    return f"BELIEF RETRACTED: {str(belief_id)} key={str(key)}"
+
+
+def _read_jsonl(path: str) -> Iterator[Dict[str, Any]]:
+    if not os.path.exists(path):
+        return iter(())
+    with open(path, "r", encoding="utf-8") as f:
+        for line in f:
+            line = line.strip()
+            if not line:
+                continue
+            yield json.loads(line)
+
+
+def append_chained_jsonl_v96(path: str, entry: Dict[str, Any], *, prev_hash: Optional[str]) -> str:
+    os.makedirs(os.path.dirname(path) or ".", exist_ok=True)
+    body = dict(entry)
+    body["prev_hash"] = prev_hash
+    entry_hash = sha256_hex(canonical_json_dumps(body).encode("utf-8"))
+    body["entry_hash"] = entry_hash
+    with open(path, "a", encoding="utf-8") as f:
+        f.write(canonical_json_dumps(body))
+        f.write("\n")
+    return entry_hash
+
+
+def verify_chained_jsonl_v96(path: str) -> bool:
+    prev: Optional[str] = None
+    for row in _read_jsonl(path):
+        row = dict(row)
+        entry_hash = row.pop("entry_hash", None)
+        if row.get("prev_hash") != prev:
+            return False
+        expected = sha256_hex(canonical_json_dumps(row).encode("utf-8"))
+        if expected != entry_hash:
+            return False
+        prev = str(entry_hash)
+    return True
+
+
+def compute_transcript_hash_v96(turns: Sequence[Dict[str, Any]]) -> str:
+    items: List[Dict[str, Any]] = []
+    for t in turns:
+        if not isinstance(t, dict):
+            continue
+        items.append({"turn_index": int(t.get("turn_index", 0)), "role": str(t.get("role") or ""), "text": str(t.get("text") or "")})
+    items.sort(key=lambda r: int(r.get("turn_index", 0)))
+    view = [{"role": str(r.get("role") or ""), "text": str(r.get("text") or "")} for r in items]
+    return sha256_hex(canonical_json_dumps(view).encode("utf-8"))
+
+
+def compute_state_chain_hash_v96(states: Sequence[Dict[str, Any]]) -> str:
+    sigs: List[str] = []
+    for s in states:
+        if not isinstance(s, dict):
+            continue
+        sigs.append(str(s.get("state_sig") or ""))
+    return sha256_hex(canonical_json_dumps(sigs).encode("utf-8"))
+
+
+def compute_parse_chain_hash_v96(parse_events: Sequence[Dict[str, Any]]) -> str:
+    sigs: List[str] = []
+    for e in parse_events:
+        if not isinstance(e, dict):
+            continue
+        payload = e.get("payload")
+        if isinstance(payload, dict):
+            sigs.append(str(payload.get("parse_sig") or ""))
+    return sha256_hex(canonical_json_dumps(sigs).encode("utf-8"))
+
+
+def compute_learned_chain_hash_v96(learned_events: Sequence[Dict[str, Any]]) -> str:
+    ids: List[str] = []
+    for ev in learned_events:
+        if not isinstance(ev, dict):
+            continue
+        lr = ev.get("learned_rule")
+        if isinstance(lr, dict):
+            ids.append(str(lr.get("rule_id") or ""))
+    return sha256_hex(canonical_json_dumps(ids).encode("utf-8"))
+
+
+def compute_plan_chain_hash_v96(plans: Sequence[Dict[str, Any]]) -> str:
+    ids: List[str] = []
+    for p in plans:
+        if not isinstance(p, dict):
+            continue
+        ids.append(str(p.get("plan_id") or ""))
+    return sha256_hex(canonical_json_dumps(ids).encode("utf-8"))
+
+
+def compute_memory_chain_hash_v96(memory_events: Sequence[Dict[str, Any]]) -> str:
+    ids: List[str] = []
+    for ev in memory_events:
+        if not isinstance(ev, dict):
+            continue
+        ids.append(str(ev.get("event_id") or ""))
+    return sha256_hex(canonical_json_dumps(ids).encode("utf-8"))
+
+
+def compute_belief_chain_hash_v96(belief_events: Sequence[Dict[str, Any]]) -> str:
+    ids: List[str] = []
+    for ev in belief_events:
+        if not isinstance(ev, dict):
+            continue
+        ids.append(str(ev.get("event_id") or ""))
+    return sha256_hex(canonical_json_dumps(ids).encode("utf-8"))
+
+
+def _verify_parse_payload_sig_v96(payload: Dict[str, Any]) -> Tuple[bool, str, Dict[str, Any]]:
+    payload2 = dict(payload)
+    got_sig = str(payload2.pop("parse_sig", "") or "")
+    if not got_sig:
+        return False, "missing_parse_sig", {}
+    want_sig = sha256_hex(canonical_json_dumps(payload2).encode("utf-8"))
+    if want_sig != got_sig:
+        return False, "parse_sig_mismatch", {"want": str(want_sig), "got": str(got_sig)}
+
+    if bool(payload.get("compound", False)):
+        segs = payload.get("segments")
+        if not isinstance(segs, list):
+            return False, "compound_segments_not_list", {}
+        for seg in segs:
+            if not isinstance(seg, dict):
+                return False, "segment_not_dict", {}
+            sidx = int(seg.get("segment_index", -1))
+            seg_parse = seg.get("segment_parse")
+            if not isinstance(seg_parse, dict):
+                return False, "segment_missing_parse", {"segment_index": int(sidx)}
+            sp2 = dict(seg_parse)
+            got2 = str(sp2.pop("parse_sig", "") or "")
+            if not got2:
+                return False, "segment_missing_parse_sig", {"segment_index": int(sidx)}
+            want2 = sha256_hex(canonical_json_dumps(sp2).encode("utf-8"))
+            if want2 != got2:
+                return False, "segment_parse_sig_mismatch", {"segment_index": int(sidx)}
+
+        want_ok = True
+        for seg in segs:
+            if not isinstance(seg, dict):
+                want_ok = False
+                break
+            sp = seg.get("segment_parse")
+            if not isinstance(sp, dict) or not bool(sp.get("parse_ok", False)):
+                want_ok = False
+                break
+            missing = sp.get("missing_slots")
+            if isinstance(missing, list) and missing:
+                want_ok = False
+                break
+        if bool(payload.get("parse_ok", False)) != bool(want_ok):
+            return False, "compound_parse_ok_inconsistent", {"want": bool(want_ok), "got": bool(payload.get("parse_ok", False))}
+
+    return True, "ok", {}
+
+
+def _verify_plan_sig_v96(plan: Dict[str, Any]) -> Tuple[bool, str, Dict[str, Any]]:
+    d = dict(plan)
+    got_sig = str(d.pop("plan_sig", "") or "")
+    got_id = str(d.pop("plan_id", "") or "")
+    if not got_sig:
+        return False, "missing_plan_sig", {}
+    want_sig = sha256_hex(canonical_json_dumps(d).encode("utf-8"))
+    if want_sig != got_sig:
+        return False, "plan_sig_mismatch", {"want": str(want_sig), "got": str(got_sig)}
+    want_id = action_plan_id_v96(got_sig)
+    if want_id != got_id:
+        return False, "plan_id_mismatch", {"want": str(want_id), "got": str(got_id)}
+    return True, "ok", {}
+
+
+def _verify_memory_item_sig_v96(item: Dict[str, Any]) -> Tuple[bool, str, Dict[str, Any]]:
+    d = dict(item)
+    got_sig = str(d.pop("memory_sig", "") or "")
+    got_id = str(d.pop("memory_id", "") or "")
+    if not got_sig:
+        return False, "missing_memory_sig", {}
+    want_sig = sha256_hex(canonical_json_dumps(d).encode("utf-8"))
+    if want_sig != got_sig:
+        return False, "memory_sig_mismatch", {"want": str(want_sig), "got": str(got_sig)}
+    want_id = memory_item_id_v96(got_sig)
+    if want_id != got_id:
+        return False, "memory_id_mismatch", {"want": str(want_id), "got": str(got_id)}
+    return True, "ok", {}
+
+
+def _verify_memory_event_sig_v96(ev: Dict[str, Any]) -> Tuple[bool, str, Dict[str, Any]]:
+    d = dict(ev)
+    got_sig = str(d.pop("event_sig", "") or "")
+    got_id = str(d.pop("event_id", "") or "")
+    if not got_sig:
+        return False, "missing_event_sig", {}
+    want_sig = sha256_hex(canonical_json_dumps(d).encode("utf-8"))
+    if want_sig != got_sig:
+        return False, "event_sig_mismatch", {"want": str(want_sig), "got": str(got_sig)}
+    want_id = memory_event_id_v96(got_sig)
+    if want_id != got_id:
+        return False, "event_id_mismatch", {"want": str(want_id), "got": str(got_id)}
+    return True, "ok", {}
+
+
+def _verify_belief_item_sig_v96(item: Dict[str, Any]) -> Tuple[bool, str, Dict[str, Any]]:
+    d = dict(item)
+    got_sig = str(d.pop("belief_sig", "") or "")
+    got_id = str(d.pop("belief_id", "") or "")
+    if not got_sig:
+        return False, "missing_belief_sig", {}
+    want_sig = sha256_hex(canonical_json_dumps(d).encode("utf-8"))
+    if want_sig != got_sig:
+        return False, "belief_sig_mismatch", {"want": str(want_sig), "got": str(got_sig)}
+    want_id = belief_item_id_v96(got_sig)
+    if want_id != got_id:
+        return False, "belief_id_mismatch", {"want": str(want_id), "got": str(got_id)}
+    return True, "ok", {}
+
+
+def _verify_belief_event_sig_v96(ev: Dict[str, Any]) -> Tuple[bool, str, Dict[str, Any]]:
+    d = dict(ev)
+    got_sig = str(d.pop("event_sig", "") or "")
+    got_id = str(d.pop("event_id", "") or "")
+    if not got_sig:
+        return False, "missing_belief_event_sig", {}
+    want_sig = sha256_hex(canonical_json_dumps(d).encode("utf-8"))
+    if want_sig != got_sig:
+        return False, "belief_event_sig_mismatch", {"want": str(want_sig), "got": str(got_sig)}
+    want_id = belief_event_id_v96(got_sig)
+    if want_id != got_id:
+        return False, "belief_event_id_mismatch", {"want": str(want_id), "got": str(got_id)}
+    return True, "ok", {}
+
+
+def _memory_active_after_step_v96(*, memory_events: Sequence[Dict[str, Any]], step: int) -> Tuple[Dict[str, Dict[str, Any]], Dict[str, Dict[str, Any]]]:
+    all_items: Dict[str, Dict[str, Any]] = {}
+    active: Dict[str, Dict[str, Any]] = {}
+    for ev in memory_events:
+        if not isinstance(ev, dict):
+            continue
+        try:
+            cstep = int(ev.get("created_step", -1))
+        except Exception:
+            cstep = -1
+        if cstep < 0 or cstep > int(step):
+            continue
+        if str(ev.get("event_kind") or "") == "ADD":
+            mi = ev.get("memory_item")
+            if isinstance(mi, dict):
+                mid = str(mi.get("memory_id") or "")
+                if mid:
+                    all_items[mid] = dict(mi)
+                    active[mid] = dict(mi)
+        elif str(ev.get("event_kind") or "") == "RETRACT":
+            tid = str(ev.get("target_memory_id") or "")
+            if tid and tid in active:
+                active.pop(tid, None)
+    return dict(active), dict(all_items)
+
+
+def _belief_active_after_step_v96(
+    *, belief_events: Sequence[Dict[str, Any]], step: int
+) -> Tuple[Dict[str, Dict[str, Any]], Dict[str, Dict[str, Any]]]:
+    """
+    Replay belief events up to and including created_step<=step.
+    Returns (active_by_key, all_items_by_id).
+    """
+    all_items: Dict[str, Dict[str, Any]] = {}
+    active_by_key: Dict[str, Dict[str, Any]] = {}
+    for ev in belief_events:
+        if not isinstance(ev, dict):
+            continue
+        try:
+            cstep = int(ev.get("created_step", -1))
+        except Exception:
+            cstep = -1
+        if cstep < 0 or cstep > int(step):
+            continue
+        ek = str(ev.get("event_kind") or "")
+        if ek == "ADD":
+            bi = ev.get("belief_item")
+            if isinstance(bi, dict):
+                bid = str(bi.get("belief_id") or "")
+                bkey = str(bi.get("belief_key") or "").strip()
+                if bid:
+                    all_items[bid] = dict(bi)
+                if bkey:
+                    active_by_key[bkey] = dict(bi)
+        elif ek == "RETRACT":
+            tid = str(ev.get("target_belief_id") or "")
+            if not tid:
+                continue
+            bi2 = all_items.get(tid)
+            if isinstance(bi2, dict):
+                bkey2 = str(bi2.get("belief_key") or "").strip()
+                if bkey2 and bkey2 in active_by_key and str(active_by_key[bkey2].get("belief_id") or "") == tid:
+                    active_by_key.pop(bkey2, None)
+    return dict(active_by_key), dict(all_items)
+
+
+def verify_conversation_chain_v96(
+    *,
+    turns: Sequence[Dict[str, Any]],
+    states: Sequence[Dict[str, Any]],
+    parse_events: Sequence[Dict[str, Any]],
+    trials: Sequence[Dict[str, Any]],
+    learned_rule_events: Sequence[Dict[str, Any]],
+    action_plans: Sequence[Dict[str, Any]],
+    memory_events: Sequence[Dict[str, Any]],
+    belief_events: Sequence[Dict[str, Any]],
+    tail_k: int,
+) -> Tuple[bool, str, Dict[str, Any]]:
+    by_index: Dict[int, Dict[str, Any]] = {}
+    by_id: Dict[str, Dict[str, Any]] = {}
+    max_idx = -1
+    for t in turns:
+        if not isinstance(t, dict):
+            return False, "turn_not_dict", {}
+        tid = str(t.get("turn_id") or "")
+        if not tid:
+            return False, "missing_turn_id", {}
+        try:
+            idx = int(t.get("turn_index", -1))
+        except Exception:
+            idx = -1
+        if idx < 0:
+            return False, "bad_turn_index", {"turn_id": tid}
+        if idx in by_index:
+            return False, "duplicate_turn_index", {"turn_index": int(idx)}
+        by_index[int(idx)] = dict(t)
+        by_id[tid] = dict(t)
+        max_idx = max(max_idx, int(idx))
+    for i in range(0, max_idx + 1):
+        if i not in by_index:
+            return False, "missing_turn_index", {"missing_turn_index": int(i)}
+    for i in range(0, max_idx + 1):
+        role = str(by_index[i].get("role") or "")
+        want_role = "user" if (i % 2 == 0) else "assistant"
+        if role != want_role:
+            return False, "turn_role_mismatch", {"turn_index": int(i), "want": want_role, "got": role}
+
+    parses_by_turn_id: Dict[str, Dict[str, Any]] = {}
+    parse_order: List[Tuple[int, str]] = []
+    for pe in parse_events:
+        if not isinstance(pe, dict):
+            return False, "parse_event_not_dict", {}
+        tid = str(pe.get("turn_id") or "")
+        if not tid:
+            return False, "parse_event_missing_turn_id", {}
+        try:
+            tix = int(pe.get("turn_index", -1))
+        except Exception:
+            tix = -1
+        if tix < 0:
+            return False, "parse_event_bad_turn_index", {"turn_id": tid}
+        payload = pe.get("payload")
+        if not isinstance(payload, dict):
+            return False, "parse_event_missing_payload", {"turn_id": tid}
+        if tid in parses_by_turn_id:
+            return False, "duplicate_parse_event_turn_id", {"turn_id": tid}
+        parses_by_turn_id[tid] = dict(payload)
+        parse_order.append((int(tix), tid))
+
+        ok_sig, rsig, dsig = _verify_parse_payload_sig_v96(payload=dict(payload))
+        if not ok_sig:
+            d = dict(dsig)
+            d["turn_id"] = str(tid)
+            return False, str(rsig), d
+
+    parse_order.sort(key=lambda x: (int(x[0]), str(x[1])))
+    for i in range(0, max_idx + 1, 2):
+        t = by_index[i]
+        tid = str(t.get("turn_id") or "")
+        if tid not in parses_by_turn_id:
+            return False, "missing_parse_for_user_turn", {"turn_index": int(i), "turn_id": tid}
+        pref = t.get("refs") if isinstance(t.get("refs"), dict) else {}
+        want_parse_sig = str(pref.get("parse_sig") or "")
+        want_intent_id = str(pref.get("intent_id") or "")
+        want_rule_id = str(pref.get("matched_rule_id") or "")
+        payload = parses_by_turn_id[tid]
+        if want_parse_sig != str(payload.get("parse_sig") or ""):
+            return False, "turn_parse_sig_mismatch", {"turn_index": int(i)}
+        if want_intent_id != str(payload.get("intent_id") or ""):
+            return False, "turn_intent_id_mismatch", {"turn_index": int(i)}
+        if want_rule_id != str(payload.get("matched_rule_id") or ""):
+            return False, "turn_matched_rule_id_mismatch", {"turn_index": int(i)}
+
+    parse_turn_indices = [int(ix) for ix, _tid in parse_order]
+    if parse_turn_indices != sorted(parse_turn_indices):
+        return False, "parse_events_not_sorted", {}
+    for ix in parse_turn_indices:
+        if ix % 2 != 0:
+            return False, "parse_event_on_non_user_turn", {"turn_index": int(ix)}
+
+    learned_by_teacher: Dict[str, Dict[str, Any]] = {}
+    for ev in learned_rule_events:
+        if not isinstance(ev, dict):
+            return False, "learned_event_not_dict", {}
+        teacher_turn_id = str(ev.get("teacher_turn_id") or "")
+        if not teacher_turn_id:
+            return False, "learned_missing_teacher_turn_id", {}
+        if teacher_turn_id in learned_by_teacher:
+            return False, "duplicate_learned_teacher_turn_id", {"teacher_turn_id": teacher_turn_id}
+        lr = ev.get("learned_rule")
+        if not isinstance(lr, dict):
+            return False, "learned_missing_rule", {"teacher_turn_id": teacher_turn_id}
+        want_rule_id = expected_learned_rule_id_v93(
+            intent_id=str(lr.get("intent_id") or ""),
+            pattern=lr.get("pattern") if isinstance(lr.get("pattern"), list) else [],
+            required_slots=lr.get("required_slots") if isinstance(lr.get("required_slots"), list) else [],
+        )
+        got_rule_id = str(lr.get("rule_id") or "")
+        if want_rule_id != got_rule_id:
+            return False, "learned_rule_id_mismatch", {"teacher_turn_id": teacher_turn_id, "want": want_rule_id, "got": got_rule_id}
+        ok_rs, rreason, rdetails = verify_learned_rule_sig_v93(dict(lr))
+        if not ok_rs:
+            d = dict(rdetails)
+            d["teacher_turn_id"] = teacher_turn_id
+            return False, str(rreason), d
+        learned_by_teacher[teacher_turn_id] = dict(ev)
+
+    # Replay memory and belief ledgers with strong invariants.
+    memory_by_event_id: Dict[str, Dict[str, Any]] = {}
+    all_mem_items_seen: Dict[str, Dict[str, Any]] = {}
+    prev_mem_step = -1
+    for ev in memory_events:
+        if not isinstance(ev, dict):
+            return False, "memory_event_not_dict", {}
+        ok_ev, ereason, edetails = _verify_memory_event_sig_v96(dict(ev))
+        if not ok_ev:
+            return False, str(ereason), dict(edetails)
+        eid = str(ev.get("event_id") or "")
+        if eid in memory_by_event_id:
+            return False, "duplicate_memory_event_id", {"event_id": eid}
+        memory_by_event_id[eid] = dict(ev)
+        try:
+            cstep = int(ev.get("created_step", -1))
+        except Exception:
+            cstep = -1
+        if cstep < 0:
+            return False, "memory_event_bad_created_step", {"event_id": eid}
+        if cstep < prev_mem_step:
+            return False, "memory_events_not_monotonic", {"event_id": eid}
+        prev_mem_step = int(cstep)
+        if str(ev.get("event_kind") or "") == "ADD":
+            mi = ev.get("memory_item")
+            if not isinstance(mi, dict):
+                return False, "memory_add_missing_item", {"event_id": eid}
+            ok_mi, mreason, mdetails = _verify_memory_item_sig_v96(dict(mi))
+            if not ok_mi:
+                return False, str(mreason), dict(mdetails)
+            mid = str(mi.get("memory_id") or "")
+            if mid:
+                all_mem_items_seen[mid] = dict(mi)
+        elif str(ev.get("event_kind") or "") == "RETRACT":
+            tid = str(ev.get("target_memory_id") or "")
+            if not tid:
+                return False, "memory_retract_missing_target", {"event_id": eid}
+            if tid not in all_mem_items_seen:
+                return False, "memory_retract_unknown_target", {"event_id": eid, "target_memory_id": tid}
+
+    belief_by_event_id: Dict[str, Dict[str, Any]] = {}
+    all_beliefs_seen: Dict[str, Dict[str, Any]] = {}
+    active_belief_by_key: Dict[str, str] = {}
+    prev_belief_step = -1
+    for ev in belief_events:
+        if not isinstance(ev, dict):
+            return False, "belief_event_not_dict", {}
+        ok_ev, ereason, edetails = _verify_belief_event_sig_v96(dict(ev))
+        if not ok_ev:
+            return False, str(ereason), dict(edetails)
+        eid = str(ev.get("event_id") or "")
+        if eid in belief_by_event_id:
+            return False, "duplicate_belief_event_id", {"event_id": eid}
+        belief_by_event_id[eid] = dict(ev)
+        try:
+            cstep = int(ev.get("created_step", -1))
+        except Exception:
+            cstep = -1
+        if cstep < 0:
+            return False, "belief_event_bad_created_step", {"event_id": eid}
+        if cstep < prev_belief_step:
+            return False, "belief_events_not_monotonic", {"event_id": eid}
+        prev_belief_step = int(cstep)
+
+        ek = str(ev.get("event_kind") or "")
+        if ek == "ADD":
+            bi = ev.get("belief_item")
+            if not isinstance(bi, dict):
+                return False, "belief_add_missing_item", {"event_id": eid}
+            ok_bi, breason, bdetails = _verify_belief_item_sig_v96(dict(bi))
+            if not ok_bi:
+                return False, str(breason), dict(bdetails)
+            bid = str(bi.get("belief_id") or "")
+            bkey = str(bi.get("belief_key") or "").strip()
+            if not bkey:
+                return False, "belief_add_empty_key", {"event_id": eid, "belief_id": bid}
+            if bkey in active_belief_by_key:
+                return False, "belief_add_key_already_active", {"event_id": eid, "belief_key": bkey}
+            if bid:
+                all_beliefs_seen[bid] = dict(bi)
+            active_belief_by_key[bkey] = bid
+        elif ek == "RETRACT":
+            tid = str(ev.get("target_belief_id") or "")
+            if not tid:
+                return False, "belief_retract_missing_target", {"event_id": eid}
+            if tid not in all_beliefs_seen:
+                return False, "belief_retract_unknown_target", {"event_id": eid, "target_belief_id": tid}
+            bi2 = all_beliefs_seen.get(tid)
+            bkey2 = str(bi2.get("belief_key") or "").strip() if isinstance(bi2, dict) else ""
+            if not bkey2:
+                return False, "belief_retract_unknown_key", {"event_id": eid, "target_belief_id": tid}
+            if bkey2 not in active_belief_by_key or str(active_belief_by_key.get(bkey2) or "") != tid:
+                return False, "belief_retract_target_not_active", {"event_id": eid, "target_belief_id": tid}
+            active_belief_by_key.pop(bkey2, None)
+
+    # States: chain + tail correctness.
+    state_by_user_turn_id: Dict[str, Dict[str, Any]] = {}
+    if states:
+        prev_state_id = ""
+        prev_created_step = -1
+        for i, s in enumerate(states):
+            if not isinstance(s, dict):
+                return False, "state_not_dict", {"index": int(i)}
+            try:
+                got_state_index = int(s.get("state_index", -1))
+            except Exception:
+                got_state_index = -1
+            if got_state_index != int(i):
+                return False, "state_index_not_incrementing", {"index": int(i), "got": s.get("state_index")}
+            if i == 0:
+                if str(s.get("prev_state_id") or "") not in ("", "None"):
+                    return False, "genesis_prev_state_not_empty", {"got": s.get("prev_state_id")}
+            else:
+                if str(s.get("prev_state_id") or "") != str(prev_state_id):
+                    return False, "prev_state_id_mismatch", {"index": int(i)}
+
+            try:
+                created_step = int(s.get("created_step", -1))
+                last_step = int(s.get("last_step", -1))
+            except Exception:
+                return False, "bad_step_fields", {"index": int(i)}
+            if created_step < 0 or last_step < 0:
+                return False, "bad_step_fields", {"index": int(i)}
+            if created_step < prev_created_step:
+                return False, "created_step_not_monotonic", {"index": int(i)}
+            if last_step < created_step:
+                return False, "last_step_before_created_step", {"index": int(i)}
+
+            s2 = dict(s)
+            got_sig = str(s2.pop("state_sig", "") or "")
+            got_state_id = str(s2.pop("state_id", "") or "")
+            if not got_sig:
+                return False, "missing_state_sig", {"index": int(i)}
+            if got_state_id != state_id_v96(got_sig):
+                return False, "state_id_mismatch", {"index": int(i)}
+            want_sig = state_sig_v96(s2)
+            if want_sig != got_sig:
+                return False, "state_sig_mismatch", {"index": int(i)}
+
+            last_user_tid = str(s.get("last_user_turn_id") or "")
+            last_asst_tid = str(s.get("last_assistant_turn_id") or "")
+            if last_user_tid not in by_id or last_asst_tid not in by_id:
+                return False, "missing_last_turn_refs", {"index": int(i)}
+            tu = by_id[last_user_tid]
+            ta = by_id[last_asst_tid]
+            if str(tu.get("role") or "") != "user" or str(ta.get("role") or "") != "assistant":
+                return False, "last_turn_roles_wrong", {"index": int(i)}
+            try:
+                tu_idx = int(tu.get("turn_index", -1))
+                ta_idx = int(ta.get("turn_index", -1))
+            except Exception:
+                return False, "last_turn_index_pair_invalid", {"index": int(i)}
+            if tu_idx < 0 or ta_idx < 0 or (ta_idx != tu_idx + 1) or (tu_idx % 2 != 0):
+                return False, "last_turn_index_pair_invalid", {"index": int(i)}
+
+            tail = s.get("tail_turn_ids")
+            tail = tail if isinstance(tail, list) else []
+            tail2 = [str(x) for x in tail if isinstance(x, str) and x]
+            if len(tail2) > int(tail_k):
+                return False, "tail_too_long", {"index": int(i)}
+            end_idx = int(ta_idx)
+            start_idx = max(0, end_idx - (int(tail_k) - 1))
+            expected_tail: List[str] = []
+            for j in range(start_idx, end_idx + 1):
+                expected_tail.append(str(by_index[int(j)].get("turn_id") or ""))
+            if tail2 != expected_tail:
+                return False, "tail_mismatch", {"index": int(i)}
+
+            state_by_user_turn_id[last_user_tid] = dict(s)
+            prev_state_id = str(got_state_id)
+            prev_created_step = int(created_step)
+
+    # Clarifying objectives must NOT create state.
+    clarifying = {"COMM_ASK_CLARIFY", "COMM_CONFIRM"}
+    state_user_turn_ids = {str(s.get("last_user_turn_id") or "") for s in states if isinstance(s, dict)}
+    for tr in trials:
+        if not isinstance(tr, dict):
+            continue
+        okind = str(tr.get("objective_kind") or "")
+        if okind not in clarifying:
+            continue
+        utid = str(tr.get("user_turn_id") or "")
+        if utid and utid in state_user_turn_ids:
+            return False, "state_updated_on_clarification", {"user_turn_id": utid, "objective_kind": okind}
+
+    # TEACH accept/reject invariants (based on parse payload).
+    learned_by_teacher2: Dict[str, Dict[str, Any]] = {}
+    for ev in learned_rule_events:
+        if isinstance(ev, dict):
+            teacher_turn_id = str(ev.get("teacher_turn_id") or "")
+            if teacher_turn_id:
+                learned_by_teacher2[teacher_turn_id] = dict(ev)
+    for i in range(0, max_idx + 1, 2):
+        ut = by_index[i]
+        utid = str(ut.get("turn_id") or "")
+        payload = parses_by_turn_id.get(utid) if utid else None
+        if not isinstance(payload, dict):
+            continue
+        if str(payload.get("intent_id") or "") != "INTENT_TEACH":
+            continue
+        teach_ok = bool(payload.get("teach_ok", False))
+        if teach_ok:
+            if utid not in learned_by_teacher2:
+                return False, "teach_ok_missing_learned_event", {"turn_id": utid}
+        else:
+            if utid in learned_by_teacher2:
+                return False, "teach_reject_has_learned_event", {"turn_id": utid}
+
+    # Belief + memory bindings must match replay at each state step.
+    active_all_mem_by_step: Dict[int, Tuple[Dict[str, Dict[str, Any]], Dict[str, Dict[str, Any]]]] = {}
+    active_all_belief_by_step: Dict[int, Tuple[Dict[str, Dict[str, Any]], Dict[str, Dict[str, Any]]]] = {}
+    for s in states:
+        if not isinstance(s, dict):
+            continue
+        try:
+            sstep = int(s.get("created_step", -1))
+        except Exception:
+            sstep = -1
+        if sstep < 0:
+            return False, "state_bad_created_step", {}
+
+        if sstep not in active_all_mem_by_step:
+            active_m, all_m = _memory_active_after_step_v96(memory_events=memory_events, step=int(sstep))
+            active_all_mem_by_step[int(sstep)] = (active_m, all_m)
+        active_mem, _all_mem = active_all_mem_by_step[int(sstep)]
+
+        if sstep not in active_all_belief_by_step:
+            active_b, all_b = _belief_active_after_step_v96(belief_events=belief_events, step=int(sstep))
+            active_all_belief_by_step[int(sstep)] = (active_b, all_b)
+        active_belief, _all_belief = active_all_belief_by_step[int(sstep)]
+
+        bindings = s.get("bindings") if isinstance(s.get("bindings"), dict) else {}
+
+        # memory_active + count must exist and match.
+        if "memory_active" not in bindings:
+            return False, "memory_active_missing", {"state_id": str(s.get("state_id") or "")}
+        mem_active = bindings.get("memory_active")
+        if not isinstance(mem_active, list):
+            return False, "memory_active_not_list", {"state_id": str(s.get("state_id") or "")}
+        mem_active_list: List[str] = []
+        for x in mem_active:
+            if not isinstance(x, str) or not x:
+                return False, "memory_active_bad_item", {"state_id": str(s.get("state_id") or ""), "item": x}
+            mem_active_list.append(str(x))
+        mem_active_list2 = sorted(set(mem_active_list))
+        if mem_active_list != mem_active_list2:
+            return False, "memory_active_not_sorted_unique", {"state_id": str(s.get("state_id") or "")}
+        want_mem = sorted(active_mem.keys(), key=str)
+        if mem_active_list2 != want_mem:
+            return False, "memory_active_mismatch", {"state_id": str(s.get("state_id") or ""), "want": want_mem, "got": mem_active_list2}
+        if "memory_active_count" not in bindings:
+            return False, "memory_active_count_missing", {"state_id": str(s.get("state_id") or "")}
+        try:
+            cntm = int(bindings.get("memory_active_count", -1))
+        except Exception:
+            cntm = -1
+        if cntm != int(len(want_mem)):
+            return False, "memory_active_count_mismatch", {"state_id": str(s.get("state_id") or ""), "want": int(len(want_mem)), "got": int(cntm)}
+
+        # belief_active_keys + count must exist and match.
+        if "belief_active_keys" not in bindings:
+            return False, "belief_active_keys_missing", {"state_id": str(s.get("state_id") or "")}
+        bak = bindings.get("belief_active_keys")
+        if not isinstance(bak, list):
+            return False, "belief_active_keys_not_list", {"state_id": str(s.get("state_id") or ""), "got_type": str(type(bak).__name__)}
+        bak_list: List[str] = []
+        for x in bak:
+            if not isinstance(x, str) or not x:
+                return False, "belief_active_keys_bad_item", {"state_id": str(s.get("state_id") or ""), "item": x}
+            bak_list.append(str(x))
+        bak_list2 = sorted(set(bak_list))
+        if bak_list != bak_list2:
+            return False, "belief_active_keys_not_sorted_unique", {"state_id": str(s.get("state_id") or ""), "got": list(bak_list)}
+        want_bak = sorted(active_belief.keys(), key=str)
+        if bak_list2 != want_bak:
+            return False, "belief_active_keys_mismatch", {"state_id": str(s.get("state_id") or ""), "want": want_bak, "got": bak_list2}
+        if "belief_active_count" not in bindings:
+            return False, "belief_active_count_missing", {"state_id": str(s.get("state_id") or "")}
+        try:
+            cntb = int(bindings.get("belief_active_count", -1))
+        except Exception:
+            cntb = -1
+        if cntb != int(len(want_bak)):
+            return False, "belief_active_count_mismatch", {"state_id": str(s.get("state_id") or ""), "want": int(len(want_bak)), "got": int(cntb)}
+
+    # Action plans: validate sigs and cross-check against turns + memory/beliefs.
+    plans_by_user_turn_id: Dict[str, Dict[str, Any]] = {}
+    plan_user_indices: List[int] = []
+    for p in action_plans:
+        if not isinstance(p, dict):
+            return False, "plan_not_dict", {}
+        ok_ps, preason, pdetails = _verify_plan_sig_v96(dict(p))
+        if not ok_ps:
+            return False, str(preason), dict(pdetails)
+        utid = str(p.get("user_turn_id") or "")
+        if not utid:
+            return False, "plan_missing_user_turn_id", {}
+        if utid in plans_by_user_turn_id:
+            return False, "duplicate_plan_user_turn_id", {"user_turn_id": utid}
+        try:
+            uidx = int(p.get("user_turn_index", -1))
+        except Exception:
+            uidx = -1
+        if uidx < 0:
+            return False, "plan_bad_user_turn_index", {"user_turn_id": utid}
+        plans_by_user_turn_id[utid] = dict(p)
+        plan_user_indices.append(int(uidx))
+
+        ranked = p.get("ranked_candidates")
+        ranked_list = ranked if isinstance(ranked, list) else []
+        ranked_ids = [str(x.get("act_id") or "") for x in ranked_list if isinstance(x, dict)]
+        if not ranked_ids:
+            return False, "plan_ranked_candidates_empty", {"user_turn_id": utid}
+        if str(p.get("chosen_action_id") or "") not in set(ranked_ids):
+            return False, "plan_chosen_not_in_ranked", {"user_turn_id": utid}
+
+        attempted = p.get("attempted_actions")
+        attempted_list = attempted if isinstance(attempted, list) else []
+        attempted_ids = [str(x.get("act_id") or "") for x in attempted_list if isinstance(x, dict)]
+        if ranked_ids[: len(attempted_ids)] != attempted_ids:
+            return False, "plan_attempted_not_prefix_of_ranked", {"user_turn_id": utid}
+        chosen_eval_id = str(p.get("chosen_eval_id") or "")
+        chosen_ok = bool(p.get("chosen_ok", False))
+        if not attempted_list:
+            return False, "plan_attempted_actions_empty", {"user_turn_id": utid}
+        ok_indices = [i for i, a in enumerate(attempted_list) if isinstance(a, dict) and bool(a.get("ok", False))]
+        if chosen_ok:
+            if not ok_indices:
+                return False, "plan_chosen_ok_true_but_no_ok_attempt", {"user_turn_id": utid}
+            first_ok = int(ok_indices[0])
+            a = attempted_list[first_ok]
+            if str(a.get("act_id") or "") != str(p.get("chosen_action_id") or ""):
+                return False, "plan_chosen_action_not_first_ok", {"user_turn_id": utid}
+            if str(a.get("eval_id") or "") != chosen_eval_id:
+                return False, "plan_chosen_eval_not_first_ok", {"user_turn_id": utid}
+        else:
+            if ok_indices:
+                return False, "plan_chosen_ok_false_but_has_ok_attempt", {"user_turn_id": utid}
+
+        # Canonical memory/belief lists.
+        mem_read_ids = _canon_str_list(p.get("memory_read_ids"))
+        mem_write_ids = _canon_str_list(p.get("memory_write_event_ids"))
+        if _canon_str_list(p.get("memory_read_ids")) != mem_read_ids or _canon_str_list(p.get("memory_write_event_ids")) != mem_write_ids:
+            return False, "plan_memory_lists_not_canonical", {"user_turn_id": utid}
+        bel_read_keys = _canon_str_list(p.get("belief_read_keys"))
+        bel_read_ids = _canon_str_list(p.get("belief_read_ids"))
+        bel_write_ids = _canon_str_list(p.get("belief_write_event_ids"))
+        if (
+            _canon_str_list(p.get("belief_read_keys")) != bel_read_keys
+            or _canon_str_list(p.get("belief_read_ids")) != bel_read_ids
+            or _canon_str_list(p.get("belief_write_event_ids")) != bel_write_ids
+        ):
+            return False, "plan_belief_lists_not_canonical", {"user_turn_id": utid}
+
+        # Belief event references must exist.
+        for wid in bel_write_ids:
+            if wid not in belief_by_event_id:
+                return False, "plan_unknown_belief_write_event_id", {"user_turn_id": utid, "event_id": wid}
+
+        intent_id = str(p.get("intent_id") or "")
+        if intent_id == INTENT_NOTE_V96:
+            parse_payload = parses_by_turn_id.get(utid, {})
+            note_ok = bool(parse_payload.get("parse_ok", False))
+            if note_ok and not mem_write_ids:
+                return False, "note_missing_write_event_ids", {"user_turn_id": utid}
+        elif intent_id == INTENT_RECALL_V96:
+            if mem_write_ids:
+                return False, "recall_has_write_event_ids", {"user_turn_id": utid}
+        elif intent_id == INTENT_FORGET_V96:
+            # memory forget can be ok even if no active memory (then no write ids).
+            pass
+
+        if intent_id == INTENT_BELIEF_ADD_V96:
+            parse_payload = parses_by_turn_id.get(utid, {})
+            if bool(parse_payload.get("parse_ok", False)) and not bel_write_ids:
+                return False, "belief_add_missing_write_event_ids", {"user_turn_id": utid}
+            if bel_write_ids:
+                ev0 = belief_by_event_id.get(bel_write_ids[0], {})
+                if str(ev0.get("event_kind") or "") != "ADD":
+                    return False, "belief_add_write_event_not_add", {"user_turn_id": utid, "event_id": bel_write_ids[0]}
+        elif intent_id == INTENT_BELIEF_REVISE_V96:
+            parse_payload = parses_by_turn_id.get(utid, {})
+            if bool(parse_payload.get("parse_ok", False)):
+                if len(bel_write_ids) != 2:
+                    return False, "belief_revise_write_events_not_two", {"user_turn_id": utid, "got": int(len(bel_write_ids))}
+                evr = belief_by_event_id.get(bel_write_ids[0], {})
+                eva = belief_by_event_id.get(bel_write_ids[1], {})
+                if str(evr.get("event_kind") or "") != "RETRACT":
+                    return False, "belief_revise_first_event_not_retract", {"user_turn_id": utid}
+                if str(eva.get("event_kind") or "") != "ADD":
+                    return False, "belief_revise_second_event_not_add", {"user_turn_id": utid}
+                if not bel_read_keys or not bel_read_ids:
+                    return False, "belief_revise_missing_reads", {"user_turn_id": utid}
+        elif intent_id == INTENT_BELIEF_FORGET_V96:
+            parse_payload = parses_by_turn_id.get(utid, {})
+            if bool(parse_payload.get("parse_ok", False)) and not bel_write_ids:
+                return False, "belief_forget_missing_write_event_ids", {"user_turn_id": utid}
+            if bel_write_ids:
+                ev0 = belief_by_event_id.get(bel_write_ids[0], {})
+                if str(ev0.get("event_kind") or "") != "RETRACT":
+                    return False, "belief_forget_write_event_not_retract", {"user_turn_id": utid}
+            if bool(parse_payload.get("parse_ok", False)):
+                if not bel_read_keys or not bel_read_ids:
+                    return False, "belief_forget_missing_reads", {"user_turn_id": utid}
+        elif intent_id == INTENT_BELIEF_LIST_V96:
+            if bel_write_ids:
+                return False, "belief_list_has_write_event_ids", {"user_turn_id": utid}
+            # Reads must reflect active beliefs at assistant turn step.
+            try:
+                uidx = int(p.get("user_turn_index", -1))
+            except Exception:
+                uidx = -1
+            at = by_index.get(int(uidx) + 1, {}) if uidx >= 0 else {}
+            try:
+                astep = int(at.get("created_step", -1))
+            except Exception:
+                astep = -1
+            if astep < 0:
+                return False, "belief_list_missing_assistant_step", {"user_turn_id": utid}
+            active_b, _all_b = _belief_active_after_step_v96(belief_events=belief_events, step=int(astep))
+            want_keys = sorted(active_b.keys(), key=str)
+            want_ids = [str(active_b[k].get("belief_id") or "") for k in want_keys if isinstance(active_b.get(k), dict)]
+            if bel_read_keys != want_keys:
+                return False, "belief_list_read_keys_mismatch", {"user_turn_id": utid, "want": want_keys, "got": bel_read_keys}
+            if bel_read_ids != want_ids:
+                return False, "belief_list_read_ids_mismatch", {"user_turn_id": utid, "want": want_ids, "got": bel_read_ids}
+
+        # GET reads belief when vars missing.
+        if intent_id == INTENT_GET_V92:
+            parse_payload = parses_by_turn_id.get(utid, {})
+            slots = parse_payload.get("slots") if isinstance(parse_payload.get("slots"), dict) else {}
+            k = str(slots.get("k") or "")
+            if not k:
+                continue
+            st = state_by_user_turn_id.get(utid)
+            if not isinstance(st, dict):
+                # likely a clarifying outcome; no belief reads expected.
+                if bel_read_keys or bel_read_ids:
+                    return False, "get_has_belief_reads_without_state", {"user_turn_id": utid}
+                continue
+            bnd = st.get("bindings") if isinstance(st.get("bindings"), dict) else {}
+            vars_map = bnd.get("vars") if isinstance(bnd.get("vars"), dict) else {}
+            if k in vars_map:
+                if bel_read_keys or bel_read_ids:
+                    return False, "get_has_belief_reads_but_var_exists", {"user_turn_id": utid, "key": k}
+            else:
+                at = by_index.get(int(uidx) + 1, {}) if uidx >= 0 else {}
+                try:
+                    astep = int(at.get("created_step", -1))
+                except Exception:
+                    astep = -1
+                if astep < 0:
+                    return False, "get_missing_assistant_step", {"user_turn_id": utid}
+                active_b, _all_b = _belief_active_after_step_v96(belief_events=belief_events, step=int(astep))
+                if k in active_b:
+                    it = active_b.get(k) if isinstance(active_b.get(k), dict) else {}
+                    want_id = str(it.get("belief_id") or "")
+                    want_val = str(it.get("belief_value") or "")
+                    if bel_read_keys != [k] or bel_read_ids != [want_id]:
+                        return False, "get_belief_reads_mismatch", {"user_turn_id": utid, "want_keys": [k], "want_ids": [want_id], "got_keys": bel_read_keys, "got_ids": bel_read_ids}
+                    want_text = f"{k}={want_val}"
+                    got_text = str(at.get("text") or "")
+                    if got_text != want_text:
+                        return False, "get_belief_text_mismatch", {"user_turn_id": utid, "want": want_text, "got": got_text}
+                else:
+                    if bel_read_keys or bel_read_ids:
+                        return False, "get_has_belief_reads_but_no_active_belief", {"user_turn_id": utid, "key": k}
+
+    if plan_user_indices != sorted(plan_user_indices):
+        return False, "plans_not_sorted_by_user_turn_index", {}
+
+    for i in range(0, max_idx + 1, 2):
+        utid = str(by_index[i].get("turn_id") or "")
+        if utid not in plans_by_user_turn_id:
+            return False, "missing_plan_for_user_turn", {"turn_index": int(i), "turn_id": utid}
+        plan = plans_by_user_turn_id[utid]
+        if int(plan.get("user_turn_index", -1)) != int(i):
+            return False, "plan_user_turn_index_mismatch", {"turn_index": int(i), "turn_id": utid}
+        pp = parses_by_turn_id.get(utid, {})
+        if str(plan.get("intent_id") or "") != str(pp.get("intent_id") or ""):
+            return False, "plan_intent_id_mismatch", {"turn_index": int(i)}
+        if str(plan.get("parse_sig") or "") != str(pp.get("parse_sig") or ""):
+            return False, "plan_parse_sig_mismatch", {"turn_index": int(i)}
+        at = by_index[i + 1]
+        aref = at.get("refs") if isinstance(at.get("refs"), dict) else {}
+        if str(plan.get("objective_kind") or "") != str(aref.get("objective_kind") or ""):
+            return False, "plan_objective_kind_mismatch", {"turn_index": int(i)}
+        if str(plan.get("objective_id") or "") != str(aref.get("objective_id") or ""):
+            return False, "plan_objective_id_mismatch", {"turn_index": int(i)}
+        if str(plan.get("chosen_action_id") or "") != str(aref.get("action_concept_id") or ""):
+            return False, "plan_action_id_mismatch", {"turn_index": int(i)}
+        if str(plan.get("chosen_eval_id") or "") != str(aref.get("eval_id") or ""):
+            return False, "plan_eval_id_mismatch", {"turn_index": int(i)}
+
+    # BELIEFS output must match renderer based on active beliefs at that time.
+    for i in range(0, max_idx + 1, 2):
+        ut = by_index[i]
+        utid = str(ut.get("turn_id") or "")
+        payload = parses_by_turn_id.get(utid, {})
+        if str(payload.get("intent_id") or "") != INTENT_BELIEF_LIST_V96:
+            continue
+        at = by_index[i + 1]
+        try:
+            astep = int(at.get("created_step", -1))
+        except Exception:
+            astep = -1
+        if astep < 0:
+            return False, "beliefs_missing_assistant_step", {"turn_id": utid}
+        active_b, _all_b = _belief_active_after_step_v96(belief_events=belief_events, step=int(astep))
+        want = render_beliefs_text_v96(active_b)
+        got = str(at.get("text") or "")
+        if want != got:
+            return False, "beliefs_text_mismatch", {"turn_id": utid, "want": want, "got": got}
+
+    return True, "ok", {"turns_total": int(len(turns)), "states_total": int(len(states)), "plans_total": int(len(action_plans)), "memory_events_total": int(len(memory_events)), "belief_events_total": int(len(belief_events))}
--- /dev/null	2026-01-13 15:24:17
+++ atos_core/intent_grammar_v96.py	2026-01-13 14:58:20
@@ -0,0 +1,284 @@
+from __future__ import annotations
+
+import unicodedata
+from typing import Any, Dict
+
+
+INTENT_NOTE_V96 = "INTENT_NOTE"
+INTENT_RECALL_V96 = "INTENT_RECALL"
+INTENT_FORGET_V96 = "INTENT_FORGET"  # memory: "forget last"
+
+INTENT_BELIEF_ADD_V96 = "INTENT_BELIEF_ADD"
+INTENT_BELIEF_REVISE_V96 = "INTENT_BELIEF_REVISE"
+INTENT_BELIEF_LIST_V96 = "INTENT_BELIEF_LIST"
+INTENT_BELIEF_FORGET_V96 = "INTENT_BELIEF_FORGET"
+
+
+def _strip_accents(text: str) -> str:
+    s = unicodedata.normalize("NFD", str(text))
+    return "".join(ch for ch in s if unicodedata.category(ch) != "Mn")
+
+
+def _norm_prefix(text: str) -> str:
+    return _strip_accents(str(text or "")).lower()
+
+
+def is_note_command_v96(user_text: str) -> bool:
+    s = str(user_text or "").lstrip()
+    s2 = _norm_prefix(s)
+    return bool(s2.startswith("note") or s2.startswith("nota"))
+
+
+def parse_note_command_v96(user_text: str) -> Dict[str, Any]:
+    """
+    Syntax (fail-closed):
+      note: <text>
+      nota: <text>
+    """
+    raw = str(user_text or "")
+    s = raw.lstrip()
+    s2 = _norm_prefix(s)
+    prefix = ""
+    if s2.startswith("note"):
+        prefix = "note"
+        rest_raw = s[len("note") :]
+    elif s2.startswith("nota"):
+        prefix = "nota"
+        rest_raw = s[len("nota") :]
+    else:
+        return {"recognized": False}
+
+    if rest_raw and (not rest_raw[0].isspace()) and (rest_raw[0] != ":"):
+        return {"recognized": False}
+
+    rest = str(rest_raw).lstrip()
+    if not rest.startswith(":"):
+        return {"recognized": True, "ok": False, "reason": "missing_colon", "prefix": str(prefix), "extra_raw": str(rest_raw)}
+
+    text = str(rest[1:]).strip()
+    if not text:
+        return {"recognized": True, "ok": False, "reason": "empty_text", "prefix": str(prefix)}
+
+    return {"recognized": True, "ok": True, "reason": "ok", "prefix": str(prefix), "memory_text_raw": str(text)}
+
+
+def is_recall_command_v96(user_text: str) -> bool:
+    s = str(user_text or "").lstrip()
+    s2 = _norm_prefix(s)
+    return bool(s2.startswith("recall") or s2.startswith("memoria"))
+
+
+def parse_recall_command_v96(user_text: str) -> Dict[str, Any]:
+    """
+    Syntax (fail-closed):
+      recall
+      memoria / memória
+      (optional) recall: / memoria: with no payload
+    """
+    raw = str(user_text or "")
+    s = raw.lstrip()
+    s2 = _norm_prefix(s)
+    prefix = ""
+    if s2.startswith("recall"):
+        prefix = "recall"
+        rest_raw = s[len("recall") :]
+    elif s2.startswith("memoria"):
+        prefix = "memoria"
+        rest_raw = s[len("memoria") :]
+    else:
+        return {"recognized": False}
+
+    if rest_raw and (not rest_raw[0].isspace()) and (rest_raw[0] != ":"):
+        return {"recognized": False}
+
+    rest = str(rest_raw).strip()
+    if rest.startswith(":"):
+        rest = rest[1:].strip()
+    if rest:
+        return {"recognized": True, "ok": False, "reason": "extra_tokens", "prefix": str(prefix), "extra_raw": str(rest_raw)}
+    return {"recognized": True, "ok": True, "reason": "ok", "prefix": str(prefix)}
+
+
+def is_belief_add_command_v96(user_text: str) -> bool:
+    s = str(user_text or "").lstrip()
+    s2 = _norm_prefix(s)
+    if s2.startswith("belief"):
+        rest = s[len("belief") :]
+        return bool(rest and rest.lstrip().startswith(":"))
+    if s2.startswith("crenca"):
+        rest = s[len("crenca") :]
+        return bool(rest and rest.lstrip().startswith(":"))
+    return False
+
+
+def _parse_key_value_after_colon(prefix: str, rest_raw: str) -> Dict[str, Any]:
+    rest = str(rest_raw).lstrip()
+    if not rest.startswith(":"):
+        return {"recognized": True, "ok": False, "reason": "missing_colon", "prefix": str(prefix), "extra_raw": str(rest_raw)}
+    body = str(rest[1:]).strip()
+    if "=" not in body:
+        return {"recognized": True, "ok": False, "reason": "missing_equals", "prefix": str(prefix), "body_raw": str(body)}
+    k_raw, v_raw = body.split("=", 1)
+    key = str(k_raw).strip()
+    val = str(v_raw).strip()
+    if not key:
+        return {"recognized": True, "ok": False, "reason": "empty_key", "prefix": str(prefix), "body_raw": str(body)}
+    if not val:
+        return {"recognized": True, "ok": False, "reason": "empty_value", "prefix": str(prefix), "body_raw": str(body), "belief_key": str(key)}
+    return {"recognized": True, "ok": True, "reason": "ok", "prefix": str(prefix), "belief_key": str(key), "belief_value": str(val)}
+
+
+def parse_belief_add_command_v96(user_text: str) -> Dict[str, Any]:
+    """
+    Syntax (fail-closed):
+      belief: <key> = <value>
+      crenca: <key> = <value>   (crença accepted via accent fold)
+    """
+    raw = str(user_text or "")
+    s = raw.lstrip()
+    s2 = _norm_prefix(s)
+    prefix = ""
+    if s2.startswith("belief"):
+        prefix = "belief"
+        rest_raw = s[len("belief") :]
+    elif s2.startswith("crenca"):
+        prefix = "crenca"
+        rest_raw = s[len("crenca") :]
+    else:
+        return {"recognized": False}
+
+    # Avoid prefix as part of a larger token (e.g. "beliefs").
+    if rest_raw and (not rest_raw[0].isspace()) and (rest_raw[0] != ":"):
+        return {"recognized": False}
+
+    return _parse_key_value_after_colon(str(prefix), str(rest_raw))
+
+
+def is_belief_revise_command_v96(user_text: str) -> bool:
+    s = str(user_text or "").lstrip()
+    s2 = _norm_prefix(s)
+    if s2.startswith("revise"):
+        rest = s[len("revise") :]
+        return bool(rest and rest.lstrip().startswith(":"))
+    if s2.startswith("revisar"):
+        rest = s[len("revisar") :]
+        return bool(rest and rest.lstrip().startswith(":"))
+    return False
+
+
+def parse_belief_revise_command_v96(user_text: str) -> Dict[str, Any]:
+    """
+    Syntax (fail-closed):
+      revise: <key> = <value>
+      revisar: <key> = <value>
+    """
+    raw = str(user_text or "")
+    s = raw.lstrip()
+    s2 = _norm_prefix(s)
+    prefix = ""
+    if s2.startswith("revise"):
+        prefix = "revise"
+        rest_raw = s[len("revise") :]
+    elif s2.startswith("revisar"):
+        prefix = "revisar"
+        rest_raw = s[len("revisar") :]
+    else:
+        return {"recognized": False}
+
+    if rest_raw and (not rest_raw[0].isspace()) and (rest_raw[0] != ":"):
+        return {"recognized": False}
+
+    return _parse_key_value_after_colon(str(prefix), str(rest_raw))
+
+
+def is_beliefs_list_command_v96(user_text: str) -> bool:
+    s = str(user_text or "").lstrip()
+    s2 = _norm_prefix(s)
+    return bool(s2.startswith("beliefs") or s2.startswith("crencas"))
+
+
+def parse_beliefs_list_command_v96(user_text: str) -> Dict[str, Any]:
+    """
+    Syntax (fail-closed):
+      beliefs
+      crencas / crenças
+      (optional) beliefs: / crencas: with no payload
+    """
+    raw = str(user_text or "")
+    s = raw.lstrip()
+    s2 = _norm_prefix(s)
+    prefix = ""
+    if s2.startswith("beliefs"):
+        prefix = "beliefs"
+        rest_raw = s[len("beliefs") :]
+    elif s2.startswith("crencas"):
+        prefix = "crencas"
+        rest_raw = s[len("crencas") :]
+    else:
+        return {"recognized": False}
+
+    if rest_raw and (not rest_raw[0].isspace()) and (rest_raw[0] != ":"):
+        return {"recognized": False}
+
+    rest = str(rest_raw).strip()
+    if rest.startswith(":"):
+        rest = rest[1:].strip()
+    if rest:
+        return {"recognized": True, "ok": False, "reason": "extra_tokens", "prefix": str(prefix), "extra_raw": str(rest_raw)}
+    return {"recognized": True, "ok": True, "reason": "ok", "prefix": str(prefix)}
+
+
+def is_forget_command_v96(user_text: str) -> bool:
+    s = str(user_text or "").lstrip()
+    s2 = _norm_prefix(s)
+    return bool(s2.startswith("forget") or s2.startswith("esquece"))
+
+
+def parse_forget_command_v96(user_text: str) -> Dict[str, Any]:
+    """
+    Syntax (fail-closed):
+      forget last              -> memory
+      esquece last             -> memory
+      forget belief <key>      -> belief
+      esquece crenca <key>     -> belief (crença accepted via accent fold)
+    """
+    raw = str(user_text or "")
+    s = raw.lstrip()
+    s2 = _norm_prefix(s)
+    prefix = ""
+    if s2.startswith("forget"):
+        prefix = "forget"
+        rest_raw = s[len("forget") :]
+    elif s2.startswith("esquece"):
+        prefix = "esquece"
+        rest_raw = s[len("esquece") :]
+    else:
+        return {"recognized": False}
+
+    if rest_raw and (not rest_raw[0].isspace()) and (rest_raw[0] != ":"):
+        return {"recognized": False}
+
+    rest = str(rest_raw).lstrip()
+    if rest.startswith(":"):
+        return {"recognized": True, "ok": False, "reason": "unsupported_format", "prefix": str(prefix), "extra_raw": str(rest_raw)}
+
+    toks = [t for t in rest.split() if t]
+    if not toks:
+        return {"recognized": True, "ok": False, "reason": "missing_target", "prefix": str(prefix)}
+
+    t0 = _norm_prefix(toks[0])
+    if t0 == "last":
+        if len(toks) != 1:
+            return {"recognized": True, "ok": False, "reason": "extra_tokens", "prefix": str(prefix), "extra_raw": str(rest_raw)}
+        return {"recognized": True, "ok": True, "reason": "ok", "prefix": str(prefix), "target_kind": "memory", "target": "last"}
+
+    if t0 in ("belief", "crenca"):
+        if len(toks) != 2:
+            return {"recognized": True, "ok": False, "reason": "extra_tokens", "prefix": str(prefix), "extra_raw": str(rest_raw)}
+        key = str(toks[1]).strip()
+        if not key:
+            return {"recognized": True, "ok": False, "reason": "empty_key", "prefix": str(prefix)}
+        return {"recognized": True, "ok": True, "reason": "ok", "prefix": str(prefix), "target_kind": "belief", "belief_key": str(key)}
+
+    return {"recognized": True, "ok": False, "reason": "bad_target", "prefix": str(prefix), "target": str(toks[0])}
+
--- /dev/null	2026-01-13 15:24:17
+++ scripts/smoke_v96_belief_ledger_dialogue_csv.py	2026-01-13 15:18:20
@@ -0,0 +1,344 @@
+#!/usr/bin/env python3
+from __future__ import annotations
+
+import argparse
+import hashlib
+import json
+import os
+import sys
+from typing import Any, Dict, List, Optional
+
+sys.path.insert(0, os.path.dirname(os.path.dirname(__file__)))
+
+from atos_core.conversation_loop_v96 import run_conversation_v96
+from atos_core.conversation_v96 import render_explain_text_v96, verify_conversation_chain_v96
+from atos_core.intent_grammar_v94 import INTENT_EXPLAIN_V94
+
+
+def sha256_file(path: str) -> str:
+    h = hashlib.sha256()
+    with open(path, "rb") as f:
+        while True:
+            b = f.read(1024 * 1024)
+            if not b:
+                break
+            h.update(b)
+    return h.hexdigest()
+
+
+def _fail(msg: str, *, code: int = 2) -> None:
+    print(msg, file=sys.stderr)
+    raise SystemExit(code)
+
+
+def ensure_absent(path: str) -> None:
+    if os.path.exists(path):
+        _fail(f"ERROR: path already exists (WORM): {path}")
+
+
+def _read_jsonl(path: str) -> List[Dict[str, Any]]:
+    rows: List[Dict[str, Any]] = []
+    with open(path, "r", encoding="utf-8") as f:
+        for line in f:
+            line = line.strip()
+            if not line:
+                continue
+            rows.append(json.loads(line))
+    return rows
+
+
+def _extract_payloads(path: str) -> List[Dict[str, Any]]:
+    out: List[Dict[str, Any]] = []
+    for r in _read_jsonl(path):
+        payload = r.get("payload")
+        if isinstance(payload, dict):
+            out.append(dict(payload))
+    return out
+
+
+def _extract_parse_events(path: str) -> List[Dict[str, Any]]:
+    out: List[Dict[str, Any]] = []
+    for r in _read_jsonl(path):
+        if not isinstance(r, dict):
+            continue
+        out.append(
+            {
+                "turn_id": str(r.get("turn_id") or ""),
+                "turn_index": int(r.get("turn_index") or 0),
+                "payload": dict(r.get("payload") or {}) if isinstance(r.get("payload"), dict) else {},
+            }
+        )
+    return out
+
+
+def _extract_trials_for_verify(path: str) -> List[Dict[str, Any]]:
+    out: List[Dict[str, Any]] = []
+    for r in _read_jsonl(path):
+        if not isinstance(r, dict):
+            continue
+        out.append({"objective_kind": str(r.get("objective_kind") or ""), "user_turn_id": str(r.get("user_turn_id") or r.get("turn_id") or "")})
+    return out
+
+
+def _extract_learned_events(path: str) -> List[Dict[str, Any]]:
+    if not os.path.exists(path):
+        return []
+    rows = _read_jsonl(path)
+    out: List[Dict[str, Any]] = []
+    for r in rows:
+        if not isinstance(r, dict):
+            continue
+        d = dict(r)
+        d.pop("prev_hash", None)
+        d.pop("entry_hash", None)
+        out.append(d)
+    return out
+
+
+def _strip_chain_fields(path: str) -> List[Dict[str, Any]]:
+    out: List[Dict[str, Any]] = []
+    for r in _read_jsonl(path):
+        if not isinstance(r, dict):
+            continue
+        d = dict(r)
+        d.pop("prev_hash", None)
+        d.pop("entry_hash", None)
+        out.append(d)
+    return out
+
+
+def _find_user_turn_indices(turns: List[Dict[str, Any]], *, text: str) -> List[int]:
+    out: List[int] = []
+    for t in turns:
+        if not isinstance(t, dict):
+            continue
+        if str(t.get("role") or "") != "user":
+            continue
+        if str(t.get("text") or "") != str(text):
+            continue
+        try:
+            out.append(int(t.get("turn_index") or 0))
+        except Exception:
+            continue
+    return list(out)
+
+
+def _get_turn_by_index(turns: List[Dict[str, Any]], idx: int) -> Dict[str, Any]:
+    for t in turns:
+        if not isinstance(t, dict):
+            continue
+        try:
+            if int(t.get("turn_index") or 0) == int(idx):
+                return dict(t)
+        except Exception:
+            continue
+    return {}
+
+
+def _last_explainable_plan_before(plans: List[Dict[str, Any]], *, user_turn_index: int) -> Optional[Dict[str, Any]]:
+    best: Optional[Dict[str, Any]] = None
+    for p in plans:
+        if not isinstance(p, dict):
+            continue
+        try:
+            uidx = int(p.get("user_turn_index", -1))
+        except Exception:
+            uidx = -1
+        if uidx < 0 or uidx >= int(user_turn_index):
+            continue
+        if str(p.get("intent_id") or "") == INTENT_EXPLAIN_V94:
+            continue
+        if best is None:
+            best = dict(p)
+            continue
+        try:
+            if int(best.get("user_turn_index", -1)) < uidx:
+                best = dict(p)
+        except Exception:
+            best = dict(p)
+    return best
+
+
+def smoke_try(*, out_dir: str, seed: int) -> Dict[str, Any]:
+    user_turns = [
+        "belief: project = IAAA",
+        "beliefs",
+        "get project",
+        "revise: project = IAAA_v2",
+        "beliefs",
+        "forget belief project",
+        "beliefs",
+        "note: meu nome é Daniel",
+        "recall",
+        "explain",
+        "end now",
+    ]
+    res = run_conversation_v96(user_turn_texts=list(user_turns), out_dir=str(out_dir), seed=int(seed))
+
+    turns = _extract_payloads(res["paths"]["turns_jsonl"])  # type: ignore[index]
+    states = _extract_payloads(res["paths"]["states_jsonl"])  # type: ignore[index]
+    parse_events = _extract_parse_events(res["paths"]["parses_jsonl"])  # type: ignore[index]
+    trials = _extract_trials_for_verify(res["paths"]["trials_jsonl"])  # type: ignore[index]
+    learned_events = _extract_learned_events(res["paths"]["learned_rules_jsonl"])  # type: ignore[index]
+    plans = _strip_chain_fields(res["paths"]["plans_jsonl"])  # type: ignore[index]
+    memory_events = _strip_chain_fields(res["paths"]["memory_events_jsonl"])  # type: ignore[index]
+    belief_events = _strip_chain_fields(res["paths"]["belief_events_jsonl"])  # type: ignore[index]
+
+    ok_good, reason_good, _details_good = verify_conversation_chain_v96(
+        turns=turns,
+        states=states,
+        parse_events=parse_events,
+        trials=trials,
+        learned_rule_events=learned_events,
+        action_plans=plans,
+        memory_events=memory_events,
+        belief_events=belief_events,
+        tail_k=6,
+    )
+    if not ok_good:
+        _fail(f"ERROR: verify_conversation_chain_v96 failed: {reason_good}")
+
+    beliefs_idxs = _find_user_turn_indices(turns, text="beliefs")
+    if len(beliefs_idxs) != 3:
+        _fail(f"ERROR: expected 3 beliefs turns, got {len(beliefs_idxs)}")
+
+    a_beliefs_1 = _get_turn_by_index(turns, beliefs_idxs[0] + 1)
+    t1 = str(a_beliefs_1.get("text") or "")
+    if "key=project" not in t1 or 'value="IAAA"' not in t1:
+        _fail("ERROR: beliefs#1 missing project=IAAA")
+
+    get_idxs = _find_user_turn_indices(turns, text="get project")
+    if len(get_idxs) != 1:
+        _fail("ERROR: expected exactly 1 get project turn")
+    a_get = _get_turn_by_index(turns, get_idxs[0] + 1)
+    if str(a_get.get("text") or "") != "project=IAAA":
+        _fail("ERROR: get project output mismatch")
+
+    a_beliefs_2 = _get_turn_by_index(turns, beliefs_idxs[1] + 1)
+    t2 = str(a_beliefs_2.get("text") or "")
+    if 'value="IAAA_v2"' not in t2:
+        _fail("ERROR: beliefs#2 missing revised value IAAA_v2")
+    if 'value="IAAA"' in t2:
+        _fail("ERROR: beliefs#2 unexpectedly contains old value IAAA")
+
+    a_beliefs_3 = _get_turn_by_index(turns, beliefs_idxs[2] + 1)
+    if str(a_beliefs_3.get("text") or "") != "BELIEFS: (empty)":
+        _fail("ERROR: beliefs#3 expected empty")
+
+    recall_idxs = _find_user_turn_indices(turns, text="recall")
+    if len(recall_idxs) != 1:
+        _fail("ERROR: expected exactly 1 recall turn")
+    a_recall = _get_turn_by_index(turns, recall_idxs[0] + 1)
+    rt = str(a_recall.get("text") or "")
+    if not rt.startswith("MEMORY:"):
+        _fail("ERROR: recall assistant text must start with 'MEMORY:'")
+    if "meu nome é Daniel" not in rt:
+        _fail("ERROR: recall assistant text missing memory payload")
+
+    explain_idxs = _find_user_turn_indices(turns, text="explain")
+    if len(explain_idxs) != 1:
+        _fail("ERROR: expected exactly 1 explain turn")
+    u_explain = explain_idxs[0]
+    a_explain = _get_turn_by_index(turns, u_explain + 1)
+    plan0 = _last_explainable_plan_before(plans, user_turn_index=u_explain)
+    if plan0 is None:
+        _fail("ERROR: missing explainable plan before 'explain'")
+    want_explain = render_explain_text_v96(plan0)
+    if str(a_explain.get("text") or "") != str(want_explain):
+        _fail("ERROR: explain output mismatch")
+
+    # Negative test: corrupt first belief event_sig and ensure verify fails deterministically.
+    if not belief_events:
+        _fail("ERROR: expected at least 1 belief event")
+    bad_belief_events = [dict(ev) for ev in belief_events]
+    bad_belief_events[0] = dict(bad_belief_events[0])
+    bad_belief_events[0]["event_sig"] = "0" * 64
+    ok_bad, reason_bad, _details_bad = verify_conversation_chain_v96(
+        turns=turns,
+        states=states,
+        parse_events=parse_events,
+        trials=trials,
+        learned_rule_events=learned_events,
+        action_plans=plans,
+        memory_events=memory_events,
+        belief_events=bad_belief_events,
+        tail_k=6,
+    )
+    if ok_bad:
+        _fail("ERROR: expected verify_conversation_chain_v96 to fail on corrupted belief event_sig")
+    if str(reason_bad) != "belief_event_sig_mismatch":
+        _fail(f"ERROR: expected reason belief_event_sig_mismatch, got {reason_bad}")
+
+    core = {
+        "store_hash": str(res.get("store_hash") or ""),
+        "transcript_hash": str(res.get("transcript_hash") or ""),
+        "state_chain_hash": str(res.get("state_chain_hash") or ""),
+        "parse_chain_hash": str(res.get("parse_chain_hash") or ""),
+        "learned_chain_hash": str(res.get("learned_chain_hash") or ""),
+        "plan_chain_hash": str(res.get("plan_chain_hash") or ""),
+        "memory_chain_hash": str(res.get("memory_chain_hash") or ""),
+        "belief_chain_hash": str(res.get("belief_chain_hash") or ""),
+        "ledger_hash": str(res.get("ledger_hash") or ""),
+        "summary_sha256": str(res.get("summary_sha256") or ""),
+        "negative_test": {"ok": True, "reason": str(reason_bad)},
+        "sha256_summary_json": sha256_file(res["paths"]["summary_json"]),  # type: ignore[index]
+        "sha256_manifest_json": sha256_file(res["paths"]["manifest_json"]),  # type: ignore[index]
+        "sha256_memory_events_jsonl": sha256_file(res["paths"]["memory_events_jsonl"]),  # type: ignore[index]
+        "sha256_belief_events_jsonl": sha256_file(res["paths"]["belief_events_jsonl"]),  # type: ignore[index]
+        "sha256_plans_jsonl": sha256_file(res["paths"]["plans_jsonl"]),  # type: ignore[index]
+        "sha256_turns_jsonl": sha256_file(res["paths"]["turns_jsonl"]),  # type: ignore[index]
+        "sha256_parses_jsonl": sha256_file(res["paths"]["parses_jsonl"]),  # type: ignore[index]
+        "sha256_states_jsonl": sha256_file(res["paths"]["states_jsonl"]),  # type: ignore[index]
+        "sha256_transcript_jsonl": sha256_file(res["paths"]["transcript_jsonl"]),  # type: ignore[index]
+    }
+    return dict(res, core=core)
+
+
+def main() -> None:
+    ap = argparse.ArgumentParser()
+    ap.add_argument("--out_base", required=True)
+    ap.add_argument("--seed", type=int, default=0)
+    args = ap.parse_args()
+
+    out_base = str(args.out_base)
+    seed = int(args.seed)
+
+    out1 = f"{out_base}_try1"
+    out2 = f"{out_base}_try2"
+    ensure_absent(out1)
+    ensure_absent(out2)
+
+    r1 = smoke_try(out_dir=out1, seed=seed)
+    r2 = smoke_try(out_dir=out2, seed=seed)
+
+    keys = [
+        "store_hash",
+        "transcript_hash",
+        "state_chain_hash",
+        "parse_chain_hash",
+        "learned_chain_hash",
+        "plan_chain_hash",
+        "memory_chain_hash",
+        "belief_chain_hash",
+        "ledger_hash",
+        "summary_sha256",
+    ]
+    for k in keys:
+        if str(r1.get(k) or "") != str(r2.get(k) or ""):
+            _fail(f"ERROR: determinism mismatch for {k}: try1={r1.get(k)} try2={r2.get(k)}")
+
+    out = {
+        "ok": True,
+        "seed": int(seed),
+        "determinism_ok": True,
+        "determinism": {k: str(r1.get(k) or "") for k in keys},
+        "negative_test": dict(r1.get("core", {}).get("negative_test", {})),
+        "try1": {"out_dir": str(out1), "summary_sha256": str(r1.get("summary_sha256") or "")},
+        "try2": {"out_dir": str(out2), "summary_sha256": str(r2.get("summary_sha256") or "")},
+    }
+    print(json.dumps(out, ensure_ascii=False, indent=2, sort_keys=True))
+
+
+if __name__ == "__main__":
+    main()
+
--- /dev/null	2026-01-13 15:24:17
+++ scripts/verify_conversation_chain_v96.py	2026-01-13 15:17:02
@@ -0,0 +1,172 @@
+#!/usr/bin/env python3
+from __future__ import annotations
+
+import argparse
+import json
+import os
+import sys
+from typing import Any, Dict, List
+
+sys.path.insert(0, os.path.dirname(os.path.dirname(__file__)))
+
+from atos_core.conversation_v96 import verify_chained_jsonl_v96, verify_conversation_chain_v96
+
+
+def _read_jsonl(path: str) -> List[Dict[str, Any]]:
+    out: List[Dict[str, Any]] = []
+    if not os.path.exists(path):
+        return out
+    with open(path, "r", encoding="utf-8") as f:
+        for line in f:
+            line = line.strip()
+            if not line:
+                continue
+            out.append(json.loads(line))
+    return out
+
+
+def _extract_payloads(rows: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
+    out: List[Dict[str, Any]] = []
+    for r in rows:
+        if not isinstance(r, dict):
+            continue
+        payload = r.get("payload")
+        if isinstance(payload, dict):
+            out.append(dict(payload))
+    return out
+
+
+def _extract_parse_events(rows: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
+    out: List[Dict[str, Any]] = []
+    for r in rows:
+        if not isinstance(r, dict):
+            continue
+        payload = r.get("payload") if isinstance(r.get("payload"), dict) else {}
+        out.append(
+            {
+                "turn_id": str(r.get("turn_id") or ""),
+                "turn_index": int(r.get("turn_index") or 0),
+                "payload": dict(payload),
+            }
+        )
+    return out
+
+
+def _extract_trials_for_verify(rows: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
+    out: List[Dict[str, Any]] = []
+    for r in rows:
+        if not isinstance(r, dict):
+            continue
+        out.append({"objective_kind": str(r.get("objective_kind") or ""), "user_turn_id": str(r.get("user_turn_id") or r.get("turn_id") or "")})
+    return out
+
+
+def _extract_learned_events(rows: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
+    out: List[Dict[str, Any]] = []
+    for r in rows:
+        if not isinstance(r, dict):
+            continue
+        d = dict(r)
+        d.pop("prev_hash", None)
+        d.pop("entry_hash", None)
+        out.append(d)
+    return out
+
+
+def _strip_chain_fields(rows: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
+    out: List[Dict[str, Any]] = []
+    for r in rows:
+        if not isinstance(r, dict):
+            continue
+        d = dict(r)
+        d.pop("prev_hash", None)
+        d.pop("entry_hash", None)
+        out.append(d)
+    return out
+
+
+def main() -> None:
+    ap = argparse.ArgumentParser()
+    ap.add_argument("--run_dir", required=True)
+    args = ap.parse_args()
+
+    run_dir = str(args.run_dir)
+    turns_path = os.path.join(run_dir, "conversation_turns.jsonl")
+    parses_path = os.path.join(run_dir, "intent_parses.jsonl")
+    learned_path = os.path.join(run_dir, "learned_intent_rules.jsonl")
+    plans_path = os.path.join(run_dir, "action_plans.jsonl")
+    memory_path = os.path.join(run_dir, "memory_events.jsonl")
+    belief_path = os.path.join(run_dir, "belief_events.jsonl")
+    states_path = os.path.join(run_dir, "conversation_states.jsonl")
+    trials_path = os.path.join(run_dir, "dialogue_trials.jsonl")
+    evals_path = os.path.join(run_dir, "objective_evals.jsonl")
+    transcript_path = os.path.join(run_dir, "transcript.jsonl")
+
+    rows_turns = _read_jsonl(turns_path)
+    rows_parses = _read_jsonl(parses_path)
+    rows_learned = _read_jsonl(learned_path) if os.path.exists(learned_path) else []
+    rows_plans = _read_jsonl(plans_path)
+    rows_memory = _read_jsonl(memory_path) if os.path.exists(memory_path) else []
+    rows_belief = _read_jsonl(belief_path) if os.path.exists(belief_path) else []
+    rows_states = _read_jsonl(states_path) if os.path.exists(states_path) else []
+    rows_trials = _read_jsonl(trials_path)
+    rows_evals = _read_jsonl(evals_path)
+    rows_transcript = _read_jsonl(transcript_path)
+
+    turns = _extract_payloads(rows_turns)
+    states = _extract_payloads(rows_states)
+    parse_events = _extract_parse_events(rows_parses)
+    trials = _extract_trials_for_verify(rows_trials)
+    learned_events = _extract_learned_events(rows_learned)
+    plans = _strip_chain_fields(rows_plans)
+    memory_events = _strip_chain_fields(rows_memory)
+    belief_events = _strip_chain_fields(rows_belief)
+
+    chains = {
+        "turns_chain_ok": bool(verify_chained_jsonl_v96(turns_path)),
+        "parses_chain_ok": bool(verify_chained_jsonl_v96(parses_path)),
+        "learned_chain_ok": bool(verify_chained_jsonl_v96(learned_path)) if os.path.exists(learned_path) else True,
+        "plans_chain_ok": bool(verify_chained_jsonl_v96(plans_path)),
+        "memory_chain_ok": bool(verify_chained_jsonl_v96(memory_path)) if os.path.exists(memory_path) else False,
+        "belief_chain_ok": bool(verify_chained_jsonl_v96(belief_path)) if os.path.exists(belief_path) else False,
+        "states_chain_ok": bool(verify_chained_jsonl_v96(states_path)) if os.path.exists(states_path) else True,
+        "trials_chain_ok": bool(verify_chained_jsonl_v96(trials_path)),
+        "evals_chain_ok": bool(verify_chained_jsonl_v96(evals_path)),
+        "transcript_chain_ok": bool(verify_chained_jsonl_v96(transcript_path)),
+    }
+
+    ok_inv, reason, details = verify_conversation_chain_v96(
+        turns=turns,
+        states=states,
+        parse_events=parse_events,
+        trials=trials,
+        learned_rule_events=learned_events,
+        action_plans=plans,
+        memory_events=memory_events,
+        belief_events=belief_events,
+        tail_k=6,
+    )
+
+    out = {
+        "ok": bool(all(chains.values())) and bool(ok_inv),
+        "chains": dict(chains),
+        "invariants": {"ok": bool(ok_inv), "reason": str(reason), "details": dict(details)},
+        "counts": {
+            "turns_total": int(len(turns)),
+            "states_total": int(len(states)),
+            "parses_total": int(len(parse_events)),
+            "learned_total": int(len(learned_events)),
+            "plans_total": int(len(plans)),
+            "memory_events_total": int(len(memory_events)),
+            "belief_events_total": int(len(belief_events)),
+            "trials_total": int(len(trials)),
+            "evals_total": int(len(rows_evals)),
+            "transcript_total": int(len(rows_transcript)),
+        },
+    }
+    print(json.dumps(out, ensure_ascii=False, indent=2, sort_keys=True))
+
+
+if __name__ == "__main__":
+    main()
+
